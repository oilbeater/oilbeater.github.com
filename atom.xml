<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Oilbeater 的自习室</title>
  <icon>http://oilbeater.com/icon.png</icon>
  
  <link href="http://oilbeater.com/atom.xml" rel="self"/>
  
  <link href="http://oilbeater.com/"/>
  <updated>2025-12-01T03:30:38.489Z</updated>
  <id>http://oilbeater.com/</id>
  
  <author>
    <name>Oilbeater</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>从 NetworkPolicy 到 ClusterNetworkPolicy</title>
    <link href="http://oilbeater.com/2025/11/30/networkpolicy-to-clusternetworkpolicy/"/>
    <id>http://oilbeater.com/2025/11/30/networkpolicy-to-clusternetworkpolicy/</id>
    <published>2025-11-30T09:45:00.000Z</published>
    <updated>2025-12-01T03:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">NetworkPolicy</a> 作为 Kubernetes 早期的 API 看似美好，实际使用过程中就会发现它功能有限，不易扩展，不易理解且不易使用。因此 Kubernetes 成立了 <a href="https://network-policy-api.sigs.k8s.io/">Network Policy API Working Group</a> 来制订下一代的 API 规范，而 <a href="https://network-policy-api.sigs.k8s.io/api-overview/#the-clusternetworkpolicy-resource">ClusterNetworkPolicy</a> 就是目前探讨出来的最新成果，未来可能会成为新的规范。</p><h2 id="NetworkPolicy-的局限性"><a href="#NetworkPolicy-的局限性" class="headerlink" title="NetworkPolicy 的局限性"></a>NetworkPolicy 的局限性</h2><p>NetworkPolicy 是 Namespace 级资源，本质上是“应用视角”的策略。它通过 podSelector、namespaceSelector 来选中一批 Pod，然后对这些 Pod 的 Ingress、Egress 做限制。这带来了几个实际的问题：</p><h3 id="缺少-Cluster-级别的控制"><a href="#缺少-Cluster-级别的控制" class="headerlink" title="缺少 Cluster 级别的控制"></a>缺少 Cluster 级别的控制</h3><p>由于策略的作用域是 Namespace，集群管理员无法定义集群级别的默认网络策略，只能在每个 Namespace 里都创建相同的网络策略。这样一方面每次更新策略需要对所有 Namespace 下的资源进行更新，另一方面，很容易和开发者创建的网络策略产生冲突。管理员设置的策略，应用侧很容易就可以通过新的策略绕过去。</p><p>本质上在于 NetworkPolicy 这种应用视角的策略和管理员集群视角的策略存在冲突，当用户的安全模型并不是应用视角的时候 NetworkPolicy 就会变得难以应用。而集群管理员管控集群整体的安全策略是个现实中很常见的场景。</p><h3 id="语义不清晰"><a href="#语义不清晰" class="headerlink" title="语义不清晰"></a>语义不清晰</h3><p>NetworkPolicy 的语义有几个“坑”，新手和运维人员都容易踩：</p><ul><li><p>隐式隔离。<br>  一旦有任何 NetworkPolicy 选中了某个 Pod，那么“未被允许”的流量就会被默认拒绝。这种隐式的行为需要靠心算来推导，很难一眼看懂。</p></li><li><p>只有允许，没有显式拒绝。<br>  标准 NetworkPolicy 只能写 allow 类型的规则，想要“拒绝某个来源”，通常要通过补充其他 allow 规则间接实现，或者依赖某些 CNI 厂商特有的扩展。</p></li><li><p>没有优先级。<br>  多个 NetworkPolicy 选择同一批 Pod 时，规则是加法而不是覆盖关系。最终行为往往需要把所有策略合在一起看，排查问题时非常困难。</p></li></ul><p>这些特点叠加在一起，就会导致 NetworkPolicy 理解起来困难，调试起来更困难。</p><h2 id="ClusterNetworkPolicy-的解决方案"><a href="#ClusterNetworkPolicy-的解决方案" class="headerlink" title="ClusterNetworkPolicy 的解决方案"></a>ClusterNetworkPolicy 的解决方案</h2><p>为了解决 NetworkPolicy 固有的问题，Network Policy API 工作组提出了一个新的 API —— ClusterNetworkPolicy (CNP)，它的目标是在不破坏现有 NetworkPolicy 用法的前提下，给集群管理员提供一个更清晰、更强大的网络控制能力。</p><p>其最核心的思路是引入策略分层，在现有的 NetworkPolicy 之前和之后分别引入独立的策略层，将集群管理员的策略和应用的策略分开，提供了更丰富的视角和更灵活的使用。<br>![[Pasted image 20251201104247.png]]</p><p>一个示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">policy.networking.k8s.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterNetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sensitive-ns-deny-from-others</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tier:</span> <span class="string">Admin</span></span><br><span class="line">  <span class="attr">priority:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">subject:</span></span><br><span class="line">    <span class="attr">namespaces:</span></span><br><span class="line">      <span class="attr">matchLabels:</span></span><br><span class="line">        <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">sensitive-ns</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">Deny</span></span><br><span class="line">      <span class="attr">from:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">namespaces:</span></span><br><span class="line">            <span class="attr">matchLabels:</span> &#123;&#125; </span><br><span class="line">      <span class="attr">name:</span> <span class="string">deny-all-from-other-namespaces</span></span><br></pre></td></tr></table></figure><h3 id="集群管理员视角"><a href="#集群管理员视角" class="headerlink" title="集群管理员视角"></a>集群管理员视角</h3><p>新引入的 ClusterNetworkPolicy 是集群级别资源，管理员可以直接选中多个 Namespace 下的 Pod 进行策略控制。同时 Admin Tier 的策略可以先于 NetworkPolicy 生效，这样集群管理员只需要少量的 Admin Tier 策略就可以控制住整个集群的红线行为。</p><p>而 Baseline Tier 的策略在所有 NetworkPolicy 都不匹配后执行，相当于提供了一个兜底策略。</p><p>简单来说：</p><ul><li><code>tier: Admin</code> 的策略用来定义<strong>绝对不能做</strong>的事情。</li><li><code>tier: Baseline</code> 的策略用来定义<strong>默认不建议做</strong>的事情，用户可以通过 NetworkPolicy 来放行。</li></ul><h3 id="明确的优先级"><a href="#明确的优先级" class="headerlink" title="明确的优先级"></a>明确的优先级</h3><p>ClusterNetworkPolicy 中新增了 <code>priority</code> 字段，这样在同一个 Tier 中多个规则的范围出现重叠时，可以通过优先级清晰的界定哪个规则该生效，不会再出现 NetworkPolicy 里那种隐式覆盖，需要互相猜测的情况。</p><h3 id="清晰的动作语义：Accept-Deny-Pass"><a href="#清晰的动作语义：Accept-Deny-Pass" class="headerlink" title="清晰的动作语义：Accept &#x2F; Deny &#x2F; Pass"></a>清晰的动作语义：Accept &#x2F; Deny &#x2F; Pass</h3><p>和 NetworkPolicy 只有“允许”语义不同，ClusterNetworkPolicy 的每条规则都有一个显式的 <code>action</code> 字段，可以取值：</p><ul><li><code>Accept</code>：允许这条规则选中的流量，并停止后续策略评估</li><li><code>Deny</code>：拒绝这条规则选中的流量，并停止后续策略评估</li><li><code>Pass</code>：在当前 tier 里跳过后续 ClusterNetworkPolicy，交给下一层继续评估</li></ul><p>同时，文档中特别强调：</p><ul><li>ClusterNetworkPolicy 不再有 NetworkPolicy 那种“隐式隔离”的效果</li><li>所有行为都来自你写的规则本身，读策略时看到什么就是什么</li></ul><p>结合优先级的配置，规则的理解就不再会产生模糊的情况，理解上也变得不那么困难。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>ClusterNetworkPolicy 一定程度上回归了传统的分层网络策略的架构，在解决了 NetworkPolicy 问题的情况下没有带来破坏性的变化，可以说是一个很不错的设计，希望能尽快看到这个规范的成熟和落地。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/services-networking/network-policies/&quot;&gt;NetworkPolicy&lt;/a&gt; 作为 Kubernetes 早期的 API 看似美好，实际使用过程中就</summary>
      
    
    
    
    
    <category term="network" scheme="http://oilbeater.com/tags/network/"/>
    
    <category term="opensource" scheme="http://oilbeater.com/tags/opensource/"/>
    
  </entry>
  
  <entry>
    <title>OpenPERouter：把 EVPN 带入 Kubernetes</title>
    <link href="http://oilbeater.com/2025/11/09/kubernetes-evpn/"/>
    <id>http://oilbeater.com/2025/11/09/kubernetes-evpn/</id>
    <published>2025-11-09T04:29:02.000Z</published>
    <updated>2025-12-01T03:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<p>目前社区在 Kubernetes 实现网络多租户主流选型是 <a href="https://github.com/kubeovn/kube-ovn">Kube-OVN</a> 和 <a href="https://github.com/ovn-kubernetes/ovn-kubernetes">ovn-kubernetes</a>，这两个方案本质上都是在物理网络上通过 OVS 和 OVN 的能力构建了一层 Overlay 虚拟网络。这种方案不太关心底层物理网络架构，有着比较好的兼容性，但是双层网络架构也加大了整体架构的复杂度。</p><p>最近我在调研 EVPN 这种物理网络多租户的方案，发现了 <a href="https://github.com/openperouter/openperouter">OpenPERouter</a> 这个开源项目，他把 EVPN 的理念引入了容器网络，提供了一种新的在 Kubernetes 上实现多租户的方案。该方案不仅能统一软硬件网络架构，还在一定程度上能兼容现有 Calico 这种通过 BGP 方式发布路由的 CNI，我甚至已经看到通过少量工作就可以让 Calico 具备多租户能力的前景。虽然这个项目还在早期，但我认为这是一个相当不错的方向，未来很可能会成为构建大规模数据中心的一个有竞争力选型。</p><h2 id="OVN-类方案的局限性"><a href="#OVN-类方案的局限性" class="headerlink" title="OVN 类方案的局限性"></a>OVN 类方案的局限性</h2><p>OVN 类方案的主要局限性有两个一个是集中式控制平面的规模限制，另一个就是网络复杂度。</p><h3 id="集中式控制平面"><a href="#集中式控制平面" class="headerlink" title="集中式控制平面"></a>集中式控制平面</h3><p>尽管 Kube-OVN 在社区已经存在了上千节点的大规模案例，但是由于 OVN 这种集中式控制面的架构，会导致控制面存在比较大的压力，成为整个集群的瓶颈。特别是在控制面节点断电或者故障时，可能会需要较长时间网络控制面才能恢复。</p><p><img src="/../images/ovn-limit.png" alt="ovn-limit"></p><p>这个问题主要是由 OVN 集中式控制平面的架构带来的，无法完全规避。ovn-kubernetes 中采用了每个节点一个 OVN 控制平面，多节点之间通过 OVN-IC 互联的方案来规避这个瓶颈。但是这个方案同时也会导致架构的复杂，并且相当于主动弃用了 OVN 本身的集群网络能力，使得大量的 OVN 能力无法使用。</p><h3 id="网络复杂度"><a href="#网络复杂度" class="headerlink" title="网络复杂度"></a>网络复杂度</h3><p>另一个问题就在于 OVS&#x2F;OVN 这套体系本身的复杂度，使用者需要重新再构建一套 OVN 规范下的网络拓扑，流表的知识体系才能保证自己面对实际问题时不会手足无措。而这套体系和底层的物理网络往往又是不同的，实际中相当于存在两套网络体系，这不仅会使问题排查变得更复杂，还会导致需要物理网络团队和容器网络团队两套人马，双方往往都无法理解彼此的工作内容，无法有效协同。</p><p>以上两个局限性更多的是选型上的取舍，如果希望能够软件集中控制，希望容器网络能不关心底层物理网络，那这样的选择必然就会带来这样的局限性。</p><h2 id="EVPN"><a href="#EVPN" class="headerlink" title="EVPN"></a>EVPN</h2><p>在和 OVS 这种纯软件方案平行的另一个硬件世界，有另一套硬件版本的多租户网络方案，那就是 EVPN。</p><p>在 EVPN 的世界里，在数据平面交换机之间通过 Vxlan 对数据包做封装，通过在 Vxlan 的 Header 中设置 VNI 来区分不同租户的流量，实现了流量的隔离。</p><p>同时，交换机之间通过 BGP 在控制平面来同步 L2&#x2F;L3 的路由以及 VNI 的信息，能够快速的学习整个网络拓扑中的地址，路由和租户信息。 </p><p><img src="/../images/evpn.png" alt="EVPN"></p><p>通过这种方式，大型数据中心可以自动化分布式的实现多租户网络。这套方案在很多大型数据中心都已经落地了，主流的交换机目前也都已经支持。那么在容器领域有没有基于这种技术架构做网络的呢？这就是我最近发现的 OpenPERouter 了。</p><h2 id="OpenPERouter"><a href="#OpenPERouter" class="headerlink" title="OpenPERouter"></a>OpenPERouter</h2><p>OpenPERouter 的核心理念是将 EVPN 交换机的逻辑下沉到节点，在每台机器上运行一个 FRR 通过直接和物理交换机建立 BGP 和 VXLAN 隧道，将容器网络直接打通到已有的 EVPN 架构的物理网络。</p><p><img src="/../images/openperouter.png"></p><p>现有的容器网络想接入 OpenPERouter 也并不算复杂，基于 BGP 的 CNI 需要和 OpenPERouter 建立 BGP Peer；对于基于 veth 和网桥的 CNI，需要把原来在宿主机一侧的 veth 改为接入到 OpenPERouter 所在的 net ns 即可。</p><p>这个方案带来了一些独特的优点：</p><ol><li>统一了底层网络和容器网络，两者采用了相同的 EVPN 架构，虽然在具体操作，软件使用上还有区别，但整体的思路已经基本一致了。</li><li>极其轻量的方式就实现了 Underlay 和多租户这两个在容器网络里比较困难的功能，由于主要的控制面和数据面都在硬件层，容器网络只是做接入，理论上 CNI 层可以做的十分轻量化。</li><li>可以将已有的 CNI 转换为多租户的 CNI，尽管项目的开发者没有具体提这个事情，但是我已经看到了给 Calico 的 IPPool 增加一个 VNI 的配置就能快速把 Calico 改造成一个多租户网络的可能性。</li></ol><p>当然这个方案当前也有它的局限性：</p><ol><li>统一的网络也就意味着容器网络完全侵入了底层物理网络，这需要有统一的团队管理，这在当前的环境可能会产生很多办公室政治问题</li><li>OpenPERouter 目前自己并没有做 CNI 相关的事情，而是尝试接入其他网络项目。这可能是考虑到当前已有多种主流方案可供选择，但从我来看接入其他 CNI 反而会让这个简洁的 EVPN 方案变的比原来更复杂，未来发生不兼容和冲突也是大概率事件。基于这个思路从头做一个轻量化的专门面向 EVPN 设计的 CNI 会是个更优雅的选择。</li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在我看来，EVPN 会是未来容器网络里的一个极其有竞争力的技术方案，但是当下并没有很成熟的开源项目，OpenPERouter 做了很好的尝试，我也很希望看到未来有一款专门为 EVPN 架构设计的 CNI 能够大幅简化全局的网络设计。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;目前社区在 Kubernetes 实现网络多租户主流选型是 &lt;a href=&quot;https://github.com/kubeovn/kube-ovn&quot;&gt;Kube-OVN&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/ovn-kubernetes/ovn</summary>
      
    
    
    
    
    <category term="EVPN" scheme="http://oilbeater.com/tags/EVPN/"/>
    
    <category term="Kubernetes" scheme="http://oilbeater.com/tags/Kubernetes/"/>
    
    <category term="Network" scheme="http://oilbeater.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>LoxiLB -- More than MetalLB</title>
    <link href="http://oilbeater.com/2025/08/15/loxilb-metallb/"/>
    <id>http://oilbeater.com/2025/08/15/loxilb-metallb/</id>
    <published>2025-08-15T14:48:00.000Z</published>
    <updated>2025-12-01T03:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/metallb/metallb">MetalLB</a> 目前几乎成了私有云场景下 Kubernetes 提供 LoadBalancer 类型 Service 的事实标准。他的实现逻辑简单清晰，并且功能单一，基于 Gossip 的分布式选主也保证了 VIP 的漂移可以做到迅速且不依赖 Kubernetes 的状态。但是它在专注的情况下也缺少了一些在生产环境极为重要的功能，这也是为什么我最近在调研其他的开源项目，并发现了 <a href="https://github.com/loxilb-io/loxilb">LoxiLB</a> 这个很不错的 MetalLB 替代项目。</p><h2 id="MetalLB-的缺陷"><a href="#MetalLB-的缺陷" class="headerlink" title="MetalLB 的缺陷"></a>MetalLB 的缺陷</h2><p>MetalLB 虽有 LB 之名，但实际上并不处理任何转发平面的工作。严格来说它只提供了 VIP 的对外通告能力，所有转发平面的事情都是依赖 kube-proxy 或者各类的 kube-proxy 的替代 来实现。这样的好处是它可以专注在提供各种类型的 VIP 宣告方式，并且能和 Kubernetes 本身的行为保持最大的兼容性，但同时由于 kube-proxy 本身孱弱的能力，也限制了 MetalLB 本身的功能。</p><h3 id="缺乏主动健康检查"><a href="#缺乏主动健康检查" class="headerlink" title="缺乏主动健康检查"></a>缺乏主动健康检查</h3><p>这是 Kubernetes 由来已久的一个问题，Service 后端的 Endpoint 健康状态依赖 Pod 本身的 ReadinessProbe&#x2F;LivenessProbe，Probe 的执行依赖当前节点的 kubelet。造成的结果就是断电或类似的直接宕机情况下 kubelet 无法更新 Pod 的健康状态，需要等到触发 node not ready 的超时才会修改 Pod 监控状态，通常在大集群这个超时可能会有数分钟，导致这段时间内访问 Service 会出现失败。</p><p>严格来说这并不是 MetalLB 的问题，但是由于 MetalLB 本身对数据转发平面没有任何控制能力，无法主动探测 Pod 真实健康情况也无法修改 Pod 健康状态，只能被动接受这种机制。</p><p>虽然通过 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate">Pod ReadinessGates</a> 可以使用额外的 controller 主动探测来控制 Pod 健康状态，间接解决这个问题，但对于 MetalLB 来说这个也和它没有什么关系，并没有能开箱即用的方案，这对生产环境还是个很大的隐患。</p><h3 id="缺乏有效的监控"><a href="#缺乏有效的监控" class="headerlink" title="缺乏有效的监控"></a>缺乏有效的监控</h3><p>这同样是依赖 kube-proxy 实现导致的一个问题，kube-proxy 的多种实现方式都没有流量层面的监控，导致的后果就是如果你看 MetalLB 提供的<a href="https://metallb.universe.tf/prometheus-metrics/">监控指标</a>就会发现里面没有任何流量的指标。这种几乎没有任何数据平面监控的 LB 要上生产，就有点过于松弛了。</p><h2 id="LoxiLB-的改进"><a href="#LoxiLB-的改进" class="headerlink" title="LoxiLB 的改进"></a>LoxiLB 的改进</h2><p>LoxiLB 本身是一个为电信场景的特殊需求，使用 eBPF 打造的专用 LB，它完全实现了控制平面和数据平面是一个完整的 LB 实现。LoxiLB 本身的功能十分多，尤其在 SCTP 领域有十分多专属能力，这里不赘述只是重点看一下针对 MetalLB 缺陷的补足。</p><h3 id="主动健康检查"><a href="#主动健康检查" class="headerlink" title="主动健康检查"></a>主动健康检查</h3><p>LoxiLB 可以给每个 Service 配置<a href="https://docs.loxilb.io/latest/cmd/#create-end-point-for-health-probing">主动健康检查</a>，支持 ping, tcp, udp, sctp, http, https 也支持超时，重试之类的细粒度配置，虽然称不上多优秀，但 MetalLB 就是没有这个功能，这就显得很尴尬。</p><h3 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h3><p>这一点就是 eBPF 的强项了，LoxiLB 内置了不少 <a href="https://docs.loxilb.io/latest/loxilb-incluster-grafana/">Metrics 和 Grafana 面板</a>，此外由于数据平面是自己实现的，添加各类监控指标也相对容易一些。</p><h3 id="潜在的风险"><a href="#潜在的风险" class="headerlink" title="潜在的风险"></a>潜在的风险</h3><p>整体来看 LoxiLB 是一个我很喜欢的项目，甚至很多关于 SCTP 协议的理解我都是看了它的一些配置才能理解是怎么回事。但是他还是有着一些不足的地方：</p><ul><li>选主的逻辑目前还是 Kubernetes 那套 Leader Election 逻辑，但我更喜欢 MetalLB 那种与 Kubernetes 解耦的选主逻辑。</li><li>文档整体比较凌乱，虽然文档内容很多但是组织的不是很好，好多配置得靠搜索才能找到，一些文档格式也存在问题。</li><li>虽然该项目是 CNCF 沙箱项目，但是整体的活跃度和参与度还是偏低，能感觉出来该项目应该还是个比较成熟的内部项目拿了出来，但是如果社区采用度比较低的话未来还是有些隐患。</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>MetalLB 依然是一个我很喜欢的项目，它极其精准地解决了 VIP 宣告及高可用的问题，但是如果达到生产上完备的状态还需要配合其他组件。LoxiLB 则是一套完整的 LB 解决方案，但是社区的发展还处于早期，还有待更多人的参与。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://github.com/metallb/metallb&quot;&gt;MetalLB&lt;/a&gt; 目前几乎成了私有云场景下 Kubernetes 提供 LoadBalancer 类型 Service 的事实标准。他的实现逻辑简单清晰，并且功能单一，基于 Go</summary>
      
    
    
    
    
    <category term="metallb" scheme="http://oilbeater.com/tags/metallb/"/>
    
    <category term="loxilb" scheme="http://oilbeater.com/tags/loxilb/"/>
    
  </entry>
  
  <entry>
    <title>GoBGP 快速上手</title>
    <link href="http://oilbeater.com/2025/07/08/gobgp-guide/"/>
    <id>http://oilbeater.com/2025/07/08/gobgp-guide/</id>
    <published>2025-07-08T22:48:00.000Z</published>
    <updated>2025-12-01T03:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<p>在做 MetalLB 和 Calico 的一些测试时需要验证 BGP 相关的功能，然而每次测试要去联系运维团队配合网络变更是不太现实的，并且大多数情况我们只要验证 BGP 信息正常交换就可以了，不需要真的去改变物理网络。于是就找到了 <a href="https://github.com/osrg/gobgp">GoBGP</a> 这个软件路由器进行模拟。</p><p>GoBGP 本身有着很复杂的配置，但是如果你只是像我一样只是想有个虚拟的路由器，让客户端把 BGP 信息发送过来，检查路由表信息是否正确更新，那看这篇文章就可以了。</p><h2 id="下载-GoBGP-二进制文件"><a href="#下载-GoBGP-二进制文件" class="headerlink" title="下载 GoBGP 二进制文件"></a>下载 GoBGP 二进制文件</h2><p>去 <a href="https://github.com/osrg/gobgp/releases">Release</a> 制品列表里找到对应系统的制品解压即可，重要的只有两个二进制文件： <code>gobgpd</code> 虚拟路由器进程，<code>gobgp</code>命令行工具，用来查看路由对不对。</p><h2 id="启动虚拟路由器"><a href="#启动虚拟路由器" class="headerlink" title="启动虚拟路由器"></a>启动虚拟路由器</h2><p>创建一个 <code>gobgp.toml</code> 文件，最简单的配置就照着我下面这个就好了，大部分基础的云原生领域 BGP 相关的软件测试用这个就够了。</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[global.config]</span></span><br><span class="line">  <span class="attr">as</span> = <span class="number">65000</span>                          <span class="comment"># 测试环境随便写一个就好</span></span><br><span class="line">  <span class="attr">router-id</span> = <span class="string">&quot;10.0.0.1&quot;</span>              <span class="comment"># 测试环境随便写一个就好，写 GoBGP 所在节点 IP 日志清晰一些</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[dynamic-neighbors]]</span>                 <span class="comment"># 被动连接模式，省去了配固定客户端</span></span><br><span class="line">  <span class="section">[dynamic-neighbors.config]</span></span><br><span class="line">    <span class="attr">prefix</span>     = <span class="string">&quot;192.168.0.0/24&quot;</span>     <span class="comment"># 允许哪个 IP 范围内的客户端来连接 </span></span><br><span class="line">    <span class="attr">peer-group</span> = <span class="string">&quot;ext-ebgp&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[peer-groups]]</span>                       <span class="comment"># 复制粘贴就好了</span></span><br><span class="line">  <span class="section">[peer-groups.config]</span></span><br><span class="line">    <span class="attr">peer-group-name</span> = <span class="string">&quot;ext-ebgp&quot;</span></span><br><span class="line">    <span class="attr">peer-as</span>         = <span class="number">65000</span></span><br><span class="line">  <span class="section">[[peer-groups.afi-safis]]</span></span><br><span class="line">    <span class="section">[peer-groups.afi-safis.config]</span></span><br><span class="line">      <span class="attr">afi-safi-name</span> = <span class="string">&quot;ipv4-unicast&quot;</span></span><br></pre></td></tr></table></figure><p>启动 <code>gobgpd</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./gobgpd -f gobgp.toml</span><br></pre></td></tr></table></figure><p>在另一个终端观察当前的路由表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./gobgp global rib</span><br></pre></td></tr></table></figure><p>这样基本上 MetalLB，Calico 的基础 BGP 能力就可以测试了。如果想更配更复杂的模式，比如 <a href="https://github.com/osrg/gobgp/blob/master/docs/sources/route-reflector.md">Router Reflector</a>，<a href="https://github.com/osrg/gobgp/blob/master/docs/sources/evpn.md">EVPN</a> 那就再去翻 <a href="https://github.com/osrg/gobgp?tab=readme-ov-file#documentation">GoBGP 的文档</a>吧。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在做 MetalLB 和 Calico 的一些测试时需要验证 BGP 相关的功能，然而每次测试要去联系运维团队配合网络变更是不太现实的，并且大多数情况我们只要验证 BGP 信息正常交换就可以了，不需要真的去改变物理网络。于是就找到了 &lt;a href=&quot;https://git</summary>
      
    
    
    
    
    <category term="networking" scheme="http://oilbeater.com/tags/networking/"/>
    
    <category term="gobgp" scheme="http://oilbeater.com/tags/gobgp/"/>
    
    <category term="tutorial" scheme="http://oilbeater.com/tags/tutorial/"/>
    
  </entry>
  
  <entry>
    <title>怎样的开源文档规范最合适？</title>
    <link href="http://oilbeater.com/2025/07/06/oss-docs-best-practise/"/>
    <id>http://oilbeater.com/2025/07/06/oss-docs-best-practise/</id>
    <published>2025-07-06T13:00:10.000Z</published>
    <updated>2025-12-01T03:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<p>最近打算把 Kube-OVN 的文档整理一遍，同时思考怎样的文档规范能尽可能做到：</p><ol><li>降低 Maintainer 的维护成本（用户看完文档后不会再去找 Maintainer ）。</li><li>能够充分复用（不看文档的人找过来可以直接甩文档）。</li><li>同时对社区的用户也尽可能有帮助（少走弯路）。</li></ol><p>我决定先按照下面的结构重构一下文档，来看看效果。</p><ol><li><strong>概要</strong>：一两句话描述这个功能达到什么效果，解决什么问题，有什么优势。之前很多文档都是以技术细节开头，反而把真正能实现的效果给模糊掉了。明确功能是什么后，用户就可以确认自己是否还需要继续往下看了。</li><li><strong>局限性</strong>：这个功能不是什么，什么没做到，解决不了什么问题，使用有什么限制条件。这个其实和第一部分一样重要，不然用户可能有不切实际的预期等到很靠后的时候才知道某个功能其实是不符合预期的或者限制条件不满足，也浪费了双方很多时间。有人问为什么不能用的时候也可以甩文档。</li><li><strong>实现原理</strong>：我们用到的 OVN&#x2F;OVS 的哪些能力，简要的介绍以及对应功能的参考文档。到这里我们其实期望用户有一些更深的理解，不至于出了问题毫无思路再去扒代码或者找到 Maintainer。我们也建议真在生产使用 Kube-OVN 的用户要有一些从底层开始排查的能力，Kube-OVN 虽然做了很多抽象让使用变得简单，但是在用户的环境里使用的异常还是需要用户自己有能力排查。</li><li><strong>使用步骤</strong>：之前的常规内容，有了前面的铺垫，这一部分可以尽可能简化，只需要步骤即可。</li></ol><p>大家有什么其他的建议也可以一块来讨论一下。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近打算把 Kube-OVN 的文档整理一遍，同时思考怎样的文档规范能尽可能做到：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;降低 Maintainer 的维护成本（用户看完文档后不会再去找 Maintainer ）。&lt;/li&gt;
&lt;li&gt;能够充分复用（不看文档的人找过来可以直接甩文档）。&lt;</summary>
      
    
    
    
    
    <category term="opensource" scheme="http://oilbeater.com/tags/opensource/"/>
    
    <category term="documents" scheme="http://oilbeater.com/tags/documents/"/>
    
  </entry>
  
  <entry>
    <title>Kube-OVN 是如何自动修复 CVE 的</title>
    <link href="http://oilbeater.com/2025/06/28/kube-ovn-autoupdate/"/>
    <id>http://oilbeater.com/2025/06/28/kube-ovn-autoupdate/</id>
    <published>2025-06-28T00:02:21.000Z</published>
    <updated>2025-12-01T03:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这篇博客是内部分享的一个提示文稿，并没有做仔细整理，大体思路就是捕获所有 Kube-OVN 的依赖：操作系统，Golang，程序依赖，环境组件（k8s,kubevirt 等），然后激进的实时更新所有依赖做到动态清零。</p></blockquote><p>Kube-OVN CVEs 问题修复的流程经历了如下几个阶段：</p><ul><li>发版&#x2F;按需统一进行手动修复</li><li>每次 commit 检测可修复安全漏洞，手动进行修复</li><li>master 依赖自动更新，发版分支部分依赖自动更新，少量手动修复</li><li>未来目标：所有依赖自动更新，避免手动修复</li></ul><h2 id="按需修复"><a href="#按需修复" class="headerlink" title="按需修复"></a>按需修复</h2><p>优势：</p><ul><li>相比每个安全漏洞单独修复，整体修复频次低<br>劣势：</li><li>发版集中修复，研发还要兼顾发版期间赶进度，测试，bug 修复，时间压力大</li><li>依赖更新没有经过日常验证，存在未知的风险</li><li>大部分安全修复工作没有实际意义还需要花费人工精力</li></ul><h2 id="每次-Commit-检测修复"><a href="#每次-Commit-检测修复" class="headerlink" title="每次 Commit 检测修复"></a>每次 Commit 检测修复</h2><p>增加工作：</p><ul><li>流水线增加 trivy 扫描，存在安全问题无法合并代码</li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-x86-image.yaml#L3437">https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-x86-image.yaml#L3437</a></li><li><a href="https://github.com/kubeovn/kube-ovn/actions/runs/15760235247?pr=5376">https://github.com/kubeovn/kube-ovn/actions/runs/15760235247?pr=5376</a></li></ul><p>优势：</p><ul><li>将 CVE 修复打散到平时，发版时时间压力较低</li><li>可以快速发版</li><li>大部分依赖更新已经得到了日常自动化测试的验证，风险也较低<br>劣势：</li><li>最后一次提交和发版扫描之间存在时间差，理论上会遗漏一部分 CVE</li><li>会干扰平时正常功能提交，bug 修复，提交经常因为不相关的 CVE 问题被阻塞</li><li>大量的手动修复</li></ul><h2 id="所有依赖自动更新"><a href="#所有依赖自动更新" class="headerlink" title="所有依赖自动更新"></a>所有依赖自动更新</h2><p>只要依赖更新版本就尝试更新，不考虑是否是安全更新。尝试解决比 CVE 修复更大的一个问题，自动就解决了 CVE 问题的修复。</p><p>我们的依赖项：</p><ul><li>OS 镜像及其依赖：<code>ubuntu:24.04</code>, <code>apt-get install ....</code></li><li>Go 语言版本，以及代码依赖库</li><li>上游依赖：<code>OVS</code>, <code>OVN</code></li><li>其他协作组件依赖： <code>kubernetes</code>, <code>kubevirt</code>,<code>multus</code>, <code>metallb</code>, <code>cilium</code>, <code>talos</code></li><li>采用比较激进的更新策略，依赖大版本更新我们也会尝试更新</li></ul><p>要做的事情：</p><ul><li>OS 镜像部分增加流水线每天重新构建，自动修复 OS 和 apt 库里解决的问题<ul><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-kube-ovn-base.yaml">https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-kube-ovn-base.yaml</a></li><li>每日自动无需人工干预</li></ul></li><li>Go 相关使用 renovate 进行自动更新<ul><li>Go 版本，<code>go.mod</code> 里的所有依赖版本</li><li>实时更新 + auto merge</li><li>出现合并问题手动处理</li><li><a href="https://github.com/kubeovn/kube-ovn/pull/5354">https://github.com/kubeovn/kube-ovn/pull/5354</a></li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/renovate.json">https://github.com/kubeovn/kube-ovn/blob/master/renovate.json</a></li><li>不需要特殊配置，按照 renovate 自动检测流程来即可</li></ul></li><li>上游组件依赖<ul><li>OVS OVN 每日构建，策略更激进直接从上游分支构建，上游不发版我们也会更新</li><li>相信上游都是 bugfix，我们这样可以增强稳定性</li></ul></li><li>其他组件<ul><li>使用 renovate 的自定义正则匹配，Dockerfile, Makefile, Action 里所有依赖软件版本自动更新</li><li><a href="https://github.com/kubeovn/kube-ovn/issues/5291">https://github.com/kubeovn/kube-ovn/issues/5291</a></li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/Makefile">https://github.com/kubeovn/kube-ovn/blob/master/Makefile</a></li></ul></li></ul><p>优点：</p><ul><li>大部分 CVE 会在不知道情况下被修复，少量可在一天内自动修复，特殊情况再手动修复</li><li>大量上游的 bugfix，性能提升和新功能被自动合入，软件整体稳定性提升</li><li>大量的版本适配验证工作，如 k8s 版本更新，KubeVirt 版本更新的适配验证也都自动进行，风险提前知晓</li><li>人工干预量较少</li></ul><p>劣势：</p><ul><li>依赖更新多比较吵，需要设置聚合策略</li><li>更新量太大无法人工测试，需要有自动化测试保证</li><li>需要积极适配上游版本变化</li><li>存在上游新版本不稳定风险，目前两年内遇到过两次</li></ul><h2 id="renovate-相比-dependabot-优势"><a href="#renovate-相比-dependabot-优势" class="headerlink" title="renovate 相比 dependabot 优势"></a>renovate 相比 dependabot 优势</h2><ul><li>可以自定义依赖捕获，Dockerfile、Makefile 里的非标准依赖可以捕获</li><li>可以在非 master 分支运行</li><li>有 auto merge 能力</li><li></li></ul><h2 id="还未解决的问题"><a href="#还未解决的问题" class="headerlink" title="还未解决的问题"></a>还未解决的问题</h2><ul><li>自动化测试误报导致无法自动合并</li><li>已发版分支的 Go 相关更新还未自动化<ul><li>renovate 的 security-only 策略效果还未知</li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/renovate.json#L45">https://github.com/kubeovn/kube-ovn/blob/master/renovate.json#L45</a></li><li>发版分支可能需要重新定义策略</li></ul></li><li>部分依赖还没有自动更新</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这篇博客是内部分享的一个提示文稿，并没有做仔细整理，大体思路就是捕获所有 Kube-OVN 的依赖：操作系统，Golang，程序依赖，环境组件（k8s,kubevirt 等），然后激进的实时更新所有依赖做到动态清零。&lt;/p&gt;
&lt;/blockquot</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>关于培训</title>
    <link href="http://oilbeater.com/2025/05/24/about-training/"/>
    <id>http://oilbeater.com/2025/05/24/about-training/</id>
    <published>2025-05-24T10:40:04.000Z</published>
    <updated>2025-12-01T03:30:38.489Z</updated>
    
    <content type="html"><![CDATA[<p>这两天接了个 Kube-OVN 培训的任务，事实上这已经是这几年第三次给这家公司培训相同的内容了，形式也从线上转到线下还要求手把手的敲命令，可想而知之前几次的最终效果怎样。我可以理解需求方的技术焦虑，但我认为培训这种形式是极其低效的，更多的只是培训当时能获得一些虚假的满足感，不会产生什么长期收益。</p><p>一方面培训是一种被动学习方式，完全由老师带节奏前进，那听讲的人只是被动的吸收，很难有深度的思考。另一方面需要等到培训才了解的知识大概率是实际上用不到的知识，如果每天都用的话根本来不及等这种一年一次的培训。如果实际用不到，那么哪怕当场掌握了，很快也会什么都剩不下。</p><p>我觉得这和我们一直以来的教育理念有些关系，传统上我们认为认真听老师讲课，努力记笔记，不会的问题堵着老师问，都是优秀的学习习惯。但这些都是偏被动的学习方法，我们很多年的教育过程中其实缺乏主动学习的机会。这种被动的方式早期的效果可能会很好，因为早期学校里的知识难度不大，而且我们展示学习成果的方式就是考试，而考试是可以通过过拟合的方式来提升效果的，并不能真正反映你对知识的掌握程度。</p><p>在我的经历里，到了初中阶段，最出色的那批人就不再是认真听课，努力记笔记那批人了。而是换成了那批给人感觉平时一直玩，考试成绩还很好的一批人，事实上越往后这批人的比例越高。我认为这里并不是智商的区别而是被动学习和主动学习模式的区别。主动学习的人会更多依赖自己思考来解决问题，而不是依赖老师的讲解，这个方法看似低效其实最终效果会更好。想象一下同样一道题，一个人是老师之前讲过所以考试的时候做出来了，另一个人是上课没听到但是考试的时候临场也做出来了。从考试的结果来说两个人是一样的，但两个人的实际能力是天差地别的。后者实际上拥有更好的学习方法和能力，并且在更难的问题上有更好的泛化能力，自然可以显得游刃有余。就好比前者一直在用冒泡算法去排序，后者则是不断用快排，在小规模上前者可能更简单更不容易出错，效果会比后者好，但是后者一旦调整好了，在更大规模的数据上会有指数级别的优势。</p><p>这也是为什么有些转行的程序员的表现会比科班的表现好。一方面他们采用的是主动学习这种高速方法，另一方面科班的被动学习学到的大量都是实际中毫无用处的知识，两者的基础差距本身就没那么大，用一个更高速的方法很容易短期就实现超越。</p><p>所以还是要主动学习，学点有用的。（不要再折腾供应商搞什么高级培训了</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这两天接了个 Kube-OVN 培训的任务，事实上这已经是这几年第三次给这家公司培训相同的内容了，形式也从线上转到线下还要求手把手的敲命令，可想而知之前几次的最终效果怎样。我可以理解需求方的技术焦虑，但我认为培训这种形式是极其低效的，更多的只是培训当时能获得一些虚假的满足感</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>如何超越 OpenShift</title>
    <link href="http://oilbeater.com/2025/04/23/surpass-openshift/"/>
    <id>http://oilbeater.com/2025/04/23/surpass-openshift/</id>
    <published>2025-04-23T10:40:43.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>OpenShift 作为容器平台的标杆产品，同时也是开源商业化的标杆，一直是被人试图追赶或者超越的对象。但是如果只是照着 OpenShift 的产品模仿，那么当追上 OpenShift 时只可能有一种情况，那就是 OpenShift 停止发展，过了一年后你终于追上了，然后会因同样原因被淘汰。</p><p>那么有没有什么方法能够追上甚至超越 OpenShift 呢？我认为要从 OpenShift 本身商业模式的选择和技术路线上的选择入手，从他们在这种选择下不可避免的缺点入手，做出差异化，才有超越的可能。</p><h2 id="OpenShift-并不-Open"><a href="#OpenShift-并不-Open" class="headerlink" title="OpenShift 并不 Open"></a>OpenShift 并不 Open</h2><p>OpenShift 里的 Open 可能和 OpenAI 里的 Open 是同一个 Open。如果你尝试不通过 RedHat 的销售自己去部署一套 OpenShift 就会知道我在说什么了。</p><p>OpenShift 的所有组件确实是开源的，但如果你是一个纯粹的社区用户会步步受挫。一个功能你可能找不到对应组件，找到组件可能找不到对应源码，找到源码又没有文档指导如何编译使用。这些现象在那些完全是 OpenShift 自己使用的组件里已经见怪不怪了。大概 OpenShift 这部分的社区只是对客户和合作伙伴开放的。</p><p>而对于那些非 OpenShift 专属的组件，OpenShift 采取的策略会是一旦选择就大举投入，争取到对应组件的社区的主导权。所以会看到的一个现象是有些社区很出名的项目 OpenShift 的人完全不投入，而一个项目在平稳发展了几年后会突然涌入大量 OpenShift 的人。</p><p>这些都是 OpenShift 在商业化与开源之间权衡后的选择，并没有对错之分，但这会给更开放的项目留出机会。如果新的产品能够降低参与门槛，收取更广泛的反馈，让更多的贡献者来参与创新，那么我认为它的上限将会超越 OpenShift。</p><h2 id="OpenShift-的技术并不先进"><a href="#OpenShift-的技术并不先进" class="headerlink" title="OpenShift 的技术并不先进"></a>OpenShift 的技术并不先进</h2><p>受限于第一点因素，OpenShift 并不能广泛的吸收整个生态的最新成果。在生态内某个组件和 OpenShift 专属的组件功能重叠情况下，OpenShift 内部的研发人员是很难有动力切换到另一个社区或者另一个公司主导的开源组件。</p><p>以我比较了解的网络为例，OpenShift 早期通过 Haproxy 实现了 Route 来打通集群外访问集群内的流量。在当时 Ingress 还不成熟，Route 是一个相比社区先进的多的方案，OpenShift 的方案在当时是绝对领先的。但是随着 Ingress 的成熟，社区生态内各种网关都在飞速发展，而 OpenShift 受限于自己早期的实现和用户用法很长时间都没有去支持 Ingress 这个在社区已经标准化的功能。现阶段 Ingress 规范已经进化到 GatewayAPI 有一段时间了，大量 AI Gateway 的新场景都在通过 GatewayAPI 进行扩展，而 OpenShift 现如今还没有支持 GatewayAPI，最近正在计划在之前的 Haproxy 上同时支持 Route，Ingress 和 GatewayAPI。</p><p>类似的案例在 OpenShift 内还有很多，早期可能还是一个优秀的方案，但由于 OpenShift 专属导致不开放，随着社区的发展，原先优势的方案反而变成了阻碍前进的障碍。就像现在在 Kubernetes 上做 Ingress Gateway 不会有人去参考 OpenShift 的实现，在很多细分领域 OpenShift 已经并不是最先进的解决方案了，尤其是在那些由 OpenShift 专属组件提供服务的领域。现在的 OpenShift 在我看来就是一个覆盖面积很广，但平庸且无趣的平台。</p><p>容器平台的生产过程其实和手机的生产很像，都是从成百上千个供应链供应商那里选择需要的配件，然后组装成一个成品。如果能够保持开放，选择供应链上最先进的那些配件，或者根据场景快速组合出一个针对特定场景的产品，那么在技术竞争力上应该会远超 OpenShift。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>要想真正追赶甚至超越 OpenShift，关键不是在已有功能上亦步亦趋，而是要做到更开放、更领先。这样才能摆脱追随者路径，真正形成对 OpenShift 的差异化优势，成为下一轮技术浪潮的主导者。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;OpenShift 作为容器平台的标杆产品，同时也是开源商业化的标杆，一直是被人试图追赶或者超越的对象。但是如果只是照着 OpenShift 的产品模仿，那么当追上 OpenShift 时只可能有一种情况，那就是 OpenShift 停止发展，过了一年后你终于追上了，然后会</summary>
      
    
    
    
    
    <category term="OpenShift" scheme="http://oilbeater.com/tags/OpenShift/"/>
    
    <category term="Product" scheme="http://oilbeater.com/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>DeepSeek MLA -- 为成本优化而生的注意力机制</title>
    <link href="http://oilbeater.com/2025/04/14/deepseek-mla/"/>
    <id>http://oilbeater.com/2025/04/14/deepseek-mla/</id>
    <published>2025-04-14T17:10:03.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>DeepSeek 第一次出名是因为 DeepSeek V2 做到了一百万 Token 只要 0.14 美元。同期的 GPT-4 是 30 美元，当时被认为极具性价比的 GPT-3.5 也要 1.5 美元。这个突破性价格的出现在国内引发了一轮价格战，大批大厂模型大幅降价甚至免费。然而和其他大厂烧钱补贴的逻辑不同，DeepSeek 是通过一系列的技术创新实现了成本数量级的下降。这篇文章就来介绍一下这背后最关键的一个技术创新 —— MLA(Multi-Head Latent Attention)。</p><p>MLA 最本质的数学技巧并不复杂，论文里也是一段话就说完了，看完让人感叹竟然还有如此精妙的解法。但是由于和整个 Transformer 架构耦合会导致理解起来有些困难，我这里会尽量简化描述，哪怕你之前完全不了解 Transformer 应该也可以领会到这个方法的精妙。</p><p>当然还是需要有一些线性代数的基础，如果你还记的一个形状为 5*4 的矩阵乘形状为 4*3 的矩阵，结果是一个形状为 5 * 3 的矩阵就可以继续了。</p><p><img src="/../images/20250414233740.png"></p><h2 id="KVCache"><a href="#KVCache" class="headerlink" title="KVCache"></a>KVCache</h2><p>大模型推理的成本的瓶颈在哪里？答案可能会出乎意料 —— 是显存。显卡有大量计算单元，而推理任务又是线性的一次只能出一个 Token，为了充分利用显卡的计算资源达到最大的吞吐，一般会同时运行尽可能多的生成任务。而每个任务在推理过程中都会占用大量显存，如果想运行尽可能多的任务就需要运行时显存占用足够小。而 MLA 在运行时的显存占用是原始注意力机制的 <strong>6.7%</strong>，你没看错，不是降低了 6.7%，是降低了 <strong>93.3%</strong>。打个比喻这一刀下去不是腰斩，而是脚踝斩。在不考虑模型本身的显存占用情况下，近似可以认为 MLA 在相同显存下可以容纳 <strong>15 倍</strong>的生成任务。</p><p>虽然 MLA 的论文里没有细说这个灵感的来源，但我认为他们是从原先的 KVCache 倒推，诞生了一种全新的注意力机制。到这里就不得不说下 KVCache 是什么。</p><p>大模型每生成一个 Token 都需要对之前所有的 Token 进行计算，来得出最新的一个 Token 是什么。但是一般任务不会生成一个 Token 就结束，往往要一直生成到结束符号，这就会导致前面的 Token 每一次都要重复计算。于是 KVCache 的作用就是把之前每个 Token 计算生成的中间结果保存下来，这样就可以避免重复计算了。你可以理解为每个 Token 都被映射成了一个 1000 * 1000 的矩阵，那么我们有没有什么办法来减少这个矩阵的内存占用呢？</p><p><img src="/../images/20250414234534.png"></p><h2 id="MLA"><a href="#MLA" class="headerlink" title="MLA"></a>MLA</h2><p>这里有意思的事情终于可以开始了，我们可以用两个小矩阵相乘来近似一个大矩阵。这里刚才你还记得的线性代数知识可以用上了，1000 * 2 的矩阵乘一个 2 * 1000 的矩阵也可以得到一个 1000 * 1000 的矩阵，而这两个矩阵总共只有 4000 个元素，是 1000 * 1000 矩阵元素数量的 0.4%。</p><p>这就是 MLA 在数学上最核心的思路了，在 DeepSeek V2 中，本来一个 Token 应该被映射为一个 1*16k 的向量，而在使用 MLA 后会先通过一个压缩矩阵将这个 Token 映射为 1*512 的向量，等到需要的时候再通过一个 512 * 16k 的解压矩阵还原成 1*16k 的向量。在这里压缩矩阵和解压矩阵都是通过训练得来，是模型的一部分只会占用固定的显存，而运行时针对每个 Token 的显存占用就只剩这个  1*512 的向量，只有原来的 3%。</p><p>一个完整的对比如下图所示，原先的 MHA 需要 Cache 完整矩阵，而 MLA 只需要 Cache 中间压缩后的一个向量，再还原出完整矩阵。</p><p><img src="/../images/20250415000024.png"><br><img src="/../images/20250414235538.png"></p><p>这一切真的这么美好嘛？让我们想想 KVCache 的最初目的是什么，是为了减少 Token 的重复中间计算，MLA 虽然压缩了 KVCache，但是每次还需要一个解压操作，计算量又回来了。</p><p>这里就是一个更精彩的故事了，按照 Transformer 的计算，中间的 Cache 乘一个解压矩阵后还要再乘一个输出矩阵得到最终的结果，可以粗略理解为最终计算的公式是 Cache * W<sup>解压</sup>  * W<sup>输出</sup> ，根据矩阵计算的结合率，可以先计算后两个矩阵的乘积，将后两个矩阵融合乘一个新的矩阵。由于 W<sup>解压</sup>  和 W<sup>输出</sup> 在训练后是确定的，因此做个简单的后处理把这部分提前算出来就好了。作者在论文中也用 <strong>Fortunately</strong> 来形容这件事情。</p><p>也就是说我们最初是出于压缩 KVCache 的思路去做了压缩和解压，但在实际推理过程中根本不存在解压的过程。在大幅压缩了显存的同时由于过程中的矩阵都变小了，推理所需的计算量也变小了。</p><h2 id="模型能力"><a href="#模型能力" class="headerlink" title="模型能力"></a>模型能力</h2><p>但在这里我其实还有个疑问没有解开，本质上 MLA 是用两个小矩阵相乘得到一个大矩阵，但是并不是所有的大矩阵都能完美分解成两个小矩阵。MLA 实际的搜索空间是小于 MHA 的，理论上来讲 MLA 的模型能力应该更弱。但是按照 DeepSeek 论文里的评测，MLA 的模型能力是要略强于 MHA 的。</p><p><img src="/../images/20250415003909.png"></p><p>这个事情其实就不太好理解了，我倾向于认为 MLA 虽然搜索空间降低了，但是最优解的概率反而变大了，收敛到了一个相比 MHA 更优的解。另外虽然 MLA 的优化是从 MHA 出发，但最终的结果其实是一套全新的注意力机制，模型的架构都发生了很大的变化，或许 DeepSeek 真的发现了一个更有效的注意力机制。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>有不少性能优化方案其实是在玩跷跷板游戏，比如用 GPU 计算时间交换显存空间，或者牺牲模型能力来换成本下降。而 MLA 在把显存打脚踝斩的情况下同时还做到了计算需求下降和模型能力提升，简直匪夷所思。</p><p>另一个感触是在经历了国内移动互联网时代的我们很容易认为价格战就是要赔本赚吆喝，却忘了技术创新才应该是那个最大的杠杆。</p><blockquote><p>这篇博客只是介绍了 MLA 最核心的理念，在实际应用中还有很多具体的问题，例如：如何处理旋转位置编码？K 和 V 的解压矩阵融合其实略有不同，一个是直接应用结合律，一个是转置后再结合，等等。还是建议大家阅读 DeepSeek V2 的原始论文，有这篇文章做基础应该容易理解很多。</p><p>博客里部分图片源自 <a href="https://www.bilibili.com/video/BV1BYXRYWEMj/">DeepSeek-v2 MLA 原理讲解</a>,也建议大家看下这个视频。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;DeepSeek 第一次出名是因为 DeepSeek V2 做到了一百万 Token 只要 0.14 美元。同期的 GPT-4 是 30 美元，当时被认为极具性价比的 GPT-3.5 也要 1.5 美元。这个突破性价格的出现在国内引发了一轮价格战，大批大厂模型大幅降价甚至免</summary>
      
    
    
    
    
    <category term="DeepSeek" scheme="http://oilbeater.com/tags/DeepSeek/"/>
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Paper" scheme="http://oilbeater.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>混乱的 Llama 4</title>
    <link href="http://oilbeater.com/2025/04/06/llama-4-chaos/"/>
    <id>http://oilbeater.com/2025/04/06/llama-4-chaos/</id>
    <published>2025-04-06T15:57:23.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间 Meta AI 的负责人离职让人怀疑 Llama 4 的进度出现了问题，结果没过两天 Meta 就发布了 Llama 4，似乎是为了打破传言。然而看完了现在已经公布的模型基础信息，我反而更觉得 Llama 项目内部已经极度混乱了。下面是我根据已有信息的分析，欢迎指正。</p><h2 id="模型基础信息"><a href="#模型基础信息" class="headerlink" title="模型基础信息"></a>模型基础信息</h2><p>Llama 这次正式发布了一个 109B 和 一个 400B 参数量的模型，以及一个未发布的 2T 参数量模型的信息，我把关键的架构信息汇总如下，以下信息均来自 Llama 自己的博客和 huggingface 模型页面：</p><table><thead><tr><th>名称</th><th>参数量</th><th>激活参数量</th><th>专家数</th><th>上下文</th><th>语料量</th><th>GPU 时间</th></tr></thead><tbody><tr><td>Scout</td><td>109B</td><td>17B</td><td>16</td><td>10M</td><td>40T</td><td>5.0M</td></tr><tr><td>Maverick</td><td>400B</td><td>17B</td><td>128+1</td><td>1M</td><td>22T</td><td>2.38M</td></tr><tr><td>Behemoth</td><td>2T</td><td>288B</td><td>16</td><td>-</td><td>-</td><td>-</td></tr></tbody></table><p>这里都不用再看模型的评分表现了，这几个模型架构方面的对比就能看出很多问题了。</p><h2 id="奇怪的-MoE-架构"><a href="#奇怪的-MoE-架构" class="headerlink" title="奇怪的 MoE 架构"></a>奇怪的 MoE 架构</h2><p>Llama 4 这次从 Dense 模型全面转向了 MoE，但是诡异的点在于他们三个模型采用了两套 MoE 架构。最大的 Behemoth 和最小的 Scout 采用的是传统的 MoE，专家数也是 16 这个传统认为比较常规的一个专家数量，而中间的那个 Maverick 采用的却是 DeepSeek MoE 提出的一个新的细粒度专家加共享专家的模型是个 128 专家加 1 共享专家的架构。</p><p>一般来说一代模型都是采用同一个架构，只是在模型的层数和每层的宽度上做调整，两个有很大差异的模型在同一代就很奇怪。而且就算有变化也不应该是最大和最小的保持一致，把中间规模的给换了，给人的感觉是中间的这个 Maverick 其实是被 DeepSeek 冲击下重新仿照 DeepSeek 模型重新训练的，但是时间上来不及把三个都重做，只好就放在一块发布了。</p><h2 id="奇怪的成本投入"><a href="#奇怪的成本投入" class="headerlink" title="奇怪的成本投入"></a>奇怪的成本投入</h2><p>一般来讲，模型参数规模越大，需要投入的成本越高。一方面是更大的模型可以容纳更多的知识，会提供给更大规模模型更多的语料；另一方在语料相同的情况下，更大的模型需要训练的参数更多 GPU 开销也会更高。所以通常来讲模型规模越大，需要的成本会越高。</p><p>然而到了 Llama 4 这里出现了两个指标都相反的情况。Maverick 的参数规模是 Scout 的接近 4 倍，但是 Maverick 训练的语料量只有 Scout 的二分之一，消耗的 GPU 时间同样也只有二分之一。考虑到这两个模型的激活参数量是一致的这个 GPU 时间可以理解，但是语料量也只给一半这个事情就很奇怪了。给我的感觉是要么这次只是试水新型的 MoE 架构，并没有想做完整训练，要么就是训到后面训崩了，从中间那个 snapshot 出来了。</p><h2 id="奇怪的上下文长度"><a href="#奇怪的上下文长度" class="headerlink" title="奇怪的上下文长度"></a>奇怪的上下文长度</h2><p>一般来讲更大的模型，能力会越强。可在这一代 Llama，最让人感到震撼的 10M 上下文是给的最小规模的 Scout，更大的 Maverick 反而是 1M 上下文。考虑到目前扩充上下文的主流方法还是在后训练做微调，更大的 Maverick 在后训练的投入上还不如更小的 Scout。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>给我的感觉是 Llama 4 这一代本来是想走传统 MoE，被 DeepSeek 冲击后又半路开始看 DeepSeek MoE。但是训练可能已经开始了，停下来又有阻力，所以中间又插了一个中规模的 Maverick。按照这个参数量选择来看是想用比 DeepSeek V3 小的参数量实现类似的性能。但是 17B 的激活要追平 DeepSeek V3 的 39B 激活我觉得还是有很大难度的。不过最后能让这一代的模型以这么混乱的形式发布，还加了个期货模型，我还是觉得 Llama 项目内部出了不少的问题。</p><p><img src="/../images/llama4.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前段时间 Meta AI 的负责人离职让人怀疑 Llama 4 的进度出现了问题，结果没过两天 Meta 就发布了 Llama 4，似乎是为了打破传言。然而看完了现在已经公布的模型基础信息，我反而更觉得 Llama 项目内部已经极度混乱了。下面是我根据已有信息的分析，欢迎指</summary>
      
    
    
    
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Llama" scheme="http://oilbeater.com/tags/Llama/"/>
    
  </entry>
  
  <entry>
    <title>DeepSeek MoE -- 创新型的 MoE 架构</title>
    <link href="http://oilbeater.com/2025/03/29/deepseek-moe/"/>
    <id>http://oilbeater.com/2025/03/29/deepseek-moe/</id>
    <published>2025-03-29T12:54:37.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>从 DeepSeek V3&#x2F;R1 开始关注 DeepSeek 工作的人很容易认为 DeepSeek 大量的工作都是在工程上优化效率，但是回看 DeepSeek 过去一年的论文才会发现他们其实一直在模型架构和训练方法上做各种创新，而 V3 和 R1 只是在之前架构创新的基础上进行 Scale。DeepSeek MoE 这篇论文就介绍了 DeepSeek 在 MoE 架构上的主要创新，现在看上去也很有希望成为未来 MoE 架构的标准。</p><h2 id="MoE-vs-Dense"><a href="#MoE-vs-Dense" class="headerlink" title="MoE vs Dense"></a>MoE vs Dense</h2><p>先说一下 MoE 和传统的 Dense 架构的区别。早期的 LLM 基本都是 Dense 架构，也就是每生成一个 Token 需要激活所有的神经元参与计算，这种方式其实和人脑的思考方式是有很大区别的，人脑是不会任何问题都需要调动所有脑细胞的，如果这样的话人早就累死了。所以很自然的一个想法就是生成 Token 的时候不要再激活所有的神经元了，每次只激活和当前任务最相关的神经元，于是就有了 MoE(Mixture of Experts) 架构，把 LLM 里每一层的神经元分割成 N 个 Expert，通过 Router 去选择 K 个最相关的 Expert 激活。</p><p><img src="/../images/20250329161016.png"></p><p>这个架构的好处就是在推理的时候不需要激活所有的神经元，计算量会大幅下降。在 DeepSeek MoE 前最常见的 8 选 2 模式下计算量可以下降到接近 Dense 模型的三分之一。</p><p>MoE 的架构看上去很理想，但本质上是在用少量 Experts 来模拟 Dense 模型的表现，所以关键是在每个 Expert 是否有足够的专业性，能否真的模拟 Dense 模型的表现。如果类比人脑，当神经元足够特化时，特定任务只需要激活少量神经元即可完成。</p><p>DeepSeek MoE 这篇论文就介绍了他们为了把每个 Expert 专业性推到极致所做的两个创新：</p><ul><li>更多更小的 Expert</li><li>知识共享 Expert</li></ul><h2 id="更多更小的-Expert"><a href="#更多更小的-Expert" class="headerlink" title="更多更小的 Expert"></a>更多更小的 Expert</h2><p><img src="/../images/20250329165838.png"></p><p>使用更多更小的 Expert 来增加每个 Expert 的专业性看似是个很符合直观的思路，但是之前主流 MoE 都是 8 个或者 16 个 Expert。可以想象 LLM 要处理的问题类型千千万，这个数量规模的 Expert 显然不可能做到高度的专业化，每个 Expert 都会有大量当前任务无关的知识。</p><p>但是随着 Expert 的数量变大，训练的难度也会变大，Router 很容易只选择少数几个 Expert 导致负载的极度不均衡。最终，理论上的 MoE 架构可能会变成每次只激活同一组 Expert 的小模型。因此，之前大部分 MoE 架构的 Expert 数量都不会太多。</p><p>DeepSeek 经过一组设计的损失函数，给重复选择同一个 Expert 增加了惩罚，从而迫使 Router 更均衡的去选择 Expert。通过这个方式 DeepSeek 解决了训练的问题，开始一步步尝试 scale Expert 的数量。从这篇论文里的 64 选 6，扩展到 128 选 12，到 V2 的 160 选 6，再到 V3 的 256 选 8。</p><p>可以看到 DeepSeek 一步步将 Expert 数量扩展，而且所需要选中的 Expert 比例也从 9% 一步步降低到 2%，证明了确实在 Expert 足够专业化后只需要更少部分的激活就可以完成对应的任务。</p><h2 id="知识共享-Expert"><a href="#知识共享-Expert" class="headerlink" title="知识共享 Expert"></a>知识共享 Expert</h2><p><img src="/../images/20250329170955.png"></p><p>随着 Expert 变小和 Expert 数量增加其实还会带来另外一个问题，那就是每个 Expert 除了需要特定领域的知识外，其实还需要一些通用知识，例如一些通用的语言理解和逻辑分析，可能是每个 Expert 都需要的。如果每个 Expert 都记忆了相关知识那么其实会造成大量的知识冗余，当 Expert 数量变多时，问题会更加明显。这其实会限制每个 Expert 的专业化，训练和推理过程中也会造成资源的浪费。</p><p>DeepSeek 提出的做法是增加一组共享 Expert，这一组 Expert 每个训练样本都会被激活，希望他们在训练过程中可以学到通用的知识，这样其他的 Expert 就无需再去学习这些通用知识，只需要学习专业知识了。当推理过程中这组共享 Expert 也会每次都被激活，来提供通用的知识信息。</p><p>这同样是一个很符合直觉的架构创新，但是由于之前 MoE 架构的 Expert 规模本来就不大，这个优化的意义其实并不明显，只有当规模上去了这个问题才会暴露出来。在这篇论文里 DeepSeek 还根据 Expert 数量按比例扩充了共享型 Expert 数量，但是随着更多的训练和实践，发现其实并不需要那么多共享型 Expert，等到 V3 的时候其实只使用到了 1 个共享型 Expert。</p><h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>看完这篇论文我最大的感受是 DeepSeek 并不是拿一个已经验证过的架构无脑堆数据，而是真正的在做模型层面的创新。这也导致在 V3&#x2F;R1 大火之后很多框架第一时间都无法运行 DeepSeek 的模型或者性能也很差，因为 DeepSeek 的模型架构和其他人都有明显的差别。</p><p>并且相比 DeepSeek 其他论文里提到的 MLA、GRPO 和 NSA 这些需要复杂数学功底的创新不同，这两个模型创新都还是相对符合直觉的，但在那个时间点只有 DeepSeek 敢于这么尝试，其他人还在 Follow Llama 的 Dense 模型，敢于去做非主流的尝试，还是需要很大的勇气，这里只能对 DeepSeek 团队再次表达 Respect。</p><p><img src="/../images/20250329200735.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从 DeepSeek V3&amp;#x2F;R1 开始关注 DeepSeek 工作的人很容易认为 DeepSeek 大量的工作都是在工程上优化效率，但是回看 DeepSeek 过去一年的论文才会发现他们其实一直在模型架构和训练方法上做各种创新，而 V3 和 R1 只是在之前架构创</summary>
      
    
    
    
    
    <category term="DeepSeek" scheme="http://oilbeater.com/tags/DeepSeek/"/>
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Paper" scheme="http://oilbeater.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>从 DeepSeek LLM 到 DeepSeek R1 —— DeepSeek LLM</title>
    <link href="http://oilbeater.com/2025/03/14/deepseek-from-llm-to-r1/"/>
    <id>http://oilbeater.com/2025/03/14/deepseek-from-llm-to-r1/</id>
    <published>2025-03-14T10:48:50.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>最近找到了 DeepSeek 发表过的论文合集，包含了从 DeepSeek 第一版的 LLM 到最新的 R1 的演变过程。从当下的角度我们当然知道 DeepSeek R1 在模型能力上已经接近了业界最领先的水平，但他是如何一步步从一个在中国一开始都没有被重视的量化公司走到这里的其实更吸引我的注意。</p><p>这个系列的博客我会从论文阅读的角度，试图去寻找他们一步步探索的轨迹，从论文的路径上来看就是 DeepSeek LLM -&gt; DeepSeek MoE -&gt; DeepSeek V2 -&gt; DeepSeek V3 -&gt; DeepSeek R1。在整理论文时我才发现，DeepSeek 第一篇对外发布的论文是在 2024 年的 1 月，当时他们刚发布第一版模型，即使在 AI 行业内也不被认为是个主要竞争者。然而仅仅一年后的 2025 年 1 月，就已经进化到了 R1 这种业界领先水平。都说 AI 一天，人间一年，但是当真看到人间一年的进展时，还是深深的被 DeepSeek 的速度所震撼。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>DeepSeek LLM 是 DeepSeek 开源的第一个 LLM，当时开源 LLM 里最受关注的是 LLaMA-2，很多模型也是基于它的架构和基础进行的。现在从后视的角度我们知道 DeepSeek 最终选择了和 LLaMA 这类 Dense 架构不同的 MoE 架构，但是在当时第一版的时候还是基本上照搬了 LLaMA-2 的架构，进行局部的调整。可以猜测当时团队内部还处于探索模型架构的阶段。</p><p>尽管架构大体和 LLaMA-2 相同，训练的数据量也都是 2T tokens，但是在性能评测上，如下图所示 DeepSeek LLM 基本上是全面超越了 LLaMA-2。论文里介绍了他们发现的一些有趣的关于数据，训练和微调的方法。</p><p><img src="/../images/deepseekllm.png" alt="alt text"></p><p>值得注意的是 DeepSeek 在训练过程中是可以使用更多的数据，使用更大参数量的模型的，显然这样做会提升模型性能。但是这篇论文目的主要是和 LLaMA-2 对比，因此特意把数据规模和参数量都做到尽可能相近，来比较在其他方面还有哪些地方可以提升。</p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>LLaMA-2 和 DeepSeek LLM 在数据的选择上还是有很大的区别的。虽然都是 2T 的 token 量，LLaMA-2 里接近 90% 的语料都是英文，而 DeepSeek LLM 虽然没有详细说语言的比例，但是看表述语料里的英文和中文比例应该是比较接近的。所以逻辑上来看 DeepSeek LLM 在中文的评测上大幅领先并不是个意外。意外的反而是在英文评测指标上，DeepSeek LLM 在训练量明显少的情况下依然取得了接近的性能结果。</p><p>我猜测这种现象的原因有两个，第一是 DeepSeek LLM 的语料质量更高，弥补了数量上的劣势。LLaMA-2 在介绍预训练语料的时候说除了一些敏感信息没有对数据集进行过滤，而 DeepSeek LLM 中介绍了为了提高数据质量专门做了模型去评估数据质量，还特意把一些冷门领域的数据占比放大，已获得更好的数据多样性。因此可以推测英文部分的语料质量 DeepSeek LLM 要高一些。作为参考 LLaMA-3 也在数据准备过程中引入了去重和质量过滤来提升语料的质量。</p><p>另一个原因我猜大概是中文语料的引入也提升了模型最终在英文上的表现。OpenAI GPT 3.5 的时候训练语料也是英文为主，但是最终在中文的表现上不差，一个猜测的原因就是在英文语料上学习到的一些知识迁移到了中文。同样中文语料里学习到的一些知识也可以迁移到英文。此外由于中文和英文在语法和表现形式上也有比较大的区别，这种多样化的数据是不是一定程度上也提升了模型的能力？还有就是不同语言本身就有不同的文化背景和内容倾向，这其实也是进一步增加了数据的多样性。如果这个猜测成立的话，那准备语料其实应该刻意地去增加不同语言的比重，让模型可以学习更丰富的语言表达形式。</p><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>模型的架构层面 DeepSeek LLM 和 LLaMA-2 几乎完全一样，各个路径上用到的技术比如 Pre-Norm，FFN 的激活函数，位置编码器都一模一样。最大的区别在于使用 GQA（Group<br>Query Attention）上。GQA 相比最原始的 MHA（Multi Head Attention），可以理解为为了节省训练和推理的 kv cache 占用，直接让多个 Query 头共享一组 Key 和 Value 的参数矩阵，这样可以大幅压缩显存的使用。但是带来的问题就是减少了 Key 和 Value 的潜空间个数，模型的表达能力也出现了下降。LLaMA-2 的做法是通过增加 FFN 网络的宽度来提供更多的非线性表达能力，而 DeepSeek LLM 的做法是增加 Attention 的层数。可以粗略理解尽管模型参数量相同，但是 LLaMA-2 是一个更宽的模型，而 DeepSeek LLM 是一个更深的模型。当然从后视的角度来看，DeepSeek 后续在 V2 公布的 MLA 对 Attention 层做了一个极其激进的更新，直接把推理所需的 KV Cache 降低了一个数量级。</p><p>另一个区别在于 LLaMA-2 使用的是 cosine learning scheduler 而 DeepSeek LLM 使用的是 Multi-Step learning scheduler。给出的理由是当增加数据量的时候，Multi-Step 可以更好的利用前一阶段的结果，持续训练速度会更快。</p><p>此外论文里还花了很大篇幅来介绍如何在不同的数据规模，数据质量，模型规模下选择合适的超参，如何去画 scaling law 曲线。这块是作者当成最大亮点来讲的，但是我看上去感觉和炼丹一样，看的我脑壳疼，感兴趣的同学可以自己看看。</p><h2 id="后训练"><a href="#后训练" class="headerlink" title="后训练"></a>后训练</h2><p>在论文发表的那个时间点，后训练主要是做对齐，也就是通过 SFT 和 RLHF 来对齐人类的偏好，增加模型的安全性。用到的数据基本上也都是一些带标记的对话文本，并没有对数据的分布做特别的处理。DeepSeek LLM 在这里对数据的选择又做出了和 LLaMA-2 很不一样的选择。</p><p>如果看最上面模型性能评估的对比图，可以看到 DeepSeek LLM 在 MATH，HumanEval 和 MBPP 几个非中文的指标表现也要好很多。因为 DeepSeek 在后训练的 SFT 阶段将近 70% 的样本都是 Math 和 Code 相关数据。可见他们根本就没把对齐作为后训练的重点，而是把提升模型能力作为后训练的重点，所以这更像是一个鸡贼的刷榜优化。</p><p>当时主流的做法还是在 base model 训练好了后再 SFT 一个代码和数学领域的模型，比如 Code LLaMA  和 OpenAI Codex 是分别在 LLaMA-2 和 OpenAI GPT3 上 SFT 出来的。Meta 当时甚至还在 Code LLaMA 上再 SFT 一个 Python 专用的 LLM 出来。</p><p>现在我们当然知道在后训练阶段通过在 Math 和 Code 样本上进行 RL 可以激发出模型 CoT 的推理能力，R1 的想法可能在这个时候就已经诞生了。</p><p>此外 DeepSeek LLM 在这里并没有用当时很流行的 RLHF，而是选择 DPO(Direct Preference Optimization) 进行和人类偏好的对齐。这种方法直接对两个不同生成结果的概率差作为优化目标进行训练，这相比 RL 其实更直观也更容易设计，在 LLaMA-3 的后训练过程中也用到了 DPO。可以看出 DeepSeek 团队当时对已有的 RL 算法还是不太满意的，还在探索。这也就造就了后来在 DeepSeek Math 中公布的 GRPO。 </p><h2 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h2><p>在我上学的时候，老师和我说真正的 Future Work 不要写在论文里，自己偷偷做再发下一篇，论文的 Future Work 里就写你觉得没戏的和你觉得做不出来的。而 DeepSeek LLM 最后 Future Work 的几句话从现在的视角来看都太真诚了，几乎已经把 R1 的路子给指出来了。</p><blockquote><p>DeepSeek LLM 将会是一个长期项目，专注于促进开源模型进步，</p></blockquote><p>这个不好说，毕竟满打满算也就一年多。</p><blockquote><p>Soon，我们将会发布 Code 和 MoE 架构的技术报告。MoE 的架构看上去很有希望。</p></blockquote><p>这个 Soon 指的是一周发布 MoE，半个月发布 DeepSeek Code。而我们已经知道 MoE 成为了 V2，V3 和 R1 模型的基础架构，参数量也上升到了 671B。</p><blockquote><p>我们现在已经有了大得多质量好得多的数据集，下一代模型所有指标都会显著提升。</p></blockquote><p>数据量半年后从 2T 变成了 8T，不过同期 LLaMA-3 变成了 15T。DeepSeek V2 的各项指标相比同期的 LLaMA-3 在英文上是稍微落后的，而且在 V2 的时候他们的重点就已经变成了疯狂降低成本。</p><blockquote><p>我们的对齐团队发现强化学习能够增强模型的复杂推理能力。</p></blockquote><p>从今天回头来看，这不就是 R1 最重要的方法么。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从今天的视角来看，DeepSeek 当时应该还在探索期，还在和业界的开源模型对齐，还做了很多理论上的研究。但是从论文的各个细节上来看，一年后那个石破天惊的 R1 诞生的条件已经差不多具备了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近找到了 DeepSeek 发表过的论文合集，包含了从 DeepSeek 第一版的 LLM 到最新的 R1 的演变过程。从当下的角度我们当然知道 DeepSeek R1 在模型能力上已经接近了业界最领先的水平，但他是如何一步步从一个在中国一开始都没有被重视的量化公司走到这</summary>
      
    
    
    
    
    <category term="DeepSeek" scheme="http://oilbeater.com/tags/DeepSeek/"/>
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Paper" scheme="http://oilbeater.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>从 Network Binding Plugin 看 KubeVirt 的扩展方式</title>
    <link href="http://oilbeater.com/2025/01/12/kubevirt-network-binding/"/>
    <id>http://oilbeater.com/2025/01/12/kubevirt-network-binding/</id>
    <published>2025-01-12T08:16:07.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>在 KubeVirt v1.4 的新版本里将 <a href="https://kubevirt.io/user-guide/network/network_binding_plugins/">Network Binding Plugin</a> 提升到了 Beta，提供了一种新的扩展 KubeVirt 网络的方式。虽然名义上是为了扩展网络的能力，但实际上从实现上来看，这个机制能做的事情远不止网络，所有和 libvirt domain xml 相关的变更都可以通过这个机制来实现。</p><h2 id="KubeVirt-Network-Overview"><a href="#KubeVirt-Network-Overview" class="headerlink" title="KubeVirt Network Overview"></a>KubeVirt Network Overview</h2><p>先从网络的角度来看下 KubeVirt 之前的网络机制有什么问题，新的机制又是如何进行扩展的。</p><p>由于 KubeVirt 使用的是 Pod 里面跑 VM 的架构，所以复用了 CNI 的网络机制。这样的话就将网络分成了两个部分，一个是 Pod 网络由各个 CNI 提供。另一部分就是如何将 CNI 提供的网络接入 VM，在 libvirt 里这部分叫做 Domain 网络。</p><p>KubeVirt 之前的各种网络机制（Bridge，Masquerade，Passt，Slirp）所做的事情就是通过不同的技术方案将 Pod 里的 eth0 接入到 VM 的 tap0 网卡。例如 Bridge 将 tap0 和 eth0 接入到同一个网桥，Masquerade 将 tap0 的流量经过 iptables nat 规则导入 eth0，Passt 和 Slirp 通过用户态的网络栈做流量重定向。</p><p><img src="/../images/kubevirt-networking-tradition.png" alt="alt text"></p><p>这些方法在实现上都是类似的，在 Pod 内部做一些网络相关的配置，然后修改 libvirt 的启动参数接入对应的网络。但是现有的机制都是写死在 KubeVirt Core 里的，并没有扩展机制，想要新增一种机制或者修改已有的机制都需要修改 KubeVirt 的代码很不灵活，例如默认的 bridge 插件会劫持 DHCP 请求，但是又不支持 IP, 所以 bridge 模式下的双栈就很难实现，而 Kube-OVN 中已经实现的 DHCP 又被这个机制绕过去了，之前想做 bridge 的双栈就需要改 KubeVirt 的代码来关闭默认的 DHCP 十分麻烦。因此新版本中将这套机制抽象出来提供了一套通用的机制。</p><h2 id="Hook-Sidecar"><a href="#Hook-Sidecar" class="headerlink" title="Hook Sidecar"></a>Hook Sidecar</h2><p>先来看一种在 KubeVirt 中已经存在的扩展机制 <a href="https://kubevirt.io/user-guide/user_workloads/hook-sidecar/">Hook Sidecar</a>。</p><p>这套机制是在 VM 正式创建前，可以加载一个用户自定义的镜像，或者一段 ConfigMap 里保存的 Shell 或者 Python 脚本，来修改 VM 启动前 libvirt 的启动参数和 cloud-init 参数。</p><p>它的执行机制和 CNI 有些类似，virt-handler 在启动 VM 前会去对应目录寻找 <code>/usr/bin/onDefineDomain</code> 和 <code>/usr/bin/preCloudInitIso</code> 两个二进制文件，前者传入 virt-handler 生成的 libvirt XML 配置，返回修改后的配置；后者传入 cloudInit 配置，返回修改后的 cloudInit 配置。这样的话所有 KubeVirt 本身不支持的 libvirt 和 cloudInit 参数都可以通过这种机制来注入修改。并且由于 Sidecar 内实际可以执行任意代码，所能做的事情远不止修改这两个配置，所有初始化阶段 KubeVirt 没有实现的能力其实都可以在这里来实现。</p><h2 id="Network-Binding-Plugin"><a href="#Network-Binding-Plugin" class="headerlink" title="Network Binding Plugin"></a>Network Binding Plugin</h2><p>现在可以到 Network Binding Plugin 这个机制了，这个机制其实和 Hook Sidecar 基本上大同小异。主要区别是将二进制调用改成了 gRPC 调用，gRPC 里注册的方法还是  <code>onDefineDomain</code> 和 <code>preCloudInitIso</code> 参数传递从命令行参数改为了 gRPC Request 里的参数，其他都是一样的。</p><p>具体的例子可以参考目前还在 KubeVirt 代码里的 <a href="https://github.com/kubevirt/kubevirt/tree/main/cmd/sidecars/network-slirp-binding">Slirp Binding</a> 的实现。尽管在 Network Binding Plugin 的规范里还增加了<code>networkAttachmentDefinition</code> 字段可以选择一个 CNI，但这个其实使用之前的网卡选择机制也能实现，甚至由于 Sidecar 里可以执行任意代码，在里面再实现一个 CNI 覆盖 Pod 原先的网络也是可以的。</p><p>那么之后的网络架构就变成了下图这样：</p><p><img src="/../images/networking-binding.png" alt="alt text"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然 Network Binding Plugin 的机制是为 Network 扩展准备的，但实际上几乎可以扩展所有 KubeVirt 在 virt-handler 侧的处理逻辑。甚至可以把 KubeVirt 也只当一个框架，所有的逻辑都通过 Sidecar 来处理，相信未来可以玩出不少花活来。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://kubevirt.io/user-guide/user_workloads/hook-sidecar/">https://kubevirt.io/user-guide/user_workloads/hook-sidecar/</a></li><li><a href="https://kubevirt.io/user-guide/network/network_binding_plugins/">https://kubevirt.io/user-guide/network/network_binding_plugins/</a></li><li><a href="https://github.com/kubevirt/kubevirt/blob/main/docs/network/network-binding-plugin.md">https://github.com/kubevirt/kubevirt/blob/main/docs/network/network-binding-plugin.md</a></li><li><a href="https://github.com/kubevirt/kubevirt/tree/main/cmd/sidecars/network-slirp-binding">https://github.com/kubevirt/kubevirt/tree/main/cmd/sidecars/network-slirp-binding</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 KubeVirt v1.4 的新版本里将 &lt;a href=&quot;https://kubevirt.io/user-guide/network/network_binding_plugins/&quot;&gt;Network Binding Plugin&lt;/a&gt; 提升到了 Beta，提供了</summary>
      
    
    
    
    
    <category term="kubevirt" scheme="http://oilbeater.com/tags/kubevirt/"/>
    
    <category term="networking" scheme="http://oilbeater.com/tags/networking/"/>
    
  </entry>
  
  <entry>
    <title>加速容器镜像下载：从缓存到按需加载</title>
    <link href="http://oilbeater.com/2024/10/31/docker-pull/"/>
    <id>http://oilbeater.com/2024/10/31/docker-pull/</id>
    <published>2024-10-31T11:59:25.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>在容器的启动过程中，镜像下载速度往往是影响启动速度的最主要因素，通常占据了启动时间的 70% 以上。特别是对于体积庞大的 VM、AI 镜像，它们的大小可能达到数十 GB，导致下载和解压速度都成为启动的瓶颈。本文将探讨镜像下载的主要瓶颈、常见的优化方案以及最新的按需加载技术，以加速容器启动。</p><h3 id="镜像下载速度慢的原因"><a href="#镜像下载速度慢的原因" class="headerlink" title="镜像下载速度慢的原因"></a>镜像下载速度慢的原因</h3><p>容器镜像下载慢的原因主要有以下几点：</p><ul><li><strong>镜像体积过大</strong>：VM、AI 镜像体积通常较大，可能达到数十 GB，使得下载时间显著。</li><li><strong>gzip 解压耗时</strong>：特别是在内网环境中，解压时间往往远高于网络传输时间，导致解压成为新的瓶颈。</li></ul><h3 id="常见的镜像优化思路"><a href="#常见的镜像优化思路" class="headerlink" title="常见的镜像优化思路"></a>常见的镜像优化思路</h3><p>为了解决下载和解压的速度问题，业界提出了多种优化方案：</p><ol><li><p><strong>镜像缓存</strong><br>镜像缓存是提升镜像下载速度的一种方法，通过缓存镜像可以避免重复下载。然而，缓存无法解决冷启动问题，并且镜像频繁变更（如应用更新或安全更新）会导致缓存失效。要实现高效的缓存管理，还需要较复杂的机制来管理缓存更新。</p></li><li><p><strong>减小镜像体积</strong><br>减少镜像体积也有助于缩短下载时间，但在某些场景下，例如 VM、AI、CUDA 镜像，体积优化空间有限。它们通常需要使用超过 7 GB 的存储空间，难以进一步缩减。</p></li></ol><h3 id="按需加载：是否可行？"><a href="#按需加载：是否可行？" class="headerlink" title="按需加载：是否可行？"></a>按需加载：是否可行？</h3><p>目前，大多数容器在启动时并不需要完整的镜像内容。一些论文表明，启动期间仅需 6.4% 的镜像内容，因此理论上可以通过按需下载来优化启动速度。然而，现有的镜像格式存在以下问题，限制了按需下载的实现：</p><ul><li><strong>OverlayFS 的限制</strong>：需要所有镜像层下载完毕后才能得知最终文件结构。</li><li><strong>gzip 不支持随机访问</strong>：即使只需下载单个文件，也要下载并解压整个层。</li><li><strong>校验问题</strong>：镜像 digest 是按整个层计算的，无法针对单个文件校验。</li></ul><h3 id="eStargz：实现按需加载"><a href="#eStargz：实现按需加载" class="headerlink" title="eStargz：实现按需加载"></a>eStargz：实现按需加载</h3><p>为了解决上述问题，eStargz 提出了针对 gzip 层的优化方案，即每个文件单独压缩并增加文件级别索引。eStargz 引入了如下优化：</p><ol><li><strong>独立压缩</strong>：每个文件单独压缩并索引，解决了 gzip 无法随机访问的问题。</li><li><strong>文件校验</strong>：可以对单个文件进行校验，无需校验整个层。</li></ol><p>具体的存储格式如下图：</p><p><img src="/../images/estartgz.png" alt="alt text"></p><p>每个文件被单独压缩合并成一个大的 blob，在 blob 最后增加一个 TOC 的描述文件记录每个文件的偏移量和校验值，这样就实现了按文件的索引和校验。</p><p>以下是 eStargz 的 TOC 格式示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;entries&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bin/&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dir&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;modtime&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2019-08-20T10:30:43Z&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span> <span class="number">16877</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;NumLink&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bin/busybox&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;reg&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;size&quot;</span><span class="punctuation">:</span> <span class="number">833104</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;modtime&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2019-06-12T17:52:45Z&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span> <span class="number">33261</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;offset&quot;</span><span class="punctuation">:</span> <span class="number">126</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;NumLink&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;digest&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sha256:8b7c559b8cccca0d30d01bc4b5dc944766208a53d18a03aa8afe97252207521f&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;chunkDigest&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sha256:8b7c559b8cccca0d30d01bc4b5dc944766208a53d18a03aa8afe97252207521f&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>通过这种改进，eStargz 实现了对单个文件的按需加载，且可以实现文件级别校验。</p><h3 id="性能权衡：优先级加载"><a href="#性能权衡：优先级加载" class="headerlink" title="性能权衡：优先级加载"></a>性能权衡：优先级加载</h3><p>虽然按需加载大幅优化了下载性能，但也可能带来运行时性能的下降。为此，eStargz 采用特殊标识来实现优先级加载，将启动所需文件放置于 <code>prioritized zone</code> 中，确保这些文件优先下载，进而提升运行时性能。</p><p><img src="/../images/estargz-optimize.png" alt="alt text"></p><p>按照作者测试的性能表现如下：</p><p><img src="/../images/estargz-perf.png" alt="alt text"></p><h3 id="代价与挑战"><a href="#代价与挑战" class="headerlink" title="代价与挑战"></a>代价与挑战</h3><p>尽管 eStargz 带来了按需加载的性能提升，但也带来了以下代价：</p><ul><li><strong>存储空间增加</strong>：每个文件单独压缩会增加额外的 metadata，降低压缩率。</li><li><strong>额外插件支持</strong>：eStargz 需要插件支持，例如在容器镜像推送和拉取时需要特定处理插件。</li></ul><h3 id="如何使用-eStargz"><a href="#如何使用-eStargz" class="headerlink" title="如何使用 eStargz"></a>如何使用 eStargz</h3><p>以下是 eStargz 的使用方法，适用于 containerd 的子项目以及一些支持 eStargz 的工具：</p><ol><li><p><strong>Docker, kaniko, nerdctl 命令行参数</strong>：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker buildx build -t ghcr.io/ktock/hello:esgz \</span><br><span class="line">    -o <span class="built_in">type</span>=registry,oci-mediatypes=<span class="literal">true</span>,compression=estargz,force-compression=<span class="literal">true</span> \</span><br><span class="line">    /tmp/buildctx/</span><br><span class="line"></span><br><span class="line">nerdctl image convert --estargz --oci ghcr.io/ktock/hello:1 ghcr.io/ktock/hello:esgz</span><br></pre></td></tr></table></figure></li><li><p><strong>containerd 插件配置</strong>：</p> <figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="section">[proxy_plugins]</span></span><br><span class="line">  <span class="section">[proxy_plugins.stargz]</span></span><br><span class="line">    <span class="attr">type</span> = <span class="string">&quot;snapshot&quot;</span></span><br><span class="line">    <span class="attr">address</span> = <span class="string">&quot;/run/containerd-stargz-grpc/containerd-stargz-grpc.sock&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]</span></span><br><span class="line">  <span class="attr">snapshotter</span> = <span class="string">&quot;stargz&quot;</span></span><br><span class="line">  <span class="attr">disable_snapshot_annotations</span> = <span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ol><p>此外，GKE 等云平台的集群已默认启用类似方案，进一步加速了镜像启动速度。看阿里也发表了基于 block device 的按需加载，这类的实现看上去在云厂商都有了比较大规模的落地。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从传统的镜像缓存、镜像体积优化，到按需加载，eStargz 提供了一种兼顾性能和灵活性的方案，使得容器可以在仅下载部分内容的情况下启动。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/estargz.md">eStargz: Standard-Compatible Extension to Container Image Layers for Lazy Pulling</a></li><li><a href="https://medium.com/nttlabs/startup-containers-in-lightning-speed-with-lazy-image-distribution-on-containerd-243d94522361">Startup Containers in Lightning Speed with Lazy Image Distribution on Containerd</a></li><li><a href="https://www.usenix.org/conference/fast16/technical-sessions/presentation/harter">Slacker: Fast Distribution with Lazy Docker Containers</a></li><li><a href="https://github.com/containerd/accelerated-container-image">Accelerated Container Image</a></li><li><a href="https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming">Use Image streaming to pull container images</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在容器的启动过程中，镜像下载速度往往是影响启动速度的最主要因素，通常占据了启动时间的 70% 以上。特别是对于体积庞大的 VM、AI 镜像，它们的大小可能达到数十 GB，导致下载和解压速度都成为启动的瓶颈。本文将探讨镜像下载的主要瓶颈、常见的优化方案以及最新的按需加载技术，</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>AI Gateway 调研之 Kong, Gloo 和 Higress</title>
    <link href="http://oilbeater.com/2024/08/26/kong-gloo-higress/"/>
    <id>http://oilbeater.com/2024/08/26/kong-gloo-higress/</id>
    <published>2024-08-26T07:39:23.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>上篇<a href="2024-08-25-ai-gateway-cloudflare">博客</a>介绍了 Cloudflare AI Gateway，这篇集中介绍一下 Kong, Gloo 和 Higress 因为这三者有一定的相似性，都是从原有的 API 网关基础上进行扩展，通过插件的方式支持了一系列 AI 相关的功能，在交付上也是传统的软件部署方式。这几个算是传统 API Gateway 迎接 AI 浪潮的代表，其中 Higress 更是把产品 Slogan 直接从 Cloud Native API Gateway 变成了 AI Gateway，虽然打不过就加入，但这样变来变去不怕人说没根么：）</p><p>由于这三款产品都需要额外的部署开通，有的 AI 功能还是商业版才有，所以下面的分析都是根据看文档总结而来，可能存在着和实际不符的情况。</p><table><thead><tr><th>功能</th><th>Kong</th><th>Gloo</th><th>Higress</th><th>备注</th></tr></thead><tbody><tr><td>技术栈</td><td>Nginx + Lua</td><td>Envoy + Go</td><td>Envoy + WASM</td><td>虽然几家都提供了插件机制，但是和网关的耦合程度都比价高，非网关的开发者上手还是有一定难度</td></tr><tr><td>日志监控</td><td>每个 AI 插件会将元信息，如模型名、Token 开销费用等信息加入到 Audit Log 中，但是似乎没有自定义元信息的功能，需要通过其他插件来辅助完成</td><td>似乎没有在 AI 这块对日志有功能增强，还是通用的监控</td><td>日志和监控中增加了 Token 的用量，提供的信息和 Kong 类似，也不具备自定义元信息的功能</td><td>如果能增加一些自定义元信息，并支持记录 Request 和 Response 里 Message 信息就更好了</td></tr><tr><td>Proxy</td><td>Kong 提供了归一化的 API 能够用一套统一的 API 去调用不同的 LLM API，这对开发者还是比较友好的能够不需要大改应用代码就能用不同的 LLM</td><td>Gloo 没有提供归一化的 API，只是反向代理到上游 LLM API</td><td>Higress 支持将不同的 LLM API 统一转换成 OpenAI API，这对开发者来说也比较友好，毕竟目前生态里还是直接用 OpenAI API 的比较多</td><td>虽然我觉得是否提供归一化的 API 没那么重要，不过一定要归一化的话归一化成 OpenAI 格式的会好些</td></tr><tr><td>API Key 管理</td><td>客户端的 Key 可以和上游的 Key 不一样，相当于把 Key 在网关层做了一层屏蔽</td><td>客户端的 Key 可以和上游的 Key 不一样，相当于把 Key 在网关层做了一层屏蔽</td><td>直接从客户端透传 Key 给上游</td><td>个人感觉 Gloo 这个功能还比较实用，避免了在 LLM 那里真实的 Key 被过多业务方知道，安全和可控性会更好一些</td></tr><tr><td>Cache</td><td>当前版本没有提供 LLM Cache 相关能力，据说会在 3.8 版本提供</td><td>提供了语义 Cache，看配置是调用了 OpenAI 的 Embedding 和 Redis 的 Vector，不过没看到更细粒度的比如 TTL 相似度的配置</td><td>提供的还是文本匹配的缓存，相比全文本可以通过 JSON PATH 的语法选择部分 Message 做缓存，看配置也是利用 Redis，不过不支持语义 Cache</td><td>Gloo 提供的语义 Cache 看起来更高级一些</td></tr><tr><td>请求&#x2F;响应改写</td><td>可以在 Request 和 Response 阶段分别加 prompt 对 message 进行改写，相当于一个小型的 workflow</td><td>只提供了 prepend system prompt 的能力，感觉提升有限</td><td>和 Kong 类似提供了用 prompt 进行改写的能力，不过现在只支持通义千问的 LLM 感觉不够开放</td><td></td></tr><tr><td>RAG</td><td>目前没有相关功能的插件</td><td>可以对接一个 postgres 和 OpenAI 的 embedding Token 这样可以自己提供一些文本来做 RAG</td><td>和 Gloo 的功能类似，不过只支持阿里云的向量服务和通义千问，还是感觉不够开放</td><td>感觉 RAG 的配置参数都比较少没有相似度，或者爬取网页的接口，只能做比较简单的 RAG</td></tr></tbody></table><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这三款产品由于只是看文档没有真实使用过，里面的内容很可能有不准确的地方，希望了解的同学可以指正。</p><p>总体来看三款产品都是 LLM 爆发前就存在的，之前也不是专门为 AI 场景设计的，很多使用的配置可能懂 Kubernetes 的更能看懂。尤其是 Gloo 的文档全是 YAML 和 CRD 的配置，浓浓的 Cloud Native 味道，Higress 看上去也是各种 ConfigMap 脱离 Kubernetes 是否还能用好我是心里存在疑虑的。</p><p>Higress 虽然没根了，但是整体看 AI 功能做的还是最完整的，发力也比较明显。Kong 感觉还只是试探性的做了些功能，而 Gloo 是把所有 AI 相关功能都放到商业版里了。如果 Higress 能把开发性做好不是被通义千问和阿里云上各种服务绑定的话我觉得还是个不错的项目。</p><p>最后的依赖还是这三款产品的扩展性可能都存在一定难度，需要高度了解网关相关的逻辑并掌握 Lua 或者 WASM 这样非主流的语言。而 AI 应用现在的形态其实还存在很多变化的可能，对应的 API 和需要的通用能力可能也有比较大的变化，比如怎么做 RAG，怎么做 Cache，怎么编排 LLM 都没有确定下来。不知道现在的架构会不会对他们未来的功能灵活变化产生影响。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;上篇&lt;a href=&quot;2024-08-25-ai-gateway-cloudflare&quot;&gt;博客&lt;/a&gt;介绍了 Cloudflare AI Gateway，这篇集中介绍一下 Kong, Gloo 和 Higress 因为这三者有一定的相似性，都是从原有的 API 网关基础上进</summary>
      
    
    
    
    
    <category term="AI" scheme="http://oilbeater.com/tags/AI/"/>
    
    <category term="Gateway" scheme="http://oilbeater.com/tags/Gateway/"/>
    
    <category term="Kong" scheme="http://oilbeater.com/tags/Kong/"/>
    
    <category term="Gloo" scheme="http://oilbeater.com/tags/Gloo/"/>
    
    <category term="Higress" scheme="http://oilbeater.com/tags/Higress/"/>
    
  </entry>
  
  <entry>
    <title>AI Gateway 调研之 Cloudflare AI Gateway</title>
    <link href="http://oilbeater.com/2024/08/25/ai-gateway-cloudflare/"/>
    <id>http://oilbeater.com/2024/08/25/ai-gateway-cloudflare/</id>
    <published>2024-08-25T14:10:45.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>随着 AI 的火热，眼看着之前调研的各家竞品 API 网关产品纷纷把自己的介绍改为 AI Gateway，于是就想调研一下这些所谓的 AI Gateway 究竟做了些啥。这次调研的对象有一些之前靠 API 网管或者云原生 Ingress Controller 起家加入 AI 功能的，例如：<a href="https://konghq.com/products/kong-ai-gateway">Kong</a>，<a href="https://www.solo.io/products/gloo-ai-gateway/">Gloo</a> 和 <a href="https://higress.io/en/">Higress</a>。也包括一些第一天就是借着 AI 起来的我认为真正 AI 原生的网关，例如 <a href="https://portkey.ai/features/ai-gateway">Portkey</a> 和 <a href="https://github.com/songquanpeng/one-api">OneAPI</a>。以及这篇博客介绍的基于公有云 Serverless 的 <a href="https://developers.cloudflare.com/ai-gateway/">Cloudflare AI Gateway</a>。</p><p>大体来看目前的 AI Gateway 主要能力在三个方面：</p><p><strong>常规 API 网关功能在 AI API 上的应用</strong>，例如：监控，日志，限速，反向代理，请求或响应改写，集成用户系统等。这些功能其实和 AI 关系不大就是把 LLM 的 API 当成了一个普通的 API 进行接入。</p><p><strong>部分 API 网关功能针对 AI 进行优化</strong>，例如限速功能增加基于 Token 的限速，缓存功能增加基于 Prompt 的缓存，防火墙基于 prompt 和 LLM 返回进行过滤，多个 LLM API Key 之间的负载均衡，多个 LLM Provider 的 API 转换。这些功能在原有的 API 网关就存在类似的概念，不过在 AI 场景下又有了相应的扩展。</p><p><strong>基于 AI 应用的场景增加的新功能</strong>，例如部分 AI 网关增加了 Embedding 和 RAG 的功能，把向量数据库和文本数据库的功能通过 API 的形式提供出来。还有一些针对 token 用量的性能优化，比如 Prompt 简化，语义化 Cache 等。还有一些更偏应用层的功能，例如对 LLM Output 提供打分功能等。</p><p>这篇博客介绍 <a href="https://developers.cloudflare.com/ai-gateway/">Cloudflare AI Gateway</a> 这款 AI Gateway 的特点。</p><h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><p>Cloudflare 的这款 AI Gateway 主要功能其实就是一个反向代理，看完了我甚至觉得我用 Cloudflare Worker 捣鼓一阵也能做个功能类似的。如果你原来用的是 OpenAI 的 API 那么现在你要做的就是把 SDK 里的 baseURL 换成 <code>https://gateway.ai.cloudflare.com/v1/$&#123;accountId&#125;/$&#123;gatewayId&#125;/openai</code> 就可以了。在这个过程中由于流量进出都是过 Cloudflare 的，Cloudflare 平台上就可以提供对应的监控，日志，缓存等功能。</p><p>这个方案有下面几个优点：</p><ul><li>接入很简单，改一下 baseURL 就接入进来了，API 格式也没有任何变化。并且完全是 Serverless 的，不需要自己额外管理任何服务器，这个功能现在是免费的，直接就白嫖了监控数据。</li><li>借助 Cloudflare 的全球网络可以实现一定的用户接入加速，不过这个用户接入的加速相比 LLM 本身的延迟比重应该很小，顶多在首个 Token 的延迟会有明显变化。</li><li>通用借助 Cloudflare 的全球网络可以一定程度隐藏掉源 IP，对于一些 OpenAI API 访问受限的区域用这个可以绕过去。</li></ul><p>但对应的也有下面的缺点：</p><ul><li>所有请求信息包括 API Key 都要在 Cloudflare 上过一道，会有安全方面的一些隐患。</li><li>Gateway 本身没有什么插件机制，想扩展功能的话会比较麻烦，只能在外面再套一层。</li><li>同样是因为 Cloudflare 的全球网路欧，如果一个 Key 一直变换 IP 地址访问，不知道会不会触发 OpenAI 那边的拉黑。</li></ul><h1 id="主要能力"><a href="#主要能力" class="headerlink" title="主要能力"></a>主要能力</h1><h2 id="多个-Provider-支持"><a href="#多个-Provider-支持" class="headerlink" title="多个 Provider 支持"></a>多个 Provider 支持</h2><p>由于 Cloudflare AI Gateway 并没有对 LLM API 进行修改，只是做反向代理，所以几乎主流的 LLM API 它都可以支持，只需要把 baseURL 改成对应 Provider 如 <code>https://gateway.ai.cloudflare.com/v1/$&#123;accountId&#125;/$&#123;gatewayId&#125;/&#123;provider&#125;</code> 即可。</p><p>它唯一多提供的一个 API 叫做 <a href="https://developers.cloudflare.com/ai-gateway/providers/universal/">Universal Endpoint</a> 可以做简单的 fallback。用法是在一个 API 请求里可以填写多个 Provider 的<br>query，这样当前面的 Provider 请求失败时会自动调用下一个 Provider。</p><h2 id="可观测"><a href="#可观测" class="headerlink" title="可观测"></a>可观测</h2><p>监控层面除了基础的 QPS 和 Error Rate 这些监控面板，还针对 LLM 的场景提供了 Token，Cost 以及 Cache 命中率的面板。</p><p>日志方面和 Worker 的日志很类似，只有实时日志无法查询历史日志。这里感觉做的不太好，Worker 至少还有第三方的方案能保存日志，但是 Gateway 这里却没有了。虽然通过一些实时日志 API 再自己保存的方式也可以，但还是太麻烦了。分析 LLM 请求和响应日志应该是很多 AI 应用后续做优化甚至 fine-tuning 的一个重要环节，这里没有直接集成持久化的方案其实是个硬伤。</p><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存方面，Cloudflare 提供的还是基于文本内容完全匹配的缓存，目测是通过 <a href="https://developers.cloudflare.com/kv/">Cloudflare Workers KV</a> 来实现的。也可以通过 <code>cf-aig-cache-key</code> 来实现自定义 Cache Key，包括设置缓存的 TTL 以及忽略 Cache。但是整体看起来基于现在的功能是无法实现语义缓存的，官方文档的说法是语义缓存会在未来提供。</p><h2 id="Rate-Limiting"><a href="#Rate-Limiting" class="headerlink" title="Rate Limiting"></a>Rate Limiting</h2><p>限速方面，Cloudflare 提供的还是传统的基于 QPS 的限速，这块并没有基于 AI 的场景提供基于 Token 的限速，这里未来还有改善的空间。</p><h2 id="Custom-metadata"><a href="#Custom-metadata" class="headerlink" title="Custom metadata"></a>Custom metadata</h2><p>可以在请求的 Header 中增加一些自定义字段，比如用户信息。这些信息可以通过日志进行检索。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>整体来看 Cloudflare AI Gateway 胜在简单易用，对于之前没有使用 AI Gateway 的用户可以两三分钟就接进来，提供了基础的监控和缓存能力。而且 Cloudflare 还有一些其他配套的 AI 服务例如 Works AI 提供了大量的开源模型的 Serving 和 Worker 提供边缘计算，几个一结合就能搭一套完全 Serverless 的 AI 系统。</p><p>他的问题主要在于更深入的功能提供的比较少，而且功能扩展比较麻烦，只能在外围通过 Worker 再来包一层。与其这样 Cloudflare 还不如直接把 AI Gateway 开源出来变成一个模板，用户可以根据自己需求去更改代码或者写插件，没准还能形成一个新的生态。毕竟我高度怀疑现在的 AI Gateway 其实就是个 Worker 模板。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;随着 AI 的火热，眼看着之前调研的各家竞品 API 网关产品纷纷把自己的介绍改为 AI Gateway，于是就想调研一下这些所谓的 AI Gateway 究竟做了些啥。这次调研的对象有一些之前靠 API 网管或者云原生 Ingress Controller 起家加入 AI</summary>
      
    
    
    
    
    <category term="AI" scheme="http://oilbeater.com/tags/AI/"/>
    
    <category term="Gateway" scheme="http://oilbeater.com/tags/Gateway/"/>
    
    <category term="Cloudflare" scheme="http://oilbeater.com/tags/Cloudflare/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes 多集群通信的五种方案</title>
    <link href="http://oilbeater.com/2024/05/24/5-way-kubernetes-multcluster-communication/"/>
    <id>http://oilbeater.com/2024/05/24/5-way-kubernetes-multcluster-communication/</id>
    <published>2024-05-24T08:25:30.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>随着企业的业务规模不断扩大，Kubernetes 的使用也从单集群逐步扩展到多集群部署。多集群环境下，集群之间的通信成为一个重要的研究课题。本文将介绍五种跨 Kubernetes 集群通信的方案的基本原理，优点及其局限性。</p><h2 id="1-Underlay-网络"><a href="#1-Underlay-网络" class="headerlink" title="1. Underlay 网络"></a>1. Underlay 网络</h2><p>这类网络插件包括 <a href="https://www.cni.dev/plugins/current/main/macvlan/">macvlan</a>&#x2F;<a href="https://www.cni.dev/plugins/current/main/ipvlan/">ipvlan</a>&#x2F;<a href="https://kubeovn.github.io/docs/stable/start/underlay/">Kube-OVN underlay</a> 以及各种云上的 VPC CNI 等。</p><p><strong>基本原理</strong>：</p><p>Underlay 网络从 CNI（容器网络接口）的角度来看是最简单的方式。这种方式依赖于底层基础设施在网络层面实现打通。例如，使用公有云上的 VPC Peering 或者物理网络配置路由和大二层。当底层网络实现了连通，跨集群的容器网络就自然连通了。</p><p><strong>优点</strong>：</p><ul><li>CNI 角度最为简单，无需额外操作。</li><li>架构上清晰，把跨集群通信的责任交给底层网络。</li></ul><p><strong>局限性</strong>：</p><ul><li>依赖于特定 CNI，Underlay 类型的网络场景使用范围有限，有些情况只能使用 Overlay 网络。</li><li>在异构的环境，比如多云之间、公有云和私有云之间打通存在困难。</li><li>只是做了基础的容器网络通信打通，更上层的服务发现，域名和网络策略等功能存在缺失。</li><li>一次性打通所有集群的容器网络，缺乏细粒度的控制。</li></ul><h2 id="2-提供跨集群通信能力的-Overlay-CNI"><a href="#2-提供跨集群通信能力的-Overlay-CNI" class="headerlink" title="2. 提供跨集群通信能力的 Overlay CNI"></a>2. 提供跨集群通信能力的 Overlay CNI</h2><p>在无法使用 Underlay 网络的情况下，一些特定的 CNI 在 Overlay 层面也实现了跨集群。例如 <a href="https://cilium.io/use-cases/cluster-mesh/">Cilium Cluster Mesh</a>, <a href="https://antrea.io/docs/v2.0.0/docs/multicluster/quick-start/">Antrea Multi-Cluster</a> 和 <a href="https://kubeovn.github.io/docs/stable/en/advance/with-ovn-ic/">Kube-OVN with ovn-ic</a>。</p><p><strong>基本原理</strong>：</p><p>这些 CNI 的实现方案其实大体一致，通过选择一组集群内的节点作为网关节点，然后网关节点之间建立隧道，跨集群流量通过网关节点转发。</p><p><strong>优点</strong>：</p><ul><li>CNI 自包含跨集群功能，无需额外组件支持。</li></ul><p><strong>局限性</strong>：</p><ul><li>依赖特定 CNI，无法实现不同 CNI 集群之间的通信。</li><li>无法处理 CIDR 重叠的情况，需要提前规划好网段。</li><li>除了 Cilium 实现的比较完整，把跨集群的服务发现和网络策略都实现了，其他的仅实现基础容器网络通信。</li><li>一次性打通所有集群的容器网络，缺乏细粒度的控制。</li></ul><h2 id="3-Submariner"><a href="#3-Submariner" class="headerlink" title="3. Submariner"></a>3. Submariner</h2><p>由于跨集群网络互通存在着通用的需求，在实现上也存在着类似，各个 CNI 其实存在着一些重复造轮子的工作。<a href="https://submariner.io/">Submariner</a> 作为一款 CNI 无关的跨集群网络插件提供了一种通用的能力，能将不同 CNI 的集群组成一个网络达到互通。Submariner 最早由 Rancher 的工程师创建，现在已经是 CNCF Sandbox 项目了，目前看红帽的工程师也在积极参与这个项目。</p><p><strong>基本原理</strong>：</p><p>Submariner 选择集群内的网关节点，网关节点通过 VXLAN 通信。跨集群流量通过 VXLAN 传输。Submariner 依赖 CNI 将 egress 流量先发送到宿主机的网络内，然后再进行转发。此外，Submariner 部署了一组 CoreDNS 实现跨集群服务发现，并使用 Globalnet Controller 解决 CIDR 重叠问题。</p><p><strong>优点</strong>：</p><ul><li>一定程度上 CNI 无关，可以连接不同 CNI 的集群。</li><li>实现了跨集群服务发现，支持 Service 和域名解析。</li><li>支持 CIDR 重叠的集群通信，避免了集群部署后想互联却发现 IP 冲突的尴尬。</li></ul><p><strong>局限性</strong>：</p><ul><li>并不是所有的 CNI 都可用，如果像 macvlan 或者 cilium 短路这种宿主机看不到流量的情况，就没有办法拦截流量到自己的隧道了。</li><li>Gateway 目前是主备模式，没法横向负载均衡，在大流量的场景下可能存在性能瓶颈。</li><li>一次性打通所有集群的容器网络，缺乏细粒度的控制。</li></ul><h2 id="4-Skupper"><a href="#4-Skupper" class="headerlink" title="4. Skupper"></a>4. Skupper</h2><p><a href="https://skupper.io/index.html">Skupper</a> 是我认为几个方案里最有意思的，它能够按需进行 Service 层面的网络打通，避免了一次完全打通的控制问题。而且很创新的使用了七层消息队列的方式来实现，可以说是对底层网络和 CNI 完全无依赖，上手也十分简单。目前 Skupper 看贡献者主要是红帽的工程师。</p><p><strong>基本原理</strong>：</p><p>和上述几个方案使用隧道将容器 IP 直接打通不同，Skupper 提出了一个 VAN（Virtual Application Networks）的概念，要在 7 层将网络打通。简单说就是不把 IP 直接打通而是把 Service 拉通，概念上和 ServiceExporter，ServiceImporter 类似，但是这个项目启动的比较早，当时还没有这些社区提出来的概念，在当时应该算个很创新的想法了</p><p>在实现上 Skupper 也另辟蹊径，用的是个消息队列的实现，多个集群之间组成了一个大的消息队列，跨集群通信的数据包发送到这个消息队列里。另一端再去消费这个数据包。思路上其实类似反向代理，但用消息队列来实现也是个很开脑洞的想法。把 Service 变成了一个消息的订阅点来提供消费，这样就可以按需的在服务端和客户端之间建立一个消息队列，通过消息队列的概念去管理和控制这个消息通路。</p><p><strong>优点</strong>：</p><ul><li>CNI 兼容性好，完全不依赖 CNI 的行为在应用层进行数据包的打通</li><li>上手简单，不需要太复杂的前期网络规划，也没有 CIDR 不重叠要求。提供了 CLI 方便临时测试和快速演示</li><li>并不是容器网络互通而是按需将 Service 打通，可以做到细粒度的控制，对底层要求也更低</li></ul><p><strong>局限性</strong>：</p><ul><li>文档介绍目前只支持 TCP 协议，UDP 和更底层的协议比如 ICMP 会有问题</li><li>由于是通过消息队列转发消息，IP 信息会丢失</li><li>通过消息队列转发的思路还是有些奇怪，在性能方面比如延迟和吞吐量上可能会有一些损失</li><li>而且 TCP 本身是有状态的，能否完全转换成消息队列的形式，兼容性如何是个疑问</li></ul><h2 id="5-KubeSlice"><a href="#5-KubeSlice" class="headerlink" title="5. KubeSlice"></a>5. KubeSlice</h2><p><a href="https://kubeslice.io/documentation/open-source/1.3.0">KubeSlice</a> 是刚刚进入 CNCF Sandbox 的一个项目。上述的方案基于隧道做的没法做到细粒度控制和 CNI 完全兼容，基于应用层做的又没法做到网络协议完全兼容。KubeSlice 提供了一个新的思路，尝试同时解决这两个问题。</p><p><strong>基本原理</strong>：</p><p>KubeSlice 最底层的思路十分简单粗暴，就是按需给 Pod 动态插入一块网卡，在这个网卡上面做跨集群的 Overlay，然后再在这个 Overlay 网络上面实现服务发现，和网络策略。用户可以按需的将跨集群的几个 Namespace 或者 某几个 Pod 组成一个网络，在可以使实现灵活的细粒度管控基础上由于走的是基于网卡的二层网络，也实现了网络协议的最大兼容性。</p><p><strong>优点</strong>：</p><ul><li>CNI 兼容性好，由于是额外插入了一块网卡完全不关心原先的 CNI 是什么，并且是额外的网络也不用担心原先网络地址是否有冲突的问题</li><li>网络协议兼容性好，同样是由于额外有了一块网卡做流量转发，所有的网络协议都是兼容的。</li><li>灵活度高，KubeSlice 提供了命令行工具可以动态的创建和加入网络，用户可以选择按应用的需求创建多个跨集群的虚拟网络</li><li>功能完善，按照文档的说法，该项目在额外的这个 Overlay 网络上实现了服务发现，DNS，QoS，Networkpolicy 和监控，可以说把各个方面都覆盖到了</li></ul><p><strong>局限性</strong>：</p><ul><li>由于本质上是双网卡，应用侧需要感知这个事情选择合适的网络，可能会涉及到应用改造</li><li>由于跨集群走的是另一个网卡不是 Pod 主网卡的 IP，对监控和追踪等外部系统可能涉及到改造</li><li>目前看文档应该是一个内部的项目进行开源，文档里很多使用方式和 API 介绍的不是特别清楚，需要对着 reference 慢慢猜每个参数到底是什么意思。功能上看上去确实比较全，但能让外部用户很好的使用的话文档还有很多需要完善的地方。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在 Kubernetes 多集群环境中实现高效通信有多种方案可供选择。每种方案都有其优点和局限性，用户可以根据具体需求和环境选择合适的方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;随着企业的业务规模不断扩大，Kubernetes 的使用也从单集群逐步扩展到多集群部署。多集群环境下，集群之间的通信成为一个重要的研究课题。本文将介绍五种跨 Kubernetes 集群通信的方案的基本原理，优点及其局限性。&lt;/p&gt;
&lt;h2 id=&quot;1-Underlay-网络</summary>
      
    
    
    
    
    <category term="network" scheme="http://oilbeater.com/tags/network/"/>
    
    <category term="kubernetes" scheme="http://oilbeater.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>k8gb: 云原生最佳开源 GSLB 方案</title>
    <link href="http://oilbeater.com/2024/04/18/k8gb-best-cloudnative-gslb/"/>
    <id>http://oilbeater.com/2024/04/18/k8gb-best-cloudnative-gslb/</id>
    <published>2024-04-18T10:01:10.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>如何将流量在多个 Kubernetes 集群之间进行负载均衡，并做到自动的灾备切换一直是一个让人头疼的问题。我们之前调研了公有云，<a href="https://github.com/karmada-io/multi-cluster-ingress-nginx">Karmada Ingress</a>，自己也做了一些手动 DNS 的方案，但这些方案在成本，通用性，灵活度以及自动化程度上都有所欠缺。直到调研到了 <a href="https://www.k8gb.io/">k8gb</a> 这个由南非银行 <a href="https://www.absa.africa/">Absa Group</a> 为了做金融级别的多活而启动的一个项目。k8gb 巧妙的利用了 DNS 的各种协议完成了一个通用且高度自动化的 GSLB 方案，看完后我就再也不想用其他的方案了。这篇博客会简单介绍一下其他几个方案各自存在的问题，以及 k8gb 究竟是如何巧妙的利用 DNS 来实现的 GSLB。</p><h2 id="什么是-GSLB"><a href="#什么是-GSLB" class="headerlink" title="什么是 GSLB"></a>什么是 GSLB</h2><p>GSLB（Global Service Load Balancer）是相对于单集群负载均衡的一个概念，单集群负载均衡主要作为一个集群的入口将流量分发到集群内部，而 GSLB 通常作为再上一层多个集群的流量入口，进行流量负载均衡和故障处理。一方面 GSLB 可以设置一些地理亲和的规则达到流量就近转发提升整体的性能，另一方面当某个集群出现问题后可以自动将流量切换到正常集群，减少单个集群故障对用户的影响。</p><h2 id="其他方案的问题"><a href="#其他方案的问题" class="headerlink" title="其他方案的问题"></a>其他方案的问题</h2><h3 id="商用负载均衡"><a href="#商用负载均衡" class="headerlink" title="商用负载均衡"></a>商用负载均衡</h3><p>GSLB 并不是一个新出的概念，所以不少商业公司都在这方面有很成熟的产品，例如 <a href="https://www.f5.com/solutions/use-cases/global-server-load-balancing-gslb">F5 GSLB</a>。这类产品通常有以下几个缺点：</p><ol><li>没有很好的和云原生对接，通常需要在 Kubernetes 集群外独立部署专有的软硬件，无法做到统一管理。</li><li>成本高，且有厂商锁定的风险。</li></ol><h3 id="公有云全局负载均衡"><a href="#公有云全局负载均衡" class="headerlink" title="公有云全局负载均衡"></a>公有云全局负载均衡</h3><p>公有云为了解决流量多地域分发会提供多集群负载均衡的产品，例如 AWS 的 <a href="https://aws.amazon.com/global-accelerator/">Global Accelerator</a> 和 GCP 的 <a href="https://cloud.google.com/load-balancing/docs/https">External Application Load Balancer</a>。GCP 上甚至还有一组自定义的 <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/multi-cluster-ingress">Multi Cluster Ingress</a> 资源，可以很好的和 Kubernetes 里的 Ingress 进行对接。但是他们也有一下几个问题：</p><ol><li>虽然是多集群负载均衡，但是多个集群必须是同一个公有云，不能在多云间进行流量调度。</li><li>私有云无法使用这个方案。</li></ol><h3 id="Karmada-Multi-Cluster-Ingress"><a href="#Karmada-Multi-Cluster-Ingress" class="headerlink" title="Karmada Multi  Cluster Ingress"></a>Karmada Multi  Cluster Ingress</h3><p>Karmada 是一个多集群的编排工具，也提供了自己的多集群流量调度方案 <a href="https://karmada.io/docs/userguide/service/multi-cluster-ingress/">Karmada Multi Cluster Ingress</a>。该方案通过在某个集群内部署一个由 Karmada 社区提供的 ingress-nginx 以及定义 <code>MultiClusterIngress</code> 来完成多集群流量调度，但这个方案有以下几个问题：</p><ol><li>依赖多集群间容器网络打通，和 ServiceImporter ServiceExporter 等 CRD，整体要求比较高。</li><li>需要额外再去管理这个提供 GSLB 服务的 ingress-nginx 实例，该部署在哪，该部署多少，怎么分配都是运维期间需要考虑的问题。</li><li>这个社区改造后的 <a href="https://github.com/karmada-io/multi-cluster-ingress-nginx">multi-cluster-ingress-nginx</a> 近两年基本没有什么代码提交，是否可用会让人有担忧。</li></ol><h3 id="简单的-DNS-方案"><a href="#简单的-DNS-方案" class="headerlink" title="简单的 DNS 方案"></a>简单的 DNS 方案</h3><p>如果手动攒出来一个简单的基于 DNS 的方案其实也是可以的，大部分 DNS 厂商都提供了健康检查的功能，因此我们可以将多个集群的出口 IP 地址加入到 DNS 的解析记录里，同时配置健康检查来做故障切换。但是这个简单的方案在规模扩大后就会有一些明显的限制：</p><ol><li>无法很好的自动化，一个集群下可能有多个不同的域名和多个不同的 Ingress IP 的组合，手动去管理他们的映射关系会随着规模增加变得难以维护。</li><li>DNS 厂商的健康检查通常是基于 TCP 和 ICMP 的，因此如果一个集群的出口完全挂掉这种故障是可以检测到并进行切换的。但是如果是局部故障就无法探测，例如多个 Ingress 复用一个 ingress-controller 并通过域名进行流量转发的情况下，如果其中一个服务的后端实例全部异常了，但是 ingress-controller 上的其他服务正常，那么健康检查还是会正常通过，并没有办法把流量切换到另一个集群。</li><li>DNS 本身存在各级缓存，更新时间可能较长。</li><li>DNS 健康检查本身也是个厂商提供的能力，并不能保证所有厂商都能提供这个能力，尤其是在私有云的场景。</li></ol><h2 id="k8gb-的解决方案"><a href="#k8gb-的解决方案" class="headerlink" title="k8gb 的解决方案"></a>k8gb 的解决方案</h2><p>k8gb 的解决方案其实也是用 DNS，但是通过自己的一系列巧妙的设计，解决了上面提到的简单 DNS 方案的一系列缺陷。</p><p>简单 DNS 方案的问题本质是没有和 Kubernetes 进行很好的对接，Kubernetes 内的一些动态信息，例如新增的 Ingress，新增的域名，服务的健康状态没法很好的同步到上游 DNS 服务器，而上游 DNS 服务器简单的健康检查也没办法应付 Kubernetes 里这种复杂的变化。因此 k8gb 最核心的一个变化就是上游的 DNS 记录不再是通过 A 记录或者 AAAA 记录指向集群的一个出口地址，而是 forward 到集群内的一个自己配置的 CoreDNS 进行 DNS 解析，将真正复杂的 DNS 逻辑下沉到集群里来自己控制。这样上游 DNS 只需要做简单的代理，不再需要配置健康检查，也不再需要动态的调整多个地址映射。</p><p>调整后用户请求 DNS 的流程如下图所示：</p><ul><li><img src="https://www.k8gb.io/docs/images/gslb-basic-multi-cluster.svg" alt="K8GB multi-cluster interoperability"></li></ul><ol><li>用户向外部 DNS 服务商请求一个域名的 IP 记录。</li><li>外部 DNS 将这个请求代理发送给集群内由 k8gb 管控的一个 CoreDNS。</li><li>k8gb 根据 Ingress Spec 里的域名，Ingress Status 里的 Ingress IP 以及集群内对应后端 Pod 的健康状态，负载均衡策略等信息分析出一个可用的 Ingress IP 返回给用户。</li><li>用户通过这个 IP 就可以直接访问到对应的 Ingress Controller。</li><li>当某一个集群的 k8gb 管控的 CoreDNS 出问题时由于上游 DNS 会同时将 DNS 请求代理到多个集群，另一个集群也可以返回自己的 Ingress IP，用户端可以通过多个返回的可用 IP 选择一个进行访问。</li></ol><p>这种方式管理员只需要在上游 DNS 注册几个域名后缀并代理到每个集群的 CoreDNS 就可以了，k8gb 本身也提供了自动化的能力，只要配好证书可以自动分析 Ingress 内使用的域名自动注册给上游 DNS，大幅简化了管理员的操作。</p><p>整个流程中还有一个特殊的点要注意，就是每个集群自己的 CoreDNS 不能只记录本集群 Ingress IP 的地址，还需要记录其他集群同一个 Ingress 的 Ingress IP 地址。因为如果只记录本集群的，当本集群对应服务的 Pod 都 Not Ready 时，CoreDNS 会返回 NXDomain 如果客户端收到了这个返回就会按照域名无法解析处理，此时另一个集群服务其实是可以正常提供服务的。因此 k8gb 还需要同步所有集群同一个域名 Ingress 对应的 Ingress IP 和它的健康状态。</p><p>众所周知多集群之间的数据同步也是一个世界难题，但是 k8gb 同样通过 DNS 巧妙的实现了数据的同步。</p><p>同步的流程图如下所示：</p><p><img src="https://www.k8gb.io/docs/images/k8gb-multi-cluster-interoperabililty.svg" alt="k8gb multi-cluster-interoperability"></p><p>大致的思路是每个集群的 k8gb 会把自己的 CoreDNS 的 Ingress IP 同样注册到上游 DNS，这样每个集群就可以直接访问另一个集群的 CoreDNS 了。然后每个集群内的 CoreDNS 再按照一个特殊的域名格式比如 <code>localtargets-app.cloud.example.com</code> 来保存本集群内 <code>app.cloud.example.com</code> Ingress 的 Ingress IP 并维护其健康状态。这样每个集群就都可以通过这个特殊的域名来获得其他集群这个域名对应的 Ingress IP 然后加入到自己的返回结果里，实现了域名解析的多集群同步。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>k8gb 作为一款开源的 GSLB 实现了和 Kubernetes 的无缝对接，能够很好的对跨集群的域名和流量进行自动化管理，并且对外部的依赖降到了只需要一个添加 DNS 记录的 API，真正实现了一套可以多云统一的 GSLB 方案。尽管目前这个项目还没有那么火热，但在我心里它已经是这个领域内的最佳方案了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如何将流量在多个 Kubernetes 集群之间进行负载均衡，并做到自动的灾备切换一直是一个让人头疼的问题。我们之前调研了公有云，&lt;a href=&quot;https://github.com/karmada-io/multi-cluster-ingress-nginx&quot;&gt;Karm</summary>
      
    
    
    
    
    <category term="network" scheme="http://oilbeater.com/tags/network/"/>
    
    <category term="kubernetes" scheme="http://oilbeater.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>如何轻松将 AI 生成内容整合入 Logseq 笔记</title>
    <link href="http://oilbeater.com/2024/03/21/sentence-to-logseq/"/>
    <id>http://oilbeater.com/2024/03/21/sentence-to-logseq/</id>
    <published>2024-03-21T10:39:37.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>我的日常生活已经融入了很多 AI 的协助，比如翻译一段文字、解释某个名词、回答一个问题等等。但是频繁使用后发现了另一个问题就是这些 AI 的产出对我的知识来说是个有益的补充，可是使用的时候通常是一次性的解决问题，并没有把这些内容沉淀下来。当需要把他们收集到笔记里的时候还要再回去整理，很是不方便。想象一下，如果这些临时查询的宝贵信息可以自动保存到自己的笔记系统中，就再也不用担心丢失重要的知识片段了。于是就萌生了做个工作流把这些 AI 生成的内容自动存到我的笔记系统里，然后再定期回顾。这里会介绍我调研的一些工具的局限，以及如何用了一个简单的框架把 AI 生成的内容自动导入到 logseq，并做成 flashcard。</p><h1 id="问题分解和初步调研"><a href="#问题分解和初步调研" class="headerlink" title="问题分解和初步调研"></a>问题分解和初步调研</h1><p>这里以我一个日常翻译的场景为例：当遇到读不懂的句子是我希望能够划词翻译，然后让 AI 帮我分析这个句子里疑难的单词，最后把这些内容以 flashcard 的格式保存到 logseq 里，这样借助手机端的同步我就可以在碎片时间来复习这个句子了。所以问题大致就是三个，1. 取出划线的文本 2. 编写一个 prompt 生成我想要的内容 3. 保存到 logseq。</p><p>前两步其实很多工具都已经集成了包括 Raycast AI 和 OpenAI-translator，但是第他们都没提供把前两步的结果导出到第三方的扩展接口。Raycast 理论上可以通过自己的插件体系来完成这件事，但是我这边不太熟悉 JS，并且也不想太依赖 Raycast AI，毕竟后面不打算续费了。于是决定自己写个 python 脚本做这些事，然后通过 Raycast 的 script command 和快捷键直接调用脚本，这样理论上也可以一个快捷键完成整个工作流。</p><h1 id="如何获取划选的文本"><a href="#如何获取划选的文本" class="headerlink" title="如何获取划选的文本"></a>如何获取划选的文本</h1><p>第一个难题就是获取划选的文本，看上去是个操作系统级别的操作，并不是很好实现。直到我看到了一个查词软件的实现我才恍然大悟：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/raycast/script-commands/blob/master/commands/apps/dictionary/look-up-in-dictionary.applescript</span></span><br><span class="line">tell application <span class="string">&quot;System Events&quot;</span></span><br><span class="line">    keystroke <span class="string">&quot;c&quot;</span> using &#123;<span class="built_in">command</span> down&#125;</span><br><span class="line">    delay 0.1</span><br><span class="line">    <span class="keyword">do</span> shell script <span class="string">&quot;open dict://&quot;</span> &amp; the clipboard</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>这个脚本本质上是模拟键盘摁下了 <code>cmd + v</code>，然后直接读剪切板去了，就这么绕过了获取选中文本的问题。考虑到我在用 Raycast 的时候经常碰到划选的文本识别错误，已经养成了 <code>cmd + v</code> 的习惯，那就不用费劲心思找获取划选的文本的方法了，直接读剪贴板就完了。</p><h1 id="调用-AI"><a href="#调用-AI" class="headerlink" title="调用 AI"></a>调用 AI</h1><p>这块基本经轻车熟路了，关键的是设置一个合适的 prompt，在翻译的同时生成一个句子的教学指南，并尽可能的按照 logseq 的格式来输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">message_text = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a university English teacher, below is a paragraph in English. &quot;</span> +</span><br><span class="line">        <span class="string">&quot;Please first translate it into Chinese. Then extract difficult words and phrases from the source paragraph, sort them in descending order of importance choose only the top 3 output them with explain of their usage to me in detail from a linguistic perspective.&quot;</span> +</span><br><span class="line">        <span class="string">&quot;The overall output should look like this: \n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;- &#123;The Chinese Translation&#125; \n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;- Explanation: \n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;  - &#123;word or phrase&#125;: &#123;explanation&#125;\n&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>:<span class="string">&quot;user&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: content</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h1 id="输出到-logseq"><a href="#输出到-logseq" class="headerlink" title="输出到 logseq"></a>输出到 logseq</h1><p>在输出到 logseq 这一步的时候本来是打算调用 logseq 的 API，logseq 的开发者模式提供了一个本地的 HTTP 服务可以通过 HTTP 去调用。但是当我看了他们的 API 文档后差点给整崩溃了，所有的操作都要用 id，page id 又没办法去直接索引，要 getAll 后自己过滤。appendBlock 也不允许插入带层级的 Block，要串好几个 API 才能完成一个简单的操作。</p><p>崩溃的时候转念一想，logseq 不就是一堆 markdown 的渲染器么，既然 API 那么难用我直接去写文件不就好了，于是一组复杂的 API 调用变成了轻松愉快的文件 append 操作。这样既绕开了 logseq API 的限制，甚至有可能接入其他基于 markdown 的笔系统。</p><p>最后完整的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyperclip</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> AzureOpenAI</span><br><span class="line"></span><br><span class="line">content = pyperclip.paste()</span><br><span class="line"></span><br><span class="line">azure_endpoint = <span class="string">&quot;YOUR AZURE ENDPOINT&quot;</span></span><br><span class="line">api_key = <span class="string">&quot;YOUR API KEY&quot;</span></span><br><span class="line">model = <span class="string">&quot;YOUR MODEL NAME&quot;</span></span><br><span class="line">logseq_path = <span class="string">&quot;YOUR LOGSEQ PAGE FILE PATH&quot;</span></span><br><span class="line"></span><br><span class="line">client = AzureOpenAI(</span><br><span class="line">  azure_endpoint = azure_endpoint,</span><br><span class="line">  api_key=api_key,</span><br><span class="line">  api_version=<span class="string">&quot;2024-02-15-preview&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">message_text = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a university English teacher, below is a paragraph in English. &quot;</span> +</span><br><span class="line">        <span class="string">&quot;Please first translate it into Chinese. Then extract difficult words and phrases from the source paragraph, sort them in descending order of importance choose only the top 3 output them with explain of their usage to me in detail from a linguistic perspective.&quot;</span> +</span><br><span class="line">        <span class="string">&quot;The overall output should look like this: \n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;- &#123;The Chinese Translation&#125; \n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;- Explanation: \n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;  - &#123;word or phrase&#125;: &#123;explanation&#125;\n&quot;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;role&quot;</span>:<span class="string">&quot;user&quot;</span>,</span><br><span class="line">        <span class="string">&quot;content&quot;</span>: content</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">completion = client.chat.completions.create(</span><br><span class="line">  model=model, <span class="comment"># model = &quot;deployment_name&quot;</span></span><br><span class="line">  messages = message_text,</span><br><span class="line">  temperature=<span class="number">0.7</span>,</span><br><span class="line">  max_tokens=<span class="number">500</span>,</span><br><span class="line">  top_p=<span class="number">0.95</span>,</span><br><span class="line">  frequency_penalty=<span class="number">0</span>,</span><br><span class="line">  presence_penalty=<span class="number">0</span>,</span><br><span class="line">  stop=<span class="literal">None</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> completion.choices[<span class="number">0</span>].message.content == <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;No response&quot;</span>)</span><br><span class="line">    exit()</span><br><span class="line"></span><br><span class="line">response = completion.choices[<span class="number">0</span>].message.content</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(logseq_path, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&quot;\n- &quot;</span> + content.rstrip() + <span class="string">&quot; #card #English&quot;</span> + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> response.splitlines():</span><br><span class="line">        <span class="keyword">if</span> line.startswith(<span class="string">&quot;```&quot;</span>):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> line.rstrip() == <span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">&quot;- &quot;</span>):</span><br><span class="line">            line = <span class="string">&quot;- &quot;</span> + line.rstrip()</span><br><span class="line">        f.write(<span class="string">&quot;  &quot;</span> + line + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure><p>后需要做的就是在 Raycast 里给这个脚本设置一个快捷键，这样下次碰到不会的句子，选中复制后就可以通过快捷键完成翻译，难点提取，和生成 flashcard 的整个工作流。</p><p>最后生成的 flashcard 效果大概如下：</p><p><img src="/../images/logseq-card.png" alt="alt text"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过将 AI 生成的内容自动化集成到 Logseq 笔记中，我们不仅提高了信息管理的效率，还优化了学习和工作流程。通过一个简单的脚本每个人都可以轻松地将这种强大的技术整合到日常生活中，实现知识的积累和复习。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我的日常生活已经融入了很多 AI 的协助，比如翻译一段文字、解释某个名词、回答一个问题等等。但是频繁使用后发现了另一个问题就是这些 AI 的产出对我的知识来说是个有益的补充，可是使用的时候通常是一次性的解决问题，并没有把这些内容沉淀下来。当需要把他们收集到笔记里的时候还要再</summary>
      
    
    
    
    
    <category term="logseq" scheme="http://oilbeater.com/tags/logseq/"/>
    
    <category term="ai" scheme="http://oilbeater.com/tags/ai/"/>
    
    <category term="learning" scheme="http://oilbeater.com/tags/learning/"/>
    
  </entry>
  
  <entry>
    <title>实现 VS Code Remote SSH 下的自动关机</title>
    <link href="http://oilbeater.com/2024/03/13/shutdown-remote-ssh-server/"/>
    <id>http://oilbeater.com/2024/03/13/shutdown-remote-ssh-server/</id>
    <published>2024-03-13T10:09:26.000Z</published>
    <updated>2025-12-01T03:30:38.488Z</updated>
    
    <content type="html"><![CDATA[<p>我现在所有的开发环境都转移到了 GCP 的 Spot Instance 实例，然后用 VS Code Remote SSH 插件进行连接。这种方式的好处是 GCP 可以按秒计费，即使开了很高规格的机器只要及时关机费用也是可控的，缺点是如果中间忘了关机赶上过节那费用就烧开了。再被烧掉了 10 多美元后，痛定思痛决定找个能在 VS Code 空闲时自动关机的方法。过程中为了能够在 Docker 容器内执行 shutdown 命令还搞了一些黑魔法。</p><h1 id="如何判断空闲"><a href="#如何判断空闲" class="headerlink" title="如何判断空闲"></a>如何判断空闲</h1><p>这个功能其实类似 CodeSpace 里的 idle timeout，但是 Remote SSH 这个插件并没有暴露这个功能，所以只能自己实现。其实主要的难点在于如何在 Server 端判断空闲，找了一圈没在 VS Code 里看到有暴露的接口，于是就想能不能跳出 VS Code 看看有什么方法能够简洁的判断空闲发生。</p><p>最直接的想法就是去看 SSH 的连接，因为 Remote SSH 也是通过 SSH 连接上来的，如果当前机器没有存活的 SSH 连接，那么就可以认为是空闲直接关机了。但是问题是 Remote SSH 的连接超时时间会特别长，搜索了一些 Issue 有说是 4 个小时的，我也尝试了直接关闭 VS Code 的客户端，发现 Server 端的 SSH 连接也一直没有消失。如果在 Server 端设置 SSH 超时，Client 那边很快就会重连，连接数量也不会减少。</p><p>既然没法通过直接看 SSH 连接数量来判断，那么就进一步去看能不能判断已有的 SSH 连接是不是已经没有流量了。用 <code>tcpdump</code> 抓包看了一下，即使客户端没有任何交互，还是会有 1s 一次的 TCP 心跳数据包，所以也不能有流量为 0 来判断。不过观察下来心跳数据包的大小都是固定的，都是 44 字节，正好可以根据这个特征来判断，如果一段时间内 SSH 端口没有大于 44 字节的数据包就可以判断空闲了。</p><p>于是第一版本的脚本就出来了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="keyword">if</span> [ -f /root/dump ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">rm</span> /root/dump</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">timeout</span> 1m tcpdump -nn -i ens4 tcp and port 22 and greater 50 -w /root/dump</span><br><span class="line"></span><br><span class="line">  line_count=$(<span class="built_in">wc</span> -l &lt; /root/dump)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> [ <span class="variable">$line_count</span> -gt 0 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">rm</span> /root/dump</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="built_in">rm</span> /root/dump</span><br><span class="line">    shutdown -h now</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>这样就实现了 1 分钟内 SSH 端口没有非心跳数据包就关机的功能，下一步就是要让这个脚本自动运行了。</p><h1 id="Docker-黑魔法"><a href="#Docker-黑魔法" class="headerlink" title="Docker 黑魔法"></a>Docker 黑魔法</h1><p>在把脚本打包成 Docker 镜像时发现了一个有趣的问题，那就是所有的 Base Image 里都没有 <code>shutdown</code> 命令，<code>shutdown</code> 命令也没法很容易的安装。为了能够执行主机上的 <code>shutdown</code> 命令，就需要在 Docker 容器里切换到主机的命名空间，再去关机。所以需要把之前的脚本稍微修改一下，包装一下 <code>shutdown</code> 命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nsenter -a -t 1 shutdown -h now</span><br></pre></td></tr></table></figure><p>这个 <code>nsenter</code> 命令的作用是选定 Pid 为 1 的进程，然后进入这个进程的所有(pid, mount, network) Namespaces，这样当 Docker 运行在共享主机 Pid 模式下我们相当于就进入了主机 1 号进程的所有 Namespaces，看上去就和 SSH 到主机上一样可以执行操作了。这样只要再用下面的命令启动容器，就可以不担心忘记随时关机了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name=close --pid=host --network=host --privileged --restart=always -d close:v0.0.1</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>通过监控 SSH 的流量情况可以一定程度上猜测 VS Code 已经空闲了，然后再用 Docker 的一些黑魔法就可以实现自动关机了。不过整个链路的黑魔法都太多了，有没有什么简单的方式呢？</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我现在所有的开发环境都转移到了 GCP 的 Spot Instance 实例，然后用 VS Code Remote SSH 插件进行连接。这种方式的好处是 GCP 可以按秒计费，即使开了很高规格的机器只要及时关机费用也是可控的，缺点是如果中间忘了关机赶上过节那费用就烧开了。</summary>
      
    
    
    
    
    <category term="docker" scheme="http://oilbeater.com/tags/docker/"/>
    
    <category term="vscode" scheme="http://oilbeater.com/tags/vscode/"/>
    
    <category term="tools" scheme="http://oilbeater.com/tags/tools/"/>
    
  </entry>
  
</feed>
