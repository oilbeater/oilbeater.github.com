<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Oilbeater 的自习室</title>
  <icon>http://oilbeater.com/icon.png</icon>
  
  <link href="http://oilbeater.com/atom.xml" rel="self"/>
  
  <link href="http://oilbeater.com/"/>
  <updated>2026-01-11T13:26:21.900Z</updated>
  <id>http://oilbeater.com/</id>
  
  <author>
    <name>Oilbeater</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>周报 4 —— 刷剧</title>
    <link href="http://oilbeater.com/2026/01/11/weekly-4/"/>
    <id>http://oilbeater.com/2026/01/11/weekly-4/</id>
    <published>2026-01-11T18:49:00.000Z</published>
    <updated>2026-01-11T13:26:21.900Z</updated>
    
    <content type="html"><![CDATA[<h2 id="娱乐"><a href="#娱乐" class="headerlink" title="娱乐"></a>娱乐</h2><p>最近迷上了补看电视剧，又看了《人民的名义》和《亮剑》，但是由于先看的《潜伏》难免会做一些对比。看了后两部更显的《潜伏》的节奏紧凑，台词没有废话，所有的演员都处在很高的水平，编剧也是自始至终的优秀。</p><p>《人民的名义》的节奏就有点拖，一个事情好几集都绕着转，换成《潜伏》一集可能三四个重要事情都过去了。里面老演员的演技还是不错的，年轻演员感觉都在用力过猛，两边一旦同场景搭戏就让人看着很尴尬。</p><p>看《亮剑》里的平安县争夺战拍出了看三大战役的感觉，还是很过瘾的，不过后面的剧情就急转直下，给人一种烂尾的既视感。</p><p>另外这两部剧很多时候都是靠喊台词来表现人物特点，《潜伏》在这方面就很收敛，更多是通过表情和动作来塑造人物。</p><h2 id="健身"><a href="#健身" class="headerlink" title="健身"></a>健身</h2><p>引体向上现在站在台阶上不用跳可以拉上去了，不过全程还是拉不上去。</p><p>最近做动作膝盖和肩关节的弹响越来越明显了，看了些视频一方面要加强后侧肌肉的训练，还要专门练习一下肩胛骨的活动度。</p><p>睡眠对力量训练的影响还是很大的，稍微一熬夜大重量拉起来就很费劲了。研究一下说是力量除了和肌肉相关也和神经募集能力相关，如果睡眠不足会导致神经无法募集足够的肌肉来发力，从这个角度看健身可能比写代码更费脑子。</p><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><p>Kubernetes 的 <code>managedFileds</code> 在 Informer 缓存的时候可以删掉来节省 client 端的内存占用。我之前一直以为这时候在根据缓存做对象的 Update 操作会出问题，经同事指点其实 APIServer 会在 Update 和 Patch 是忽略没有 <code>managedFileds</code> 的情况，具体可以参考 <a href="https://kubernetes.io/docs/reference/using-api/server-side-apply/#clearing-managedfields">Server Side Apply: clearing managedFields</a></p><p>之前为了标记生成的 Go 二进制对应的是代码的哪个 commit 会在 build 的时候把这个参数传进去，但是 Go 在 1.18 之后的 runtime 里其实默认就带了 VCS 的相关信息，只需要使用 <code>go version -m xxx</code> 就可以从二进制文件里直接获取构建信息了，更多参考 <a href="https://shibumi.dev/posts/go-18-feature/">Go 1.18 debug&#x2F;buildinfo features</a></p><h2 id="AI"><a href="#AI" class="headerlink" title="AI"></a>AI</h2><p>发现了两个适合让 codex 来做的任务：</p><ol><li>每天从竞品的 github 上拉取最近创建的 Issue 和 PR，分析有哪些对改进自己项目有帮助的优化点</li><li>把每天 E2E 的日志下载一份，从日志里来分析有没有潜在的问题和优化点</li></ol><p>最近在做数字骨灰盒时发现其实大部分厂商都提供了视频理解的 LLM，但是 GLM 和 Qwen 只支持 public_url 方式传入视频，对非公开视频不是很友好。而 Gemini 是支持上传文件后再引用文件 ID 的，国内貌似只有 DouBao 支持类似的功能。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;娱乐&quot;&gt;&lt;a href=&quot;#娱乐&quot; class=&quot;headerlink&quot; title=&quot;娱乐&quot;&gt;&lt;/a&gt;娱乐&lt;/h2&gt;&lt;p&gt;最近迷上了补看电视剧，又看了《人民的名义》和《亮剑》，但是由于先看的《潜伏》难免会做一些对比。看了后两部更显的《潜伏》的节奏紧凑，台词没有废</summary>
      
    
    
    
    
    <category term="weekly" scheme="http://oilbeater.com/tags/weekly/"/>
    
  </entry>
  
  <entry>
    <title>周报 3 —— 痔疮上身</title>
    <link href="http://oilbeater.com/2025/12/29/weekly-3/"/>
    <id>http://oilbeater.com/2025/12/29/weekly-3/</id>
    <published>2025-12-29T08:25:00.000Z</published>
    <updated>2026-01-11T13:26:21.900Z</updated>
    
    <content type="html"><![CDATA[<h2 id="痔疮"><a href="#痔疮" class="headerlink" title="痔疮"></a>痔疮</h2><p>居家办公三周后莫名其妙的得了痔疮，前几天都只能躺着了。查了下资料说现代人可能是因为长时间坐马桶导致的，可是我并没有。稍微好一些之后发现只要坐平时办工坐的椅子就会疼，仔细观察发现这个椅子由于长时间胶皮老化中间凹下去了，所以做起来就类似一个马桶两边高中间低，换成个平板椅子就好多了。</p><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><p>对着上周看的 <a href="https://abseil.io/fast/hints.html">Performance Hints</a> 里的一条<a href="https://abseil.io/fast/hints.html#unnecessarily-nested-maps">unnecessarily-nested-maps</a>，拿着锤子找钉子，去 Prometheus 里看看有没有什么蹭 PR 的机会。最终发现这个优化方法还是有很多细节要考虑的，并不是完全没有副作用，尤其在 Prometheus 的场景里有时候完全不适用还会导致性能严重下降，之后可能会单写一个博客来说明。不过好在 Prometheus 里还有一处是完美适合这个优化的，提交了一个 PR <a href="https://github.com/prometheus/prometheus/pull/17732">perf(promql): update matchedSigs to a flat map reduce memory by 97% for GROUP_LEFT</a>，能优化一个常见场景 13% 的 CPU 和 97% 的内存分配。</p><p>看了<a href="https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html">How uv got so fast</a>，和第一直觉认为的 Rust 比 Python 快，所以 uv 才能这么快不同，uv 的快主要还是来自实现架构层面的选择。一方面是 Python 的包管理出了更高效的标准，另一方面 uv 选择放弃了大量的历史兼容性，专注于标准路径的优化。此外还有很多语言无关的优化，比如并行下载，硬链接等等其实是其他语言的依赖管理都有的功能，只是 pip 的历史包袱太大了，一直都没有这方面的优化。</p><p>在逛 Prometheus Issues 是发现一个 <a href="https://github.com/prometheus/prometheus/pull/17734">WIP: tsdb: persist series metadata to Parquet files</a> 需要找时间看一下 Parquet 是个什么存储。</p><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><p>周末和孩子去了<a href="https://j.map.baidu.com/5c/3FQk">城市农场</a>，一开始以为是个什么网红景点，去了后发现是个正经的科研机构，中国奶牛的育种就是从这里开始的。里面都是些看上去六七十年代的老房子，有科研人员专门负责讲解，体验还是很不错的。另一方面想到自己小时候没有盒装奶还都是牧场每天早上和报纸一块送的鲜牛奶要拿回家去煮。</p><p>里面有从刚出生到三四岁的奶牛，可以自己去喂，小孩抱着草料来回跑喂了快一个小时。</p><p><img src="/../images/585200c8615451436d3d3387ab65f7591.jpg"></p><h2 id="娱乐"><a href="#娱乐" class="headerlink" title="娱乐"></a>娱乐</h2><ul><li>要打仗先修路 <a href="https://www.bilibili.com/video/BV1qwBWBXE32/?spm_id_from=333.1391.0.0">【不懂地理打不了仗】3D地形全面复盘蜀汉立国之战——汉中之战！</a> </li><li>可汗的充电视频 <a href="https://www.bilibili.com/video/BV1oMBUBREK8/?spm_id_from=333.1391.0.0">赠予沙阿（上） 伊朗·1951</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;痔疮&quot;&gt;&lt;a href=&quot;#痔疮&quot; class=&quot;headerlink&quot; title=&quot;痔疮&quot;&gt;&lt;/a&gt;痔疮&lt;/h2&gt;&lt;p&gt;居家办公三周后莫名其妙的得了痔疮，前几天都只能躺着了。查了下资料说现代人可能是因为长时间坐马桶导致的，可是我并没有。稍微好一些之后发现只要坐</summary>
      
    
    
    
    
    <category term="weekly" scheme="http://oilbeater.com/tags/weekly/"/>
    
  </entry>
  
  <entry>
    <title>周报 2 —— 开源 and AI</title>
    <link href="http://oilbeater.com/2025/12/21/weekly-2-oss-ai/"/>
    <id>http://oilbeater.com/2025/12/21/weekly-2-oss-ai/</id>
    <published>2025-12-21T20:43:00.000Z</published>
    <updated>2026-01-11T13:26:21.900Z</updated>
    
    <content type="html"><![CDATA[<h2 id="开源"><a href="#开源" class="headerlink" title="开源"></a>开源</h2><p>最近社区的 PR 越来越多，由于 AI 的增强，每个 PR 膨胀的也很厉害，Review 的难度也越来越大。一直以来我对 PR 的合并手都比较松，现在合并一个新功能不强制有 proposal，不强制有测试，文档有时候甚至都是我后来再写的。如果从教条的开源社区规范来看，这个项目的治理，社区，文档都是乱哄哄的。代码债也到处都是，我最近初步梳理了几个文件就费了好大的劲。如果不是借助 AI 好多重构的活会更难。</p><p>不过从我的价值倾向来看，相比规范性，我更注重的还是一个项目是不是真的有用。尽管不规范会带来长期的隐患，但是保持这个项目一直有用就有机会等到后人有智慧来解决。</p><h2 id="AI"><a href="#AI" class="headerlink" title="AI"></a>AI</h2><p>最近在反思之前用 AI 的一些方法，在习惯了自己不动手一把梭后，感觉自己阅读代码和复杂内容的耐心也下降了。或许以后确实 AI 可以做所有脑力劳动了，那么脑力劳动可能就变成现在的健身房了，未来人类需要和现在刻意锻炼肌肉一样才能保证脑力不流失。</p><p><a href="https://github.com/slopus/happy">happy</a> 一个能在手机上控制开发机上 codex 和 claude code 的工具，这样不在电脑前也能抽 AI 干活了。</p><h2 id="健身"><a href="#健身" class="headerlink" title="健身"></a>健身</h2><p>10kg 哑铃片到货，视觉上还是有些吓人。</p><p><img src="/../images/20251221192028.png"></p><p>全程的引体向上还是做不了，不过肩胛骨旋转的感觉找到一些了，离心可以做全程了。</p><p>连续三周上重量后，这周五的时候明显感觉硬拉拉不动了，下周打算做个减载周。</p><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><p><a href="https://www.youtube.com/watch?v=nFuEy9D4GGM">OpenShift Roadmap</a> OpenShift 更新了未来一年的 RoadMap，公司里如果还有上了年纪的人可能会关心。</p><p><a href="https://valkey.io/blog/new-hash-table/">A new hash table </a> 是 Valkey 的一个 hash table 实现变种，主要目的是为了节省内存体积和内存访问次数。这种把数组和链表组合的思路能够兼顾顺序访问的效率和链表无限扩容还是挺有意思。不过后来又看了下其他的 hash table 实现，发现这好像就是 Golang 在使用 Swiss Table 之前的实现。</p><p><a href="https://github.com/starbops/kubevirtbmc">kubevirtbmc</a> 一个对接 KubeVirt 和传统物理机 BMC 协议的工具，能把 IPMI 和 Redfish API 的调用转换成 KubeVirt 的 API。这样用就能复用之前管理物理机的工具和流程来管理 KubeVirt 的虚拟机了。</p><p><a href="https://abseil.io/fast/hints.html">Performance Hints</a> Jeff Dean 和另一个 Google 初创时的工程师 <a href="https://research.google/people/sanjayghemawat/">Sanjay Ghemawat</a> 写的性能优化手册。和大部分性能优化都是先 profile 找到热点再优化不同，这个手册介绍的主要是火焰图上看不到热点的时候如何怎么榨取性能。 因此里面介绍的全都是微操，针对 common case 做 fast path 已经算是最大块的优化方法了。里面有不少在 search 和 tensorflow 上做微操的例子，看上去还是很过瘾的。</p><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><p>海底捞的海螺片和鞭炮笋很好吃，推荐尝试，新出的猪肉卷就不要试了。另一个感叹是海底捞现在已经变成了个家庭聚餐的地方，满屋子都是过生日的，而在几年前我一直以为这是个工作或者同学聚餐的地方。</p><p>中午逛公园走了条平时没走的小路，上了段城墙，然后发现了传说中的“蓟门烟树”，我一直以为是什么古树，原来是个石碑，看介绍是乾隆题的字。</p><p><img src="/../images/68598f7ac4dc3dcf030684b75d8e4af5.jpg"></p><p>去了平西府地铁站新开的小站公园，公园用的一个人物形象名字是“下腰女孩（Tireless Girl）”。虽然我能勉强搞明白下腰和 Tireless 的关系，但这个翻译实在是太奇怪了。</p><p><img src="/../images/6ad0dd8d1e1f02966a5221d9cd2ab8ac.jpg"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;开源&quot;&gt;&lt;a href=&quot;#开源&quot; class=&quot;headerlink&quot; title=&quot;开源&quot;&gt;&lt;/a&gt;开源&lt;/h2&gt;&lt;p&gt;最近社区的 PR 越来越多，由于 AI 的增强，每个 PR 膨胀的也很厉害，Review 的难度也越来越大。一直以来我对 PR 的合并手都比</summary>
      
    
    
    
    
    <category term="weekly" scheme="http://oilbeater.com/tags/weekly/"/>
    
  </entry>
  
  <entry>
    <title>周报 1 —— 远程办公</title>
    <link href="http://oilbeater.com/2025/12/15/weekly-1/"/>
    <id>http://oilbeater.com/2025/12/15/weekly-1/</id>
    <published>2025-12-15T07:46:00.000Z</published>
    <updated>2026-01-11T13:26:21.900Z</updated>
    
    <content type="html"><![CDATA[<h2 id="远程办公"><a href="#远程办公" class="headerlink" title="远程办公"></a>远程办公</h2><p>这是第二周远程办公，专注度相比上一周出现了很大起伏。上一周基本上能从早上起来一直拉满到晚上，这周注意力有所下降。</p><p>想了一下上周社区的问题比较多，基本是问题驱动的，自己不需要去考虑要做什么。这周问题少了空下来很多时候就没想法了。还是需要开启 Plan 模式，多做一些规划，给自己分配一些明确的任务。</p><h2 id="健身"><a href="#健身" class="headerlink" title="健身"></a>健身</h2><p>这周花了些时间把<a href="https://www.youtube.com/@UncleZhuo">卓叔增重</a>和<a href="https://www.youtube.com/@kaizen_wang9356/">凯圣王Kaizen_Wang</a> 的动作视频看了一遍。随着力量增加，一些之前看不懂的动作细节和找不到的发力感，现在渐渐能体会到了。再仔细看一遍争取每次动作都有进步。</p><p>这周做深蹲和硬拉已经能把单只 18kg 的哑铃片加满了，然后发现个问题就是这个重量做深蹲已经不太能靠手臂的力量把哑铃撑到肩上了，危险系数陡增。深蹲还能考虑换单腿，硬拉还是要加重量了。趁着双十二 pdd 了四个 10kg 哑铃片，估计能再撑几个月了。</p><h2 id="数字骨灰盒"><a href="#数字骨灰盒" class="headerlink" title="数字骨灰盒"></a>数字骨灰盒</h2><p>我一直有个想法是把看到的所有东西都记录下来，然后借助 AI 的能力能不断检索一个人，甚至重建一个人。之前我的想法是感觉这个事情只能放在眼睛上来做，但是最近想法有变化，发现其实只要在我们日常接触的主要屏幕，比如电脑和手机上做记录也可以达到接近的效果。于是开始仔细的去看几个开源项目：<a href="https://github.com/JerryZLiu/Dayflow">DayFlow</a>, <a href="https://github.com/mediar-ai/screenpipe">ScreenPipe</a> 和 <a href="https://github.com/openrecall/openrecall">OpenRecall</a>。</p><p>这个过程中发现了很多我之前的知识盲区。一个是这里面有的项目是通过截图去记录屏幕信息，但是会通过视频的形式进行存储，原因是视频的压缩率会更高一些。我尝试了一下 5s 的频率截取了 120 张图片，用 zip 普通压缩一下还是有将近 400M，而用 FFmpeg 转成 1FPS 的视频后只需要 3.4M。</p><p>第二个是我才注意到 Gemini 是有视频模态的，这应该是目前主流 AI 厂商里少有的具有视频理解能力的。</p><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><p>这周内部同事分享了 ZCF 的<a href="http://zcf.ufomiao.com/zh-CN/workflows/zcf-workflow">六阶段工作流</a>，我比较感兴趣它的实现方式。一般用 coding agent 使用 agent.md 其实不太好控制工作流，因为有的时候是写功能，有的时候是排查故障，有的时候是重构，不同的目标使用的工作流其实是不一样的。而 agent.md 里即使根据各种情况写了工作流，也还需要 AI 工具能自动分析出是哪种情况，并且多轮对话的时候很容易出现不一致的情况。ZCF 是通过 command 来实现，需要用户显式去说明用哪个工作流，感觉上不是太智能，但其实实际中用起来一致性应该会更好。</p><p>这周还发现 <a href="https://www.openvswitch.org/support/ovscon2025/">OVS+OVN Con 2025</a> 的视频和 Slide 已经上传了，下周找时间过一下。粗看一个感兴趣的议题 <a href="https://www.openvswitch.org/support/ovscon2025/#t19">Deprecating Code</a> 看样子 OVS 要移除对 Windows 的支持了，原因是没人知道该怎么维护，甚至没人知道是不是还能正常工作，当然从我们团队同事之前的经验看在最新的 Windows 上已经不太正常了，这样我也可以顺带着清理一波代码了。</p><h2 id="娱乐"><a href="#娱乐" class="headerlink" title="娱乐"></a>娱乐</h2><p>这周看了<a href="https://movie.douban.com/subject/26817136/">《疯狂动物城 2》</a>，还是标准的迪士尼套路，没有啥太多的惊喜。和年初的<a href="https://movie.douban.com/subject/34780991/">《哪吒之魔童闹海》</a>比，还是能看出明显的文化区别。动物城目标群体是全球用户，所以选了没啥文化背景理解需求的动物做主角，而哪吒明显是个中国文化故事，甚至能看到对<a href="https://movie.douban.com/subject/1307315/">《哪吒闹海》</a>和<a href="https://movie.douban.com/subject/25805054/">《十万个冷笑话》</a>的致敬。动物城是个中规中矩的工业品，而哪吒是有着很鲜明作者特色和作者表达的作品。我对动物城票房数字唯一的理解就是这一年除了哪吒就再也没有一个水平线上的电影作品了。</p><p>最近迷上了看<a href="https://movie.douban.com/subject/3314870/">《潜伏》</a>的解读，主要看了 B 站 Up 弥先生碎碎念的<a href="https://space.bilibili.com/14582269/lists/5098470?type=season">《细讲潜伏》</a>系列。之前只是觉得台词好，演技好，解读后才发现编剧是多么的厉害，历史背景有多么复杂。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;远程办公&quot;&gt;&lt;a href=&quot;#远程办公&quot; class=&quot;headerlink&quot; title=&quot;远程办公&quot;&gt;&lt;/a&gt;远程办公&lt;/h2&gt;&lt;p&gt;这是第二周远程办公，专注度相比上一周出现了很大起伏。上一周基本上能从早上起来一直拉满到晚上，这周注意力有所下降。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    
    <category term="weekly" scheme="http://oilbeater.com/tags/weekly/"/>
    
  </entry>
  
  <entry>
    <title>从 NetworkPolicy 到 ClusterNetworkPolicy</title>
    <link href="http://oilbeater.com/2025/11/30/networkpolicy-to-clusternetworkpolicy/"/>
    <id>http://oilbeater.com/2025/11/30/networkpolicy-to-clusternetworkpolicy/</id>
    <published>2025-11-30T09:45:00.000Z</published>
    <updated>2026-01-11T13:26:21.900Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">NetworkPolicy</a> 作为 Kubernetes 早期的 API 看似美好，实际使用过程中就会发现它功能有限，不易扩展，不易理解且不易使用。因此 Kubernetes 成立了 <a href="https://network-policy-api.sigs.k8s.io/">Network Policy API Working Group</a> 来制订下一代的 API 规范，而 <a href="https://network-policy-api.sigs.k8s.io/api-overview/#the-clusternetworkpolicy-resource">ClusterNetworkPolicy</a> 就是目前探讨出来的最新成果，未来可能会成为新的规范。</p><h2 id="NetworkPolicy-的局限性"><a href="#NetworkPolicy-的局限性" class="headerlink" title="NetworkPolicy 的局限性"></a>NetworkPolicy 的局限性</h2><p>NetworkPolicy 是 Namespace 级资源，本质上是“应用视角”的策略。它通过 podSelector、namespaceSelector 来选中一批 Pod，然后对这些 Pod 的 Ingress、Egress 做限制。这带来了几个实际的问题：</p><h3 id="缺少-Cluster-级别的控制"><a href="#缺少-Cluster-级别的控制" class="headerlink" title="缺少 Cluster 级别的控制"></a>缺少 Cluster 级别的控制</h3><p>由于策略的作用域是 Namespace，集群管理员无法定义集群级别的默认网络策略，只能在每个 Namespace 里都创建相同的网络策略。这样一方面每次更新策略需要对所有 Namespace 下的资源进行更新，另一方面，很容易和开发者创建的网络策略产生冲突。管理员设置的策略，应用侧很容易就可以通过新的策略绕过去。</p><p>本质上在于 NetworkPolicy 这种应用视角的策略和管理员集群视角的策略存在冲突，当用户的安全模型并不是应用视角的时候 NetworkPolicy 就会变得难以应用。而集群管理员管控集群整体的安全策略是个现实中很常见的场景。</p><h3 id="语义不清晰"><a href="#语义不清晰" class="headerlink" title="语义不清晰"></a>语义不清晰</h3><p>NetworkPolicy 的语义有几个“坑”，新手和运维人员都容易踩：</p><ul><li><p>隐式隔离。<br>  一旦有任何 NetworkPolicy 选中了某个 Pod，那么“未被允许”的流量就会被默认拒绝。这种隐式的行为需要靠心算来推导，很难一眼看懂。</p></li><li><p>只有允许，没有显式拒绝。<br>  标准 NetworkPolicy 只能写 allow 类型的规则，想要“拒绝某个来源”，通常要通过补充其他 allow 规则间接实现，或者依赖某些 CNI 厂商特有的扩展。</p></li><li><p>没有优先级。<br>  多个 NetworkPolicy 选择同一批 Pod 时，规则是加法而不是覆盖关系。最终行为往往需要把所有策略合在一起看，排查问题时非常困难。</p></li></ul><p>这些特点叠加在一起，就会导致 NetworkPolicy 理解起来困难，调试起来更困难。</p><h2 id="ClusterNetworkPolicy-的解决方案"><a href="#ClusterNetworkPolicy-的解决方案" class="headerlink" title="ClusterNetworkPolicy 的解决方案"></a>ClusterNetworkPolicy 的解决方案</h2><p>为了解决 NetworkPolicy 固有的问题，Network Policy API 工作组提出了一个新的 API —— ClusterNetworkPolicy (CNP)，它的目标是在不破坏现有 NetworkPolicy 用法的前提下，给集群管理员提供一个更清晰、更强大的网络控制能力。</p><p>其最核心的思路是引入策略分层，在现有的 NetworkPolicy 之前和之后分别引入独立的策略层，将集群管理员的策略和应用的策略分开，提供了更丰富的视角和更灵活的使用。</p><p><img src="/../images/20251201104247.png"></p><p>一个示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">policy.networking.k8s.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterNetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sensitive-ns-deny-from-others</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tier:</span> <span class="string">Admin</span></span><br><span class="line">  <span class="attr">priority:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">subject:</span></span><br><span class="line">    <span class="attr">namespaces:</span></span><br><span class="line">      <span class="attr">matchLabels:</span></span><br><span class="line">        <span class="attr">kubernetes.io/metadata.name:</span> <span class="string">sensitive-ns</span></span><br><span class="line">  <span class="attr">ingress:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">action:</span> <span class="string">Deny</span></span><br><span class="line">      <span class="attr">from:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">namespaces:</span></span><br><span class="line">            <span class="attr">matchLabels:</span> &#123;&#125; </span><br><span class="line">      <span class="attr">name:</span> <span class="string">deny-all-from-other-namespaces</span></span><br></pre></td></tr></table></figure><h3 id="集群管理员视角"><a href="#集群管理员视角" class="headerlink" title="集群管理员视角"></a>集群管理员视角</h3><p>新引入的 ClusterNetworkPolicy 是集群级别资源，管理员可以直接选中多个 Namespace 下的 Pod 进行策略控制。同时 Admin Tier 的策略可以先于 NetworkPolicy 生效，这样集群管理员只需要少量的 Admin Tier 策略就可以控制住整个集群的红线行为。</p><p>而 Baseline Tier 的策略在所有 NetworkPolicy 都不匹配后执行，相当于提供了一个兜底策略。</p><p>简单来说：</p><ul><li><code>tier: Admin</code> 的策略用来定义<strong>绝对不能做</strong>的事情。</li><li><code>tier: Baseline</code> 的策略用来定义<strong>默认不建议做</strong>的事情，用户可以通过 NetworkPolicy 来放行。</li></ul><h3 id="明确的优先级"><a href="#明确的优先级" class="headerlink" title="明确的优先级"></a>明确的优先级</h3><p>ClusterNetworkPolicy 中新增了 <code>priority</code> 字段，这样在同一个 Tier 中多个规则的范围出现重叠时，可以通过优先级清晰的界定哪个规则该生效，不会再出现 NetworkPolicy 里那种隐式覆盖，需要互相猜测的情况。</p><h3 id="清晰的动作语义：Accept-Deny-Pass"><a href="#清晰的动作语义：Accept-Deny-Pass" class="headerlink" title="清晰的动作语义：Accept &#x2F; Deny &#x2F; Pass"></a>清晰的动作语义：Accept &#x2F; Deny &#x2F; Pass</h3><p>和 NetworkPolicy 只有“允许”语义不同，ClusterNetworkPolicy 的每条规则都有一个显式的 <code>action</code> 字段，可以取值：</p><ul><li><code>Accept</code>：允许这条规则选中的流量，并停止后续策略评估</li><li><code>Deny</code>：拒绝这条规则选中的流量，并停止后续策略评估</li><li><code>Pass</code>：在当前 tier 里跳过后续 ClusterNetworkPolicy，交给下一层继续评估</li></ul><p>同时，文档中特别强调：</p><ul><li>ClusterNetworkPolicy 不再有 NetworkPolicy 那种“隐式隔离”的效果</li><li>所有行为都来自你写的规则本身，读策略时看到什么就是什么</li></ul><p>结合优先级的配置，规则的理解就不再会产生模糊的情况，理解上也变得不那么困难。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>ClusterNetworkPolicy 一定程度上回归了传统的分层网络策略的架构，在解决了 NetworkPolicy 问题的情况下没有带来破坏性的变化，可以说是一个很不错的设计，希望能尽快看到这个规范的成熟和落地。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/services-networking/network-policies/&quot;&gt;NetworkPolicy&lt;/a&gt; 作为 Kubernetes 早期的 API 看似美好，实际使用过程中就</summary>
      
    
    
    
    
    <category term="network" scheme="http://oilbeater.com/tags/network/"/>
    
    <category term="opensource" scheme="http://oilbeater.com/tags/opensource/"/>
    
  </entry>
  
  <entry>
    <title>OpenPERouter：把 EVPN 带入 Kubernetes</title>
    <link href="http://oilbeater.com/2025/11/09/kubernetes-evpn/"/>
    <id>http://oilbeater.com/2025/11/09/kubernetes-evpn/</id>
    <published>2025-11-09T04:29:02.000Z</published>
    <updated>2026-01-11T13:26:21.900Z</updated>
    
    <content type="html"><![CDATA[<p>目前社区在 Kubernetes 实现网络多租户主流选型是 <a href="https://github.com/kubeovn/kube-ovn">Kube-OVN</a> 和 <a href="https://github.com/ovn-kubernetes/ovn-kubernetes">ovn-kubernetes</a>，这两个方案本质上都是在物理网络上通过 OVS 和 OVN 的能力构建了一层 Overlay 虚拟网络。这种方案不太关心底层物理网络架构，有着比较好的兼容性，但是双层网络架构也加大了整体架构的复杂度。</p><p>最近我在调研 EVPN 这种物理网络多租户的方案，发现了 <a href="https://github.com/openperouter/openperouter">OpenPERouter</a> 这个开源项目，他把 EVPN 的理念引入了容器网络，提供了一种新的在 Kubernetes 上实现多租户的方案。该方案不仅能统一软硬件网络架构，还在一定程度上能兼容现有 Calico 这种通过 BGP 方式发布路由的 CNI，我甚至已经看到通过少量工作就可以让 Calico 具备多租户能力的前景。虽然这个项目还在早期，但我认为这是一个相当不错的方向，未来很可能会成为构建大规模数据中心的一个有竞争力选型。</p><h2 id="OVN-类方案的局限性"><a href="#OVN-类方案的局限性" class="headerlink" title="OVN 类方案的局限性"></a>OVN 类方案的局限性</h2><p>OVN 类方案的主要局限性有两个一个是集中式控制平面的规模限制，另一个就是网络复杂度。</p><h3 id="集中式控制平面"><a href="#集中式控制平面" class="headerlink" title="集中式控制平面"></a>集中式控制平面</h3><p>尽管 Kube-OVN 在社区已经存在了上千节点的大规模案例，但是由于 OVN 这种集中式控制面的架构，会导致控制面存在比较大的压力，成为整个集群的瓶颈。特别是在控制面节点断电或者故障时，可能会需要较长时间网络控制面才能恢复。</p><p><img src="/../images/ovn-limit.png" alt="ovn-limit"></p><p>这个问题主要是由 OVN 集中式控制平面的架构带来的，无法完全规避。ovn-kubernetes 中采用了每个节点一个 OVN 控制平面，多节点之间通过 OVN-IC 互联的方案来规避这个瓶颈。但是这个方案同时也会导致架构的复杂，并且相当于主动弃用了 OVN 本身的集群网络能力，使得大量的 OVN 能力无法使用。</p><h3 id="网络复杂度"><a href="#网络复杂度" class="headerlink" title="网络复杂度"></a>网络复杂度</h3><p>另一个问题就在于 OVS&#x2F;OVN 这套体系本身的复杂度，使用者需要重新再构建一套 OVN 规范下的网络拓扑，流表的知识体系才能保证自己面对实际问题时不会手足无措。而这套体系和底层的物理网络往往又是不同的，实际中相当于存在两套网络体系，这不仅会使问题排查变得更复杂，还会导致需要物理网络团队和容器网络团队两套人马，双方往往都无法理解彼此的工作内容，无法有效协同。</p><p>以上两个局限性更多的是选型上的取舍，如果希望能够软件集中控制，希望容器网络能不关心底层物理网络，那这样的选择必然就会带来这样的局限性。</p><h2 id="EVPN"><a href="#EVPN" class="headerlink" title="EVPN"></a>EVPN</h2><p>在和 OVS 这种纯软件方案平行的另一个硬件世界，有另一套硬件版本的多租户网络方案，那就是 EVPN。</p><p>在 EVPN 的世界里，在数据平面交换机之间通过 Vxlan 对数据包做封装，通过在 Vxlan 的 Header 中设置 VNI 来区分不同租户的流量，实现了流量的隔离。</p><p>同时，交换机之间通过 BGP 在控制平面来同步 L2&#x2F;L3 的路由以及 VNI 的信息，能够快速的学习整个网络拓扑中的地址，路由和租户信息。 </p><p><img src="/../images/evpn.png" alt="EVPN"></p><p>通过这种方式，大型数据中心可以自动化分布式的实现多租户网络。这套方案在很多大型数据中心都已经落地了，主流的交换机目前也都已经支持。那么在容器领域有没有基于这种技术架构做网络的呢？这就是我最近发现的 OpenPERouter 了。</p><h2 id="OpenPERouter"><a href="#OpenPERouter" class="headerlink" title="OpenPERouter"></a>OpenPERouter</h2><p>OpenPERouter 的核心理念是将 EVPN 交换机的逻辑下沉到节点，在每台机器上运行一个 FRR 通过直接和物理交换机建立 BGP 和 VXLAN 隧道，将容器网络直接打通到已有的 EVPN 架构的物理网络。</p><p><img src="/../images/openperouter.png"></p><p>现有的容器网络想接入 OpenPERouter 也并不算复杂，基于 BGP 的 CNI 需要和 OpenPERouter 建立 BGP Peer；对于基于 veth 和网桥的 CNI，需要把原来在宿主机一侧的 veth 改为接入到 OpenPERouter 所在的 net ns 即可。</p><p>这个方案带来了一些独特的优点：</p><ol><li>统一了底层网络和容器网络，两者采用了相同的 EVPN 架构，虽然在具体操作，软件使用上还有区别，但整体的思路已经基本一致了。</li><li>极其轻量的方式就实现了 Underlay 和多租户这两个在容器网络里比较困难的功能，由于主要的控制面和数据面都在硬件层，容器网络只是做接入，理论上 CNI 层可以做的十分轻量化。</li><li>可以将已有的 CNI 转换为多租户的 CNI，尽管项目的开发者没有具体提这个事情，但是我已经看到了给 Calico 的 IPPool 增加一个 VNI 的配置就能快速把 Calico 改造成一个多租户网络的可能性。</li></ol><p>当然这个方案当前也有它的局限性：</p><ol><li>统一的网络也就意味着容器网络完全侵入了底层物理网络，这需要有统一的团队管理，这在当前的环境可能会产生很多办公室政治问题</li><li>OpenPERouter 目前自己并没有做 CNI 相关的事情，而是尝试接入其他网络项目。这可能是考虑到当前已有多种主流方案可供选择，但从我来看接入其他 CNI 反而会让这个简洁的 EVPN 方案变的比原来更复杂，未来发生不兼容和冲突也是大概率事件。基于这个思路从头做一个轻量化的专门面向 EVPN 设计的 CNI 会是个更优雅的选择。</li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在我看来，EVPN 会是未来容器网络里的一个极其有竞争力的技术方案，但是当下并没有很成熟的开源项目，OpenPERouter 做了很好的尝试，我也很希望看到未来有一款专门为 EVPN 架构设计的 CNI 能够大幅简化全局的网络设计。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;目前社区在 Kubernetes 实现网络多租户主流选型是 &lt;a href=&quot;https://github.com/kubeovn/kube-ovn&quot;&gt;Kube-OVN&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/ovn-kubernetes/ovn</summary>
      
    
    
    
    
    <category term="EVPN" scheme="http://oilbeater.com/tags/EVPN/"/>
    
    <category term="Kubernetes" scheme="http://oilbeater.com/tags/Kubernetes/"/>
    
    <category term="Network" scheme="http://oilbeater.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>LoxiLB -- More than MetalLB</title>
    <link href="http://oilbeater.com/2025/08/15/loxilb-metallb/"/>
    <id>http://oilbeater.com/2025/08/15/loxilb-metallb/</id>
    <published>2025-08-15T14:48:00.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/metallb/metallb">MetalLB</a> 目前几乎成了私有云场景下 Kubernetes 提供 LoadBalancer 类型 Service 的事实标准。他的实现逻辑简单清晰，并且功能单一，基于 Gossip 的分布式选主也保证了 VIP 的漂移可以做到迅速且不依赖 Kubernetes 的状态。但是它在专注的情况下也缺少了一些在生产环境极为重要的功能，这也是为什么我最近在调研其他的开源项目，并发现了 <a href="https://github.com/loxilb-io/loxilb">LoxiLB</a> 这个很不错的 MetalLB 替代项目。</p><h2 id="MetalLB-的缺陷"><a href="#MetalLB-的缺陷" class="headerlink" title="MetalLB 的缺陷"></a>MetalLB 的缺陷</h2><p>MetalLB 虽有 LB 之名，但实际上并不处理任何转发平面的工作。严格来说它只提供了 VIP 的对外通告能力，所有转发平面的事情都是依赖 kube-proxy 或者各类的 kube-proxy 的替代 来实现。这样的好处是它可以专注在提供各种类型的 VIP 宣告方式，并且能和 Kubernetes 本身的行为保持最大的兼容性，但同时由于 kube-proxy 本身孱弱的能力，也限制了 MetalLB 本身的功能。</p><h3 id="缺乏主动健康检查"><a href="#缺乏主动健康检查" class="headerlink" title="缺乏主动健康检查"></a>缺乏主动健康检查</h3><p>这是 Kubernetes 由来已久的一个问题，Service 后端的 Endpoint 健康状态依赖 Pod 本身的 ReadinessProbe&#x2F;LivenessProbe，Probe 的执行依赖当前节点的 kubelet。造成的结果就是断电或类似的直接宕机情况下 kubelet 无法更新 Pod 的健康状态，需要等到触发 node not ready 的超时才会修改 Pod 监控状态，通常在大集群这个超时可能会有数分钟，导致这段时间内访问 Service 会出现失败。</p><p>严格来说这并不是 MetalLB 的问题，但是由于 MetalLB 本身对数据转发平面没有任何控制能力，无法主动探测 Pod 真实健康情况也无法修改 Pod 健康状态，只能被动接受这种机制。</p><p>虽然通过 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate">Pod ReadinessGates</a> 可以使用额外的 controller 主动探测来控制 Pod 健康状态，间接解决这个问题，但对于 MetalLB 来说这个也和它没有什么关系，并没有能开箱即用的方案，这对生产环境还是个很大的隐患。</p><h3 id="缺乏有效的监控"><a href="#缺乏有效的监控" class="headerlink" title="缺乏有效的监控"></a>缺乏有效的监控</h3><p>这同样是依赖 kube-proxy 实现导致的一个问题，kube-proxy 的多种实现方式都没有流量层面的监控，导致的后果就是如果你看 MetalLB 提供的<a href="https://metallb.universe.tf/prometheus-metrics/">监控指标</a>就会发现里面没有任何流量的指标。这种几乎没有任何数据平面监控的 LB 要上生产，就有点过于松弛了。</p><h2 id="LoxiLB-的改进"><a href="#LoxiLB-的改进" class="headerlink" title="LoxiLB 的改进"></a>LoxiLB 的改进</h2><p>LoxiLB 本身是一个为电信场景的特殊需求，使用 eBPF 打造的专用 LB，它完全实现了控制平面和数据平面是一个完整的 LB 实现。LoxiLB 本身的功能十分多，尤其在 SCTP 领域有十分多专属能力，这里不赘述只是重点看一下针对 MetalLB 缺陷的补足。</p><h3 id="主动健康检查"><a href="#主动健康检查" class="headerlink" title="主动健康检查"></a>主动健康检查</h3><p>LoxiLB 可以给每个 Service 配置<a href="https://docs.loxilb.io/latest/cmd/#create-end-point-for-health-probing">主动健康检查</a>，支持 ping, tcp, udp, sctp, http, https 也支持超时，重试之类的细粒度配置，虽然称不上多优秀，但 MetalLB 就是没有这个功能，这就显得很尴尬。</p><h3 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h3><p>这一点就是 eBPF 的强项了，LoxiLB 内置了不少 <a href="https://docs.loxilb.io/latest/loxilb-incluster-grafana/">Metrics 和 Grafana 面板</a>，此外由于数据平面是自己实现的，添加各类监控指标也相对容易一些。</p><h3 id="潜在的风险"><a href="#潜在的风险" class="headerlink" title="潜在的风险"></a>潜在的风险</h3><p>整体来看 LoxiLB 是一个我很喜欢的项目，甚至很多关于 SCTP 协议的理解我都是看了它的一些配置才能理解是怎么回事。但是他还是有着一些不足的地方：</p><ul><li>选主的逻辑目前还是 Kubernetes 那套 Leader Election 逻辑，但我更喜欢 MetalLB 那种与 Kubernetes 解耦的选主逻辑。</li><li>文档整体比较凌乱，虽然文档内容很多但是组织的不是很好，好多配置得靠搜索才能找到，一些文档格式也存在问题。</li><li>虽然该项目是 CNCF 沙箱项目，但是整体的活跃度和参与度还是偏低，能感觉出来该项目应该还是个比较成熟的内部项目拿了出来，但是如果社区采用度比较低的话未来还是有些隐患。</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>MetalLB 依然是一个我很喜欢的项目，它极其精准地解决了 VIP 宣告及高可用的问题，但是如果达到生产上完备的状态还需要配合其他组件。LoxiLB 则是一套完整的 LB 解决方案，但是社区的发展还处于早期，还有待更多人的参与。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://github.com/metallb/metallb&quot;&gt;MetalLB&lt;/a&gt; 目前几乎成了私有云场景下 Kubernetes 提供 LoadBalancer 类型 Service 的事实标准。他的实现逻辑简单清晰，并且功能单一，基于 Go</summary>
      
    
    
    
    
    <category term="metallb" scheme="http://oilbeater.com/tags/metallb/"/>
    
    <category term="loxilb" scheme="http://oilbeater.com/tags/loxilb/"/>
    
  </entry>
  
  <entry>
    <title>GoBGP 快速上手</title>
    <link href="http://oilbeater.com/2025/07/08/gobgp-guide/"/>
    <id>http://oilbeater.com/2025/07/08/gobgp-guide/</id>
    <published>2025-07-08T22:48:00.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>在做 MetalLB 和 Calico 的一些测试时需要验证 BGP 相关的功能，然而每次测试要去联系运维团队配合网络变更是不太现实的，并且大多数情况我们只要验证 BGP 信息正常交换就可以了，不需要真的去改变物理网络。于是就找到了 <a href="https://github.com/osrg/gobgp">GoBGP</a> 这个软件路由器进行模拟。</p><p>GoBGP 本身有着很复杂的配置，但是如果你只是像我一样只是想有个虚拟的路由器，让客户端把 BGP 信息发送过来，检查路由表信息是否正确更新，那看这篇文章就可以了。</p><h2 id="下载-GoBGP-二进制文件"><a href="#下载-GoBGP-二进制文件" class="headerlink" title="下载 GoBGP 二进制文件"></a>下载 GoBGP 二进制文件</h2><p>去 <a href="https://github.com/osrg/gobgp/releases">Release</a> 制品列表里找到对应系统的制品解压即可，重要的只有两个二进制文件： <code>gobgpd</code> 虚拟路由器进程，<code>gobgp</code>命令行工具，用来查看路由对不对。</p><h2 id="启动虚拟路由器"><a href="#启动虚拟路由器" class="headerlink" title="启动虚拟路由器"></a>启动虚拟路由器</h2><p>创建一个 <code>gobgp.toml</code> 文件，最简单的配置就照着我下面这个就好了，大部分基础的云原生领域 BGP 相关的软件测试用这个就够了。</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[global.config]</span></span><br><span class="line">  <span class="attr">as</span> = <span class="number">65000</span>                          <span class="comment"># 测试环境随便写一个就好</span></span><br><span class="line">  <span class="attr">router-id</span> = <span class="string">&quot;10.0.0.1&quot;</span>              <span class="comment"># 测试环境随便写一个就好，写 GoBGP 所在节点 IP 日志清晰一些</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[dynamic-neighbors]]</span>                 <span class="comment"># 被动连接模式，省去了配固定客户端</span></span><br><span class="line">  <span class="section">[dynamic-neighbors.config]</span></span><br><span class="line">    <span class="attr">prefix</span>     = <span class="string">&quot;192.168.0.0/24&quot;</span>     <span class="comment"># 允许哪个 IP 范围内的客户端来连接 </span></span><br><span class="line">    <span class="attr">peer-group</span> = <span class="string">&quot;ext-ebgp&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[peer-groups]]</span>                       <span class="comment"># 复制粘贴就好了</span></span><br><span class="line">  <span class="section">[peer-groups.config]</span></span><br><span class="line">    <span class="attr">peer-group-name</span> = <span class="string">&quot;ext-ebgp&quot;</span></span><br><span class="line">    <span class="attr">peer-as</span>         = <span class="number">65000</span></span><br><span class="line">  <span class="section">[[peer-groups.afi-safis]]</span></span><br><span class="line">    <span class="section">[peer-groups.afi-safis.config]</span></span><br><span class="line">      <span class="attr">afi-safi-name</span> = <span class="string">&quot;ipv4-unicast&quot;</span></span><br></pre></td></tr></table></figure><p>启动 <code>gobgpd</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./gobgpd -f gobgp.toml</span><br></pre></td></tr></table></figure><p>在另一个终端观察当前的路由表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./gobgp global rib</span><br></pre></td></tr></table></figure><p>这样基本上 MetalLB，Calico 的基础 BGP 能力就可以测试了。如果想更配更复杂的模式，比如 <a href="https://github.com/osrg/gobgp/blob/master/docs/sources/route-reflector.md">Router Reflector</a>，<a href="https://github.com/osrg/gobgp/blob/master/docs/sources/evpn.md">EVPN</a> 那就再去翻 <a href="https://github.com/osrg/gobgp?tab=readme-ov-file#documentation">GoBGP 的文档</a>吧。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在做 MetalLB 和 Calico 的一些测试时需要验证 BGP 相关的功能，然而每次测试要去联系运维团队配合网络变更是不太现实的，并且大多数情况我们只要验证 BGP 信息正常交换就可以了，不需要真的去改变物理网络。于是就找到了 &lt;a href=&quot;https://git</summary>
      
    
    
    
    
    <category term="networking" scheme="http://oilbeater.com/tags/networking/"/>
    
    <category term="gobgp" scheme="http://oilbeater.com/tags/gobgp/"/>
    
    <category term="tutorial" scheme="http://oilbeater.com/tags/tutorial/"/>
    
  </entry>
  
  <entry>
    <title>怎样的开源文档规范最合适？</title>
    <link href="http://oilbeater.com/2025/07/06/oss-docs-best-practise/"/>
    <id>http://oilbeater.com/2025/07/06/oss-docs-best-practise/</id>
    <published>2025-07-06T13:00:10.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>最近打算把 Kube-OVN 的文档整理一遍，同时思考怎样的文档规范能尽可能做到：</p><ol><li>降低 Maintainer 的维护成本（用户看完文档后不会再去找 Maintainer ）。</li><li>能够充分复用（不看文档的人找过来可以直接甩文档）。</li><li>同时对社区的用户也尽可能有帮助（少走弯路）。</li></ol><p>我决定先按照下面的结构重构一下文档，来看看效果。</p><ol><li><strong>概要</strong>：一两句话描述这个功能达到什么效果，解决什么问题，有什么优势。之前很多文档都是以技术细节开头，反而把真正能实现的效果给模糊掉了。明确功能是什么后，用户就可以确认自己是否还需要继续往下看了。</li><li><strong>局限性</strong>：这个功能不是什么，什么没做到，解决不了什么问题，使用有什么限制条件。这个其实和第一部分一样重要，不然用户可能有不切实际的预期等到很靠后的时候才知道某个功能其实是不符合预期的或者限制条件不满足，也浪费了双方很多时间。有人问为什么不能用的时候也可以甩文档。</li><li><strong>实现原理</strong>：我们用到的 OVN&#x2F;OVS 的哪些能力，简要的介绍以及对应功能的参考文档。到这里我们其实期望用户有一些更深的理解，不至于出了问题毫无思路再去扒代码或者找到 Maintainer。我们也建议真在生产使用 Kube-OVN 的用户要有一些从底层开始排查的能力，Kube-OVN 虽然做了很多抽象让使用变得简单，但是在用户的环境里使用的异常还是需要用户自己有能力排查。</li><li><strong>使用步骤</strong>：之前的常规内容，有了前面的铺垫，这一部分可以尽可能简化，只需要步骤即可。</li></ol><p>大家有什么其他的建议也可以一块来讨论一下。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近打算把 Kube-OVN 的文档整理一遍，同时思考怎样的文档规范能尽可能做到：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;降低 Maintainer 的维护成本（用户看完文档后不会再去找 Maintainer ）。&lt;/li&gt;
&lt;li&gt;能够充分复用（不看文档的人找过来可以直接甩文档）。&lt;</summary>
      
    
    
    
    
    <category term="opensource" scheme="http://oilbeater.com/tags/opensource/"/>
    
    <category term="documents" scheme="http://oilbeater.com/tags/documents/"/>
    
  </entry>
  
  <entry>
    <title>Kube-OVN 是如何自动修复 CVE 的</title>
    <link href="http://oilbeater.com/2025/06/28/kube-ovn-autoupdate/"/>
    <id>http://oilbeater.com/2025/06/28/kube-ovn-autoupdate/</id>
    <published>2025-06-28T00:02:21.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>这篇博客是内部分享的一个提示文稿，并没有做仔细整理，大体思路就是捕获所有 Kube-OVN 的依赖：操作系统，Golang，程序依赖，环境组件（k8s,kubevirt 等），然后激进的实时更新所有依赖做到动态清零。</p></blockquote><p>Kube-OVN CVEs 问题修复的流程经历了如下几个阶段：</p><ul><li>发版&#x2F;按需统一进行手动修复</li><li>每次 commit 检测可修复安全漏洞，手动进行修复</li><li>master 依赖自动更新，发版分支部分依赖自动更新，少量手动修复</li><li>未来目标：所有依赖自动更新，避免手动修复</li></ul><h2 id="按需修复"><a href="#按需修复" class="headerlink" title="按需修复"></a>按需修复</h2><p>优势：</p><ul><li>相比每个安全漏洞单独修复，整体修复频次低<br>劣势：</li><li>发版集中修复，研发还要兼顾发版期间赶进度，测试，bug 修复，时间压力大</li><li>依赖更新没有经过日常验证，存在未知的风险</li><li>大部分安全修复工作没有实际意义还需要花费人工精力</li></ul><h2 id="每次-Commit-检测修复"><a href="#每次-Commit-检测修复" class="headerlink" title="每次 Commit 检测修复"></a>每次 Commit 检测修复</h2><p>增加工作：</p><ul><li>流水线增加 trivy 扫描，存在安全问题无法合并代码</li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-x86-image.yaml#L3437">https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-x86-image.yaml#L3437</a></li><li><a href="https://github.com/kubeovn/kube-ovn/actions/runs/15760235247?pr=5376">https://github.com/kubeovn/kube-ovn/actions/runs/15760235247?pr=5376</a></li></ul><p>优势：</p><ul><li>将 CVE 修复打散到平时，发版时时间压力较低</li><li>可以快速发版</li><li>大部分依赖更新已经得到了日常自动化测试的验证，风险也较低<br>劣势：</li><li>最后一次提交和发版扫描之间存在时间差，理论上会遗漏一部分 CVE</li><li>会干扰平时正常功能提交，bug 修复，提交经常因为不相关的 CVE 问题被阻塞</li><li>大量的手动修复</li></ul><h2 id="所有依赖自动更新"><a href="#所有依赖自动更新" class="headerlink" title="所有依赖自动更新"></a>所有依赖自动更新</h2><p>只要依赖更新版本就尝试更新，不考虑是否是安全更新。尝试解决比 CVE 修复更大的一个问题，自动就解决了 CVE 问题的修复。</p><p>我们的依赖项：</p><ul><li>OS 镜像及其依赖：<code>ubuntu:24.04</code>, <code>apt-get install ....</code></li><li>Go 语言版本，以及代码依赖库</li><li>上游依赖：<code>OVS</code>, <code>OVN</code></li><li>其他协作组件依赖： <code>kubernetes</code>, <code>kubevirt</code>,<code>multus</code>, <code>metallb</code>, <code>cilium</code>, <code>talos</code></li><li>采用比较激进的更新策略，依赖大版本更新我们也会尝试更新</li></ul><p>要做的事情：</p><ul><li>OS 镜像部分增加流水线每天重新构建，自动修复 OS 和 apt 库里解决的问题<ul><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-kube-ovn-base.yaml">https://github.com/kubeovn/kube-ovn/blob/master/.github/workflows/build-kube-ovn-base.yaml</a></li><li>每日自动无需人工干预</li></ul></li><li>Go 相关使用 renovate 进行自动更新<ul><li>Go 版本，<code>go.mod</code> 里的所有依赖版本</li><li>实时更新 + auto merge</li><li>出现合并问题手动处理</li><li><a href="https://github.com/kubeovn/kube-ovn/pull/5354">https://github.com/kubeovn/kube-ovn/pull/5354</a></li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/renovate.json">https://github.com/kubeovn/kube-ovn/blob/master/renovate.json</a></li><li>不需要特殊配置，按照 renovate 自动检测流程来即可</li></ul></li><li>上游组件依赖<ul><li>OVS OVN 每日构建，策略更激进直接从上游分支构建，上游不发版我们也会更新</li><li>相信上游都是 bugfix，我们这样可以增强稳定性</li></ul></li><li>其他组件<ul><li>使用 renovate 的自定义正则匹配，Dockerfile, Makefile, Action 里所有依赖软件版本自动更新</li><li><a href="https://github.com/kubeovn/kube-ovn/issues/5291">https://github.com/kubeovn/kube-ovn/issues/5291</a></li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/Makefile">https://github.com/kubeovn/kube-ovn/blob/master/Makefile</a></li></ul></li></ul><p>优点：</p><ul><li>大部分 CVE 会在不知道情况下被修复，少量可在一天内自动修复，特殊情况再手动修复</li><li>大量上游的 bugfix，性能提升和新功能被自动合入，软件整体稳定性提升</li><li>大量的版本适配验证工作，如 k8s 版本更新，KubeVirt 版本更新的适配验证也都自动进行，风险提前知晓</li><li>人工干预量较少</li></ul><p>劣势：</p><ul><li>依赖更新多比较吵，需要设置聚合策略</li><li>更新量太大无法人工测试，需要有自动化测试保证</li><li>需要积极适配上游版本变化</li><li>存在上游新版本不稳定风险，目前两年内遇到过两次</li></ul><h2 id="renovate-相比-dependabot-优势"><a href="#renovate-相比-dependabot-优势" class="headerlink" title="renovate 相比 dependabot 优势"></a>renovate 相比 dependabot 优势</h2><ul><li>可以自定义依赖捕获，Dockerfile、Makefile 里的非标准依赖可以捕获</li><li>可以在非 master 分支运行</li><li>有 auto merge 能力</li><li></li></ul><h2 id="还未解决的问题"><a href="#还未解决的问题" class="headerlink" title="还未解决的问题"></a>还未解决的问题</h2><ul><li>自动化测试误报导致无法自动合并</li><li>已发版分支的 Go 相关更新还未自动化<ul><li>renovate 的 security-only 策略效果还未知</li><li><a href="https://github.com/kubeovn/kube-ovn/blob/master/renovate.json#L45">https://github.com/kubeovn/kube-ovn/blob/master/renovate.json#L45</a></li><li>发版分支可能需要重新定义策略</li></ul></li><li>部分依赖还没有自动更新</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;这篇博客是内部分享的一个提示文稿，并没有做仔细整理，大体思路就是捕获所有 Kube-OVN 的依赖：操作系统，Golang，程序依赖，环境组件（k8s,kubevirt 等），然后激进的实时更新所有依赖做到动态清零。&lt;/p&gt;
&lt;/blockquot</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>关于培训</title>
    <link href="http://oilbeater.com/2025/05/24/about-training/"/>
    <id>http://oilbeater.com/2025/05/24/about-training/</id>
    <published>2025-05-24T10:40:04.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>这两天接了个 Kube-OVN 培训的任务，事实上这已经是这几年第三次给这家公司培训相同的内容了，形式也从线上转到线下还要求手把手的敲命令，可想而知之前几次的最终效果怎样。我可以理解需求方的技术焦虑，但我认为培训这种形式是极其低效的，更多的只是培训当时能获得一些虚假的满足感，不会产生什么长期收益。</p><p>一方面培训是一种被动学习方式，完全由老师带节奏前进，那听讲的人只是被动的吸收，很难有深度的思考。另一方面需要等到培训才了解的知识大概率是实际上用不到的知识，如果每天都用的话根本来不及等这种一年一次的培训。如果实际用不到，那么哪怕当场掌握了，很快也会什么都剩不下。</p><p>我觉得这和我们一直以来的教育理念有些关系，传统上我们认为认真听老师讲课，努力记笔记，不会的问题堵着老师问，都是优秀的学习习惯。但这些都是偏被动的学习方法，我们很多年的教育过程中其实缺乏主动学习的机会。这种被动的方式早期的效果可能会很好，因为早期学校里的知识难度不大，而且我们展示学习成果的方式就是考试，而考试是可以通过过拟合的方式来提升效果的，并不能真正反映你对知识的掌握程度。</p><p>在我的经历里，到了初中阶段，最出色的那批人就不再是认真听课，努力记笔记那批人了。而是换成了那批给人感觉平时一直玩，考试成绩还很好的一批人，事实上越往后这批人的比例越高。我认为这里并不是智商的区别而是被动学习和主动学习模式的区别。主动学习的人会更多依赖自己思考来解决问题，而不是依赖老师的讲解，这个方法看似低效其实最终效果会更好。想象一下同样一道题，一个人是老师之前讲过所以考试的时候做出来了，另一个人是上课没听到但是考试的时候临场也做出来了。从考试的结果来说两个人是一样的，但两个人的实际能力是天差地别的。后者实际上拥有更好的学习方法和能力，并且在更难的问题上有更好的泛化能力，自然可以显得游刃有余。就好比前者一直在用冒泡算法去排序，后者则是不断用快排，在小规模上前者可能更简单更不容易出错，效果会比后者好，但是后者一旦调整好了，在更大规模的数据上会有指数级别的优势。</p><p>这也是为什么有些转行的程序员的表现会比科班的表现好。一方面他们采用的是主动学习这种高速方法，另一方面科班的被动学习学到的大量都是实际中毫无用处的知识，两者的基础差距本身就没那么大，用一个更高速的方法很容易短期就实现超越。</p><p>所以还是要主动学习，学点有用的。（不要再折腾供应商搞什么高级培训了</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这两天接了个 Kube-OVN 培训的任务，事实上这已经是这几年第三次给这家公司培训相同的内容了，形式也从线上转到线下还要求手把手的敲命令，可想而知之前几次的最终效果怎样。我可以理解需求方的技术焦虑，但我认为培训这种形式是极其低效的，更多的只是培训当时能获得一些虚假的满足感</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>如何超越 OpenShift</title>
    <link href="http://oilbeater.com/2025/04/23/surpass-openshift/"/>
    <id>http://oilbeater.com/2025/04/23/surpass-openshift/</id>
    <published>2025-04-23T10:40:43.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>OpenShift 作为容器平台的标杆产品，同时也是开源商业化的标杆，一直是被人试图追赶或者超越的对象。但是如果只是照着 OpenShift 的产品模仿，那么当追上 OpenShift 时只可能有一种情况，那就是 OpenShift 停止发展，过了一年后你终于追上了，然后会因同样原因被淘汰。</p><p>那么有没有什么方法能够追上甚至超越 OpenShift 呢？我认为要从 OpenShift 本身商业模式的选择和技术路线上的选择入手，从他们在这种选择下不可避免的缺点入手，做出差异化，才有超越的可能。</p><h2 id="OpenShift-并不-Open"><a href="#OpenShift-并不-Open" class="headerlink" title="OpenShift 并不 Open"></a>OpenShift 并不 Open</h2><p>OpenShift 里的 Open 可能和 OpenAI 里的 Open 是同一个 Open。如果你尝试不通过 RedHat 的销售自己去部署一套 OpenShift 就会知道我在说什么了。</p><p>OpenShift 的所有组件确实是开源的，但如果你是一个纯粹的社区用户会步步受挫。一个功能你可能找不到对应组件，找到组件可能找不到对应源码，找到源码又没有文档指导如何编译使用。这些现象在那些完全是 OpenShift 自己使用的组件里已经见怪不怪了。大概 OpenShift 这部分的社区只是对客户和合作伙伴开放的。</p><p>而对于那些非 OpenShift 专属的组件，OpenShift 采取的策略会是一旦选择就大举投入，争取到对应组件的社区的主导权。所以会看到的一个现象是有些社区很出名的项目 OpenShift 的人完全不投入，而一个项目在平稳发展了几年后会突然涌入大量 OpenShift 的人。</p><p>这些都是 OpenShift 在商业化与开源之间权衡后的选择，并没有对错之分，但这会给更开放的项目留出机会。如果新的产品能够降低参与门槛，收取更广泛的反馈，让更多的贡献者来参与创新，那么我认为它的上限将会超越 OpenShift。</p><h2 id="OpenShift-的技术并不先进"><a href="#OpenShift-的技术并不先进" class="headerlink" title="OpenShift 的技术并不先进"></a>OpenShift 的技术并不先进</h2><p>受限于第一点因素，OpenShift 并不能广泛的吸收整个生态的最新成果。在生态内某个组件和 OpenShift 专属的组件功能重叠情况下，OpenShift 内部的研发人员是很难有动力切换到另一个社区或者另一个公司主导的开源组件。</p><p>以我比较了解的网络为例，OpenShift 早期通过 Haproxy 实现了 Route 来打通集群外访问集群内的流量。在当时 Ingress 还不成熟，Route 是一个相比社区先进的多的方案，OpenShift 的方案在当时是绝对领先的。但是随着 Ingress 的成熟，社区生态内各种网关都在飞速发展，而 OpenShift 受限于自己早期的实现和用户用法很长时间都没有去支持 Ingress 这个在社区已经标准化的功能。现阶段 Ingress 规范已经进化到 GatewayAPI 有一段时间了，大量 AI Gateway 的新场景都在通过 GatewayAPI 进行扩展，而 OpenShift 现如今还没有支持 GatewayAPI，最近正在计划在之前的 Haproxy 上同时支持 Route，Ingress 和 GatewayAPI。</p><p>类似的案例在 OpenShift 内还有很多，早期可能还是一个优秀的方案，但由于 OpenShift 专属导致不开放，随着社区的发展，原先优势的方案反而变成了阻碍前进的障碍。就像现在在 Kubernetes 上做 Ingress Gateway 不会有人去参考 OpenShift 的实现，在很多细分领域 OpenShift 已经并不是最先进的解决方案了，尤其是在那些由 OpenShift 专属组件提供服务的领域。现在的 OpenShift 在我看来就是一个覆盖面积很广，但平庸且无趣的平台。</p><p>容器平台的生产过程其实和手机的生产很像，都是从成百上千个供应链供应商那里选择需要的配件，然后组装成一个成品。如果能够保持开放，选择供应链上最先进的那些配件，或者根据场景快速组合出一个针对特定场景的产品，那么在技术竞争力上应该会远超 OpenShift。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>要想真正追赶甚至超越 OpenShift，关键不是在已有功能上亦步亦趋，而是要做到更开放、更领先。这样才能摆脱追随者路径，真正形成对 OpenShift 的差异化优势，成为下一轮技术浪潮的主导者。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;OpenShift 作为容器平台的标杆产品，同时也是开源商业化的标杆，一直是被人试图追赶或者超越的对象。但是如果只是照着 OpenShift 的产品模仿，那么当追上 OpenShift 时只可能有一种情况，那就是 OpenShift 停止发展，过了一年后你终于追上了，然后会</summary>
      
    
    
    
    
    <category term="OpenShift" scheme="http://oilbeater.com/tags/OpenShift/"/>
    
    <category term="Product" scheme="http://oilbeater.com/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>DeepSeek MLA -- 为成本优化而生的注意力机制</title>
    <link href="http://oilbeater.com/2025/04/14/deepseek-mla/"/>
    <id>http://oilbeater.com/2025/04/14/deepseek-mla/</id>
    <published>2025-04-14T17:10:03.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>DeepSeek 第一次出名是因为 DeepSeek V2 做到了一百万 Token 只要 0.14 美元。同期的 GPT-4 是 30 美元，当时被认为极具性价比的 GPT-3.5 也要 1.5 美元。这个突破性价格的出现在国内引发了一轮价格战，大批大厂模型大幅降价甚至免费。然而和其他大厂烧钱补贴的逻辑不同，DeepSeek 是通过一系列的技术创新实现了成本数量级的下降。这篇文章就来介绍一下这背后最关键的一个技术创新 —— MLA(Multi-Head Latent Attention)。</p><p>MLA 最本质的数学技巧并不复杂，论文里也是一段话就说完了，看完让人感叹竟然还有如此精妙的解法。但是由于和整个 Transformer 架构耦合会导致理解起来有些困难，我这里会尽量简化描述，哪怕你之前完全不了解 Transformer 应该也可以领会到这个方法的精妙。</p><p>当然还是需要有一些线性代数的基础，如果你还记的一个形状为 5*4 的矩阵乘形状为 4*3 的矩阵，结果是一个形状为 5 * 3 的矩阵就可以继续了。</p><p><img src="/../images/20250414233740.png"></p><h2 id="KVCache"><a href="#KVCache" class="headerlink" title="KVCache"></a>KVCache</h2><p>大模型推理的成本的瓶颈在哪里？答案可能会出乎意料 —— 是显存。显卡有大量计算单元，而推理任务又是线性的一次只能出一个 Token，为了充分利用显卡的计算资源达到最大的吞吐，一般会同时运行尽可能多的生成任务。而每个任务在推理过程中都会占用大量显存，如果想运行尽可能多的任务就需要运行时显存占用足够小。而 MLA 在运行时的显存占用是原始注意力机制的 <strong>6.7%</strong>，你没看错，不是降低了 6.7%，是降低了 <strong>93.3%</strong>。打个比喻这一刀下去不是腰斩，而是脚踝斩。在不考虑模型本身的显存占用情况下，近似可以认为 MLA 在相同显存下可以容纳 <strong>15 倍</strong>的生成任务。</p><p>虽然 MLA 的论文里没有细说这个灵感的来源，但我认为他们是从原先的 KVCache 倒推，诞生了一种全新的注意力机制。到这里就不得不说下 KVCache 是什么。</p><p>大模型每生成一个 Token 都需要对之前所有的 Token 进行计算，来得出最新的一个 Token 是什么。但是一般任务不会生成一个 Token 就结束，往往要一直生成到结束符号，这就会导致前面的 Token 每一次都要重复计算。于是 KVCache 的作用就是把之前每个 Token 计算生成的中间结果保存下来，这样就可以避免重复计算了。你可以理解为每个 Token 都被映射成了一个 1000 * 1000 的矩阵，那么我们有没有什么办法来减少这个矩阵的内存占用呢？</p><p><img src="/../images/20250414234534.png"></p><h2 id="MLA"><a href="#MLA" class="headerlink" title="MLA"></a>MLA</h2><p>这里有意思的事情终于可以开始了，我们可以用两个小矩阵相乘来近似一个大矩阵。这里刚才你还记得的线性代数知识可以用上了，1000 * 2 的矩阵乘一个 2 * 1000 的矩阵也可以得到一个 1000 * 1000 的矩阵，而这两个矩阵总共只有 4000 个元素，是 1000 * 1000 矩阵元素数量的 0.4%。</p><p>这就是 MLA 在数学上最核心的思路了，在 DeepSeek V2 中，本来一个 Token 应该被映射为一个 1*16k 的向量，而在使用 MLA 后会先通过一个压缩矩阵将这个 Token 映射为 1*512 的向量，等到需要的时候再通过一个 512 * 16k 的解压矩阵还原成 1*16k 的向量。在这里压缩矩阵和解压矩阵都是通过训练得来，是模型的一部分只会占用固定的显存，而运行时针对每个 Token 的显存占用就只剩这个  1*512 的向量，只有原来的 3%。</p><p>一个完整的对比如下图所示，原先的 MHA 需要 Cache 完整矩阵，而 MLA 只需要 Cache 中间压缩后的一个向量，再还原出完整矩阵。</p><p><img src="/../images/20250415000024.png"><br><img src="/../images/20250414235538.png"></p><p>这一切真的这么美好嘛？让我们想想 KVCache 的最初目的是什么，是为了减少 Token 的重复中间计算，MLA 虽然压缩了 KVCache，但是每次还需要一个解压操作，计算量又回来了。</p><p>这里就是一个更精彩的故事了，按照 Transformer 的计算，中间的 Cache 乘一个解压矩阵后还要再乘一个输出矩阵得到最终的结果，可以粗略理解为最终计算的公式是 Cache * W<sup>解压</sup>  * W<sup>输出</sup> ，根据矩阵计算的结合率，可以先计算后两个矩阵的乘积，将后两个矩阵融合乘一个新的矩阵。由于 W<sup>解压</sup>  和 W<sup>输出</sup> 在训练后是确定的，因此做个简单的后处理把这部分提前算出来就好了。作者在论文中也用 <strong>Fortunately</strong> 来形容这件事情。</p><p>也就是说我们最初是出于压缩 KVCache 的思路去做了压缩和解压，但在实际推理过程中根本不存在解压的过程。在大幅压缩了显存的同时由于过程中的矩阵都变小了，推理所需的计算量也变小了。</p><h2 id="模型能力"><a href="#模型能力" class="headerlink" title="模型能力"></a>模型能力</h2><p>但在这里我其实还有个疑问没有解开，本质上 MLA 是用两个小矩阵相乘得到一个大矩阵，但是并不是所有的大矩阵都能完美分解成两个小矩阵。MLA 实际的搜索空间是小于 MHA 的，理论上来讲 MLA 的模型能力应该更弱。但是按照 DeepSeek 论文里的评测，MLA 的模型能力是要略强于 MHA 的。</p><p><img src="/../images/20250415003909.png"></p><p>这个事情其实就不太好理解了，我倾向于认为 MLA 虽然搜索空间降低了，但是最优解的概率反而变大了，收敛到了一个相比 MHA 更优的解。另外虽然 MLA 的优化是从 MHA 出发，但最终的结果其实是一套全新的注意力机制，模型的架构都发生了很大的变化，或许 DeepSeek 真的发现了一个更有效的注意力机制。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>有不少性能优化方案其实是在玩跷跷板游戏，比如用 GPU 计算时间交换显存空间，或者牺牲模型能力来换成本下降。而 MLA 在把显存打脚踝斩的情况下同时还做到了计算需求下降和模型能力提升，简直匪夷所思。</p><p>另一个感触是在经历了国内移动互联网时代的我们很容易认为价格战就是要赔本赚吆喝，却忘了技术创新才应该是那个最大的杠杆。</p><blockquote><p>这篇博客只是介绍了 MLA 最核心的理念，在实际应用中还有很多具体的问题，例如：如何处理旋转位置编码？K 和 V 的解压矩阵融合其实略有不同，一个是直接应用结合律，一个是转置后再结合，等等。还是建议大家阅读 DeepSeek V2 的原始论文，有这篇文章做基础应该容易理解很多。</p><p>博客里部分图片源自 <a href="https://www.bilibili.com/video/BV1BYXRYWEMj/">DeepSeek-v2 MLA 原理讲解</a>,也建议大家看下这个视频。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;DeepSeek 第一次出名是因为 DeepSeek V2 做到了一百万 Token 只要 0.14 美元。同期的 GPT-4 是 30 美元，当时被认为极具性价比的 GPT-3.5 也要 1.5 美元。这个突破性价格的出现在国内引发了一轮价格战，大批大厂模型大幅降价甚至免</summary>
      
    
    
    
    
    <category term="DeepSeek" scheme="http://oilbeater.com/tags/DeepSeek/"/>
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Paper" scheme="http://oilbeater.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>混乱的 Llama 4</title>
    <link href="http://oilbeater.com/2025/04/06/llama-4-chaos/"/>
    <id>http://oilbeater.com/2025/04/06/llama-4-chaos/</id>
    <published>2025-04-06T15:57:23.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间 Meta AI 的负责人离职让人怀疑 Llama 4 的进度出现了问题，结果没过两天 Meta 就发布了 Llama 4，似乎是为了打破传言。然而看完了现在已经公布的模型基础信息，我反而更觉得 Llama 项目内部已经极度混乱了。下面是我根据已有信息的分析，欢迎指正。</p><h2 id="模型基础信息"><a href="#模型基础信息" class="headerlink" title="模型基础信息"></a>模型基础信息</h2><p>Llama 这次正式发布了一个 109B 和 一个 400B 参数量的模型，以及一个未发布的 2T 参数量模型的信息，我把关键的架构信息汇总如下，以下信息均来自 Llama 自己的博客和 huggingface 模型页面：</p><table><thead><tr><th>名称</th><th>参数量</th><th>激活参数量</th><th>专家数</th><th>上下文</th><th>语料量</th><th>GPU 时间</th></tr></thead><tbody><tr><td>Scout</td><td>109B</td><td>17B</td><td>16</td><td>10M</td><td>40T</td><td>5.0M</td></tr><tr><td>Maverick</td><td>400B</td><td>17B</td><td>128+1</td><td>1M</td><td>22T</td><td>2.38M</td></tr><tr><td>Behemoth</td><td>2T</td><td>288B</td><td>16</td><td>-</td><td>-</td><td>-</td></tr></tbody></table><p>这里都不用再看模型的评分表现了，这几个模型架构方面的对比就能看出很多问题了。</p><h2 id="奇怪的-MoE-架构"><a href="#奇怪的-MoE-架构" class="headerlink" title="奇怪的 MoE 架构"></a>奇怪的 MoE 架构</h2><p>Llama 4 这次从 Dense 模型全面转向了 MoE，但是诡异的点在于他们三个模型采用了两套 MoE 架构。最大的 Behemoth 和最小的 Scout 采用的是传统的 MoE，专家数也是 16 这个传统认为比较常规的一个专家数量，而中间的那个 Maverick 采用的却是 DeepSeek MoE 提出的一个新的细粒度专家加共享专家的模型是个 128 专家加 1 共享专家的架构。</p><p>一般来说一代模型都是采用同一个架构，只是在模型的层数和每层的宽度上做调整，两个有很大差异的模型在同一代就很奇怪。而且就算有变化也不应该是最大和最小的保持一致，把中间规模的给换了，给人的感觉是中间的这个 Maverick 其实是被 DeepSeek 冲击下重新仿照 DeepSeek 模型重新训练的，但是时间上来不及把三个都重做，只好就放在一块发布了。</p><h2 id="奇怪的成本投入"><a href="#奇怪的成本投入" class="headerlink" title="奇怪的成本投入"></a>奇怪的成本投入</h2><p>一般来讲，模型参数规模越大，需要投入的成本越高。一方面是更大的模型可以容纳更多的知识，会提供给更大规模模型更多的语料；另一方在语料相同的情况下，更大的模型需要训练的参数更多 GPU 开销也会更高。所以通常来讲模型规模越大，需要的成本会越高。</p><p>然而到了 Llama 4 这里出现了两个指标都相反的情况。Maverick 的参数规模是 Scout 的接近 4 倍，但是 Maverick 训练的语料量只有 Scout 的二分之一，消耗的 GPU 时间同样也只有二分之一。考虑到这两个模型的激活参数量是一致的这个 GPU 时间可以理解，但是语料量也只给一半这个事情就很奇怪了。给我的感觉是要么这次只是试水新型的 MoE 架构，并没有想做完整训练，要么就是训到后面训崩了，从中间那个 snapshot 出来了。</p><h2 id="奇怪的上下文长度"><a href="#奇怪的上下文长度" class="headerlink" title="奇怪的上下文长度"></a>奇怪的上下文长度</h2><p>一般来讲更大的模型，能力会越强。可在这一代 Llama，最让人感到震撼的 10M 上下文是给的最小规模的 Scout，更大的 Maverick 反而是 1M 上下文。考虑到目前扩充上下文的主流方法还是在后训练做微调，更大的 Maverick 在后训练的投入上还不如更小的 Scout。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>给我的感觉是 Llama 4 这一代本来是想走传统 MoE，被 DeepSeek 冲击后又半路开始看 DeepSeek MoE。但是训练可能已经开始了，停下来又有阻力，所以中间又插了一个中规模的 Maverick。按照这个参数量选择来看是想用比 DeepSeek V3 小的参数量实现类似的性能。但是 17B 的激活要追平 DeepSeek V3 的 39B 激活我觉得还是有很大难度的。不过最后能让这一代的模型以这么混乱的形式发布，还加了个期货模型，我还是觉得 Llama 项目内部出了不少的问题。</p><p><img src="/../images/llama4.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前段时间 Meta AI 的负责人离职让人怀疑 Llama 4 的进度出现了问题，结果没过两天 Meta 就发布了 Llama 4，似乎是为了打破传言。然而看完了现在已经公布的模型基础信息，我反而更觉得 Llama 项目内部已经极度混乱了。下面是我根据已有信息的分析，欢迎指</summary>
      
    
    
    
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Llama" scheme="http://oilbeater.com/tags/Llama/"/>
    
  </entry>
  
  <entry>
    <title>DeepSeek MoE -- 创新型的 MoE 架构</title>
    <link href="http://oilbeater.com/2025/03/29/deepseek-moe/"/>
    <id>http://oilbeater.com/2025/03/29/deepseek-moe/</id>
    <published>2025-03-29T12:54:37.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>从 DeepSeek V3&#x2F;R1 开始关注 DeepSeek 工作的人很容易认为 DeepSeek 大量的工作都是在工程上优化效率，但是回看 DeepSeek 过去一年的论文才会发现他们其实一直在模型架构和训练方法上做各种创新，而 V3 和 R1 只是在之前架构创新的基础上进行 Scale。DeepSeek MoE 这篇论文就介绍了 DeepSeek 在 MoE 架构上的主要创新，现在看上去也很有希望成为未来 MoE 架构的标准。</p><h2 id="MoE-vs-Dense"><a href="#MoE-vs-Dense" class="headerlink" title="MoE vs Dense"></a>MoE vs Dense</h2><p>先说一下 MoE 和传统的 Dense 架构的区别。早期的 LLM 基本都是 Dense 架构，也就是每生成一个 Token 需要激活所有的神经元参与计算，这种方式其实和人脑的思考方式是有很大区别的，人脑是不会任何问题都需要调动所有脑细胞的，如果这样的话人早就累死了。所以很自然的一个想法就是生成 Token 的时候不要再激活所有的神经元了，每次只激活和当前任务最相关的神经元，于是就有了 MoE(Mixture of Experts) 架构，把 LLM 里每一层的神经元分割成 N 个 Expert，通过 Router 去选择 K 个最相关的 Expert 激活。</p><p><img src="/../images/20250329161016.png"></p><p>这个架构的好处就是在推理的时候不需要激活所有的神经元，计算量会大幅下降。在 DeepSeek MoE 前最常见的 8 选 2 模式下计算量可以下降到接近 Dense 模型的三分之一。</p><p>MoE 的架构看上去很理想，但本质上是在用少量 Experts 来模拟 Dense 模型的表现，所以关键是在每个 Expert 是否有足够的专业性，能否真的模拟 Dense 模型的表现。如果类比人脑，当神经元足够特化时，特定任务只需要激活少量神经元即可完成。</p><p>DeepSeek MoE 这篇论文就介绍了他们为了把每个 Expert 专业性推到极致所做的两个创新：</p><ul><li>更多更小的 Expert</li><li>知识共享 Expert</li></ul><h2 id="更多更小的-Expert"><a href="#更多更小的-Expert" class="headerlink" title="更多更小的 Expert"></a>更多更小的 Expert</h2><p><img src="/../images/20250329165838.png"></p><p>使用更多更小的 Expert 来增加每个 Expert 的专业性看似是个很符合直观的思路，但是之前主流 MoE 都是 8 个或者 16 个 Expert。可以想象 LLM 要处理的问题类型千千万，这个数量规模的 Expert 显然不可能做到高度的专业化，每个 Expert 都会有大量当前任务无关的知识。</p><p>但是随着 Expert 的数量变大，训练的难度也会变大，Router 很容易只选择少数几个 Expert 导致负载的极度不均衡。最终，理论上的 MoE 架构可能会变成每次只激活同一组 Expert 的小模型。因此，之前大部分 MoE 架构的 Expert 数量都不会太多。</p><p>DeepSeek 经过一组设计的损失函数，给重复选择同一个 Expert 增加了惩罚，从而迫使 Router 更均衡的去选择 Expert。通过这个方式 DeepSeek 解决了训练的问题，开始一步步尝试 scale Expert 的数量。从这篇论文里的 64 选 6，扩展到 128 选 12，到 V2 的 160 选 6，再到 V3 的 256 选 8。</p><p>可以看到 DeepSeek 一步步将 Expert 数量扩展，而且所需要选中的 Expert 比例也从 9% 一步步降低到 2%，证明了确实在 Expert 足够专业化后只需要更少部分的激活就可以完成对应的任务。</p><h2 id="知识共享-Expert"><a href="#知识共享-Expert" class="headerlink" title="知识共享 Expert"></a>知识共享 Expert</h2><p><img src="/../images/20250329170955.png"></p><p>随着 Expert 变小和 Expert 数量增加其实还会带来另外一个问题，那就是每个 Expert 除了需要特定领域的知识外，其实还需要一些通用知识，例如一些通用的语言理解和逻辑分析，可能是每个 Expert 都需要的。如果每个 Expert 都记忆了相关知识那么其实会造成大量的知识冗余，当 Expert 数量变多时，问题会更加明显。这其实会限制每个 Expert 的专业化，训练和推理过程中也会造成资源的浪费。</p><p>DeepSeek 提出的做法是增加一组共享 Expert，这一组 Expert 每个训练样本都会被激活，希望他们在训练过程中可以学到通用的知识，这样其他的 Expert 就无需再去学习这些通用知识，只需要学习专业知识了。当推理过程中这组共享 Expert 也会每次都被激活，来提供通用的知识信息。</p><p>这同样是一个很符合直觉的架构创新，但是由于之前 MoE 架构的 Expert 规模本来就不大，这个优化的意义其实并不明显，只有当规模上去了这个问题才会暴露出来。在这篇论文里 DeepSeek 还根据 Expert 数量按比例扩充了共享型 Expert 数量，但是随着更多的训练和实践，发现其实并不需要那么多共享型 Expert，等到 V3 的时候其实只使用到了 1 个共享型 Expert。</p><h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>看完这篇论文我最大的感受是 DeepSeek 并不是拿一个已经验证过的架构无脑堆数据，而是真正的在做模型层面的创新。这也导致在 V3&#x2F;R1 大火之后很多框架第一时间都无法运行 DeepSeek 的模型或者性能也很差，因为 DeepSeek 的模型架构和其他人都有明显的差别。</p><p>并且相比 DeepSeek 其他论文里提到的 MLA、GRPO 和 NSA 这些需要复杂数学功底的创新不同，这两个模型创新都还是相对符合直觉的，但在那个时间点只有 DeepSeek 敢于这么尝试，其他人还在 Follow Llama 的 Dense 模型，敢于去做非主流的尝试，还是需要很大的勇气，这里只能对 DeepSeek 团队再次表达 Respect。</p><p><img src="/../images/20250329200735.png"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从 DeepSeek V3&amp;#x2F;R1 开始关注 DeepSeek 工作的人很容易认为 DeepSeek 大量的工作都是在工程上优化效率，但是回看 DeepSeek 过去一年的论文才会发现他们其实一直在模型架构和训练方法上做各种创新，而 V3 和 R1 只是在之前架构创</summary>
      
    
    
    
    
    <category term="DeepSeek" scheme="http://oilbeater.com/tags/DeepSeek/"/>
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Paper" scheme="http://oilbeater.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>从 DeepSeek LLM 到 DeepSeek R1 —— DeepSeek LLM</title>
    <link href="http://oilbeater.com/2025/03/14/deepseek-from-llm-to-r1/"/>
    <id>http://oilbeater.com/2025/03/14/deepseek-from-llm-to-r1/</id>
    <published>2025-03-14T10:48:50.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>最近找到了 DeepSeek 发表过的论文合集，包含了从 DeepSeek 第一版的 LLM 到最新的 R1 的演变过程。从当下的角度我们当然知道 DeepSeek R1 在模型能力上已经接近了业界最领先的水平，但他是如何一步步从一个在中国一开始都没有被重视的量化公司走到这里的其实更吸引我的注意。</p><p>这个系列的博客我会从论文阅读的角度，试图去寻找他们一步步探索的轨迹，从论文的路径上来看就是 DeepSeek LLM -&gt; DeepSeek MoE -&gt; DeepSeek V2 -&gt; DeepSeek V3 -&gt; DeepSeek R1。在整理论文时我才发现，DeepSeek 第一篇对外发布的论文是在 2024 年的 1 月，当时他们刚发布第一版模型，即使在 AI 行业内也不被认为是个主要竞争者。然而仅仅一年后的 2025 年 1 月，就已经进化到了 R1 这种业界领先水平。都说 AI 一天，人间一年，但是当真看到人间一年的进展时，还是深深的被 DeepSeek 的速度所震撼。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>DeepSeek LLM 是 DeepSeek 开源的第一个 LLM，当时开源 LLM 里最受关注的是 LLaMA-2，很多模型也是基于它的架构和基础进行的。现在从后视的角度我们知道 DeepSeek 最终选择了和 LLaMA 这类 Dense 架构不同的 MoE 架构，但是在当时第一版的时候还是基本上照搬了 LLaMA-2 的架构，进行局部的调整。可以猜测当时团队内部还处于探索模型架构的阶段。</p><p>尽管架构大体和 LLaMA-2 相同，训练的数据量也都是 2T tokens，但是在性能评测上，如下图所示 DeepSeek LLM 基本上是全面超越了 LLaMA-2。论文里介绍了他们发现的一些有趣的关于数据，训练和微调的方法。</p><p><img src="/../images/deepseekllm.png" alt="alt text"></p><p>值得注意的是 DeepSeek 在训练过程中是可以使用更多的数据，使用更大参数量的模型的，显然这样做会提升模型性能。但是这篇论文目的主要是和 LLaMA-2 对比，因此特意把数据规模和参数量都做到尽可能相近，来比较在其他方面还有哪些地方可以提升。</p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>LLaMA-2 和 DeepSeek LLM 在数据的选择上还是有很大的区别的。虽然都是 2T 的 token 量，LLaMA-2 里接近 90% 的语料都是英文，而 DeepSeek LLM 虽然没有详细说语言的比例，但是看表述语料里的英文和中文比例应该是比较接近的。所以逻辑上来看 DeepSeek LLM 在中文的评测上大幅领先并不是个意外。意外的反而是在英文评测指标上，DeepSeek LLM 在训练量明显少的情况下依然取得了接近的性能结果。</p><p>我猜测这种现象的原因有两个，第一是 DeepSeek LLM 的语料质量更高，弥补了数量上的劣势。LLaMA-2 在介绍预训练语料的时候说除了一些敏感信息没有对数据集进行过滤，而 DeepSeek LLM 中介绍了为了提高数据质量专门做了模型去评估数据质量，还特意把一些冷门领域的数据占比放大，已获得更好的数据多样性。因此可以推测英文部分的语料质量 DeepSeek LLM 要高一些。作为参考 LLaMA-3 也在数据准备过程中引入了去重和质量过滤来提升语料的质量。</p><p>另一个原因我猜大概是中文语料的引入也提升了模型最终在英文上的表现。OpenAI GPT 3.5 的时候训练语料也是英文为主，但是最终在中文的表现上不差，一个猜测的原因就是在英文语料上学习到的一些知识迁移到了中文。同样中文语料里学习到的一些知识也可以迁移到英文。此外由于中文和英文在语法和表现形式上也有比较大的区别，这种多样化的数据是不是一定程度上也提升了模型的能力？还有就是不同语言本身就有不同的文化背景和内容倾向，这其实也是进一步增加了数据的多样性。如果这个猜测成立的话，那准备语料其实应该刻意地去增加不同语言的比重，让模型可以学习更丰富的语言表达形式。</p><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>模型的架构层面 DeepSeek LLM 和 LLaMA-2 几乎完全一样，各个路径上用到的技术比如 Pre-Norm，FFN 的激活函数，位置编码器都一模一样。最大的区别在于使用 GQA（Group<br>Query Attention）上。GQA 相比最原始的 MHA（Multi Head Attention），可以理解为为了节省训练和推理的 kv cache 占用，直接让多个 Query 头共享一组 Key 和 Value 的参数矩阵，这样可以大幅压缩显存的使用。但是带来的问题就是减少了 Key 和 Value 的潜空间个数，模型的表达能力也出现了下降。LLaMA-2 的做法是通过增加 FFN 网络的宽度来提供更多的非线性表达能力，而 DeepSeek LLM 的做法是增加 Attention 的层数。可以粗略理解尽管模型参数量相同，但是 LLaMA-2 是一个更宽的模型，而 DeepSeek LLM 是一个更深的模型。当然从后视的角度来看，DeepSeek 后续在 V2 公布的 MLA 对 Attention 层做了一个极其激进的更新，直接把推理所需的 KV Cache 降低了一个数量级。</p><p>另一个区别在于 LLaMA-2 使用的是 cosine learning scheduler 而 DeepSeek LLM 使用的是 Multi-Step learning scheduler。给出的理由是当增加数据量的时候，Multi-Step 可以更好的利用前一阶段的结果，持续训练速度会更快。</p><p>此外论文里还花了很大篇幅来介绍如何在不同的数据规模，数据质量，模型规模下选择合适的超参，如何去画 scaling law 曲线。这块是作者当成最大亮点来讲的，但是我看上去感觉和炼丹一样，看的我脑壳疼，感兴趣的同学可以自己看看。</p><h2 id="后训练"><a href="#后训练" class="headerlink" title="后训练"></a>后训练</h2><p>在论文发表的那个时间点，后训练主要是做对齐，也就是通过 SFT 和 RLHF 来对齐人类的偏好，增加模型的安全性。用到的数据基本上也都是一些带标记的对话文本，并没有对数据的分布做特别的处理。DeepSeek LLM 在这里对数据的选择又做出了和 LLaMA-2 很不一样的选择。</p><p>如果看最上面模型性能评估的对比图，可以看到 DeepSeek LLM 在 MATH，HumanEval 和 MBPP 几个非中文的指标表现也要好很多。因为 DeepSeek 在后训练的 SFT 阶段将近 70% 的样本都是 Math 和 Code 相关数据。可见他们根本就没把对齐作为后训练的重点，而是把提升模型能力作为后训练的重点，所以这更像是一个鸡贼的刷榜优化。</p><p>当时主流的做法还是在 base model 训练好了后再 SFT 一个代码和数学领域的模型，比如 Code LLaMA  和 OpenAI Codex 是分别在 LLaMA-2 和 OpenAI GPT3 上 SFT 出来的。Meta 当时甚至还在 Code LLaMA 上再 SFT 一个 Python 专用的 LLM 出来。</p><p>现在我们当然知道在后训练阶段通过在 Math 和 Code 样本上进行 RL 可以激发出模型 CoT 的推理能力，R1 的想法可能在这个时候就已经诞生了。</p><p>此外 DeepSeek LLM 在这里并没有用当时很流行的 RLHF，而是选择 DPO(Direct Preference Optimization) 进行和人类偏好的对齐。这种方法直接对两个不同生成结果的概率差作为优化目标进行训练，这相比 RL 其实更直观也更容易设计，在 LLaMA-3 的后训练过程中也用到了 DPO。可以看出 DeepSeek 团队当时对已有的 RL 算法还是不太满意的，还在探索。这也就造就了后来在 DeepSeek Math 中公布的 GRPO。 </p><h2 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h2><p>在我上学的时候，老师和我说真正的 Future Work 不要写在论文里，自己偷偷做再发下一篇，论文的 Future Work 里就写你觉得没戏的和你觉得做不出来的。而 DeepSeek LLM 最后 Future Work 的几句话从现在的视角来看都太真诚了，几乎已经把 R1 的路子给指出来了。</p><blockquote><p>DeepSeek LLM 将会是一个长期项目，专注于促进开源模型进步，</p></blockquote><p>这个不好说，毕竟满打满算也就一年多。</p><blockquote><p>Soon，我们将会发布 Code 和 MoE 架构的技术报告。MoE 的架构看上去很有希望。</p></blockquote><p>这个 Soon 指的是一周发布 MoE，半个月发布 DeepSeek Code。而我们已经知道 MoE 成为了 V2，V3 和 R1 模型的基础架构，参数量也上升到了 671B。</p><blockquote><p>我们现在已经有了大得多质量好得多的数据集，下一代模型所有指标都会显著提升。</p></blockquote><p>数据量半年后从 2T 变成了 8T，不过同期 LLaMA-3 变成了 15T。DeepSeek V2 的各项指标相比同期的 LLaMA-3 在英文上是稍微落后的，而且在 V2 的时候他们的重点就已经变成了疯狂降低成本。</p><blockquote><p>我们的对齐团队发现强化学习能够增强模型的复杂推理能力。</p></blockquote><p>从今天回头来看，这不就是 R1 最重要的方法么。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从今天的视角来看，DeepSeek 当时应该还在探索期，还在和业界的开源模型对齐，还做了很多理论上的研究。但是从论文的各个细节上来看，一年后那个石破天惊的 R1 诞生的条件已经差不多具备了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近找到了 DeepSeek 发表过的论文合集，包含了从 DeepSeek 第一版的 LLM 到最新的 R1 的演变过程。从当下的角度我们当然知道 DeepSeek R1 在模型能力上已经接近了业界最领先的水平，但他是如何一步步从一个在中国一开始都没有被重视的量化公司走到这</summary>
      
    
    
    
    
    <category term="DeepSeek" scheme="http://oilbeater.com/tags/DeepSeek/"/>
    
    <category term="LLM" scheme="http://oilbeater.com/tags/LLM/"/>
    
    <category term="Paper" scheme="http://oilbeater.com/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>从 Network Binding Plugin 看 KubeVirt 的扩展方式</title>
    <link href="http://oilbeater.com/2025/01/12/kubevirt-network-binding/"/>
    <id>http://oilbeater.com/2025/01/12/kubevirt-network-binding/</id>
    <published>2025-01-12T08:16:07.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>在 KubeVirt v1.4 的新版本里将 <a href="https://kubevirt.io/user-guide/network/network_binding_plugins/">Network Binding Plugin</a> 提升到了 Beta，提供了一种新的扩展 KubeVirt 网络的方式。虽然名义上是为了扩展网络的能力，但实际上从实现上来看，这个机制能做的事情远不止网络，所有和 libvirt domain xml 相关的变更都可以通过这个机制来实现。</p><h2 id="KubeVirt-Network-Overview"><a href="#KubeVirt-Network-Overview" class="headerlink" title="KubeVirt Network Overview"></a>KubeVirt Network Overview</h2><p>先从网络的角度来看下 KubeVirt 之前的网络机制有什么问题，新的机制又是如何进行扩展的。</p><p>由于 KubeVirt 使用的是 Pod 里面跑 VM 的架构，所以复用了 CNI 的网络机制。这样的话就将网络分成了两个部分，一个是 Pod 网络由各个 CNI 提供。另一部分就是如何将 CNI 提供的网络接入 VM，在 libvirt 里这部分叫做 Domain 网络。</p><p>KubeVirt 之前的各种网络机制（Bridge，Masquerade，Passt，Slirp）所做的事情就是通过不同的技术方案将 Pod 里的 eth0 接入到 VM 的 tap0 网卡。例如 Bridge 将 tap0 和 eth0 接入到同一个网桥，Masquerade 将 tap0 的流量经过 iptables nat 规则导入 eth0，Passt 和 Slirp 通过用户态的网络栈做流量重定向。</p><p><img src="/../images/kubevirt-networking-tradition.png" alt="alt text"></p><p>这些方法在实现上都是类似的，在 Pod 内部做一些网络相关的配置，然后修改 libvirt 的启动参数接入对应的网络。但是现有的机制都是写死在 KubeVirt Core 里的，并没有扩展机制，想要新增一种机制或者修改已有的机制都需要修改 KubeVirt 的代码很不灵活，例如默认的 bridge 插件会劫持 DHCP 请求，但是又不支持 IP, 所以 bridge 模式下的双栈就很难实现，而 Kube-OVN 中已经实现的 DHCP 又被这个机制绕过去了，之前想做 bridge 的双栈就需要改 KubeVirt 的代码来关闭默认的 DHCP 十分麻烦。因此新版本中将这套机制抽象出来提供了一套通用的机制。</p><h2 id="Hook-Sidecar"><a href="#Hook-Sidecar" class="headerlink" title="Hook Sidecar"></a>Hook Sidecar</h2><p>先来看一种在 KubeVirt 中已经存在的扩展机制 <a href="https://kubevirt.io/user-guide/user_workloads/hook-sidecar/">Hook Sidecar</a>。</p><p>这套机制是在 VM 正式创建前，可以加载一个用户自定义的镜像，或者一段 ConfigMap 里保存的 Shell 或者 Python 脚本，来修改 VM 启动前 libvirt 的启动参数和 cloud-init 参数。</p><p>它的执行机制和 CNI 有些类似，virt-handler 在启动 VM 前会去对应目录寻找 <code>/usr/bin/onDefineDomain</code> 和 <code>/usr/bin/preCloudInitIso</code> 两个二进制文件，前者传入 virt-handler 生成的 libvirt XML 配置，返回修改后的配置；后者传入 cloudInit 配置，返回修改后的 cloudInit 配置。这样的话所有 KubeVirt 本身不支持的 libvirt 和 cloudInit 参数都可以通过这种机制来注入修改。并且由于 Sidecar 内实际可以执行任意代码，所能做的事情远不止修改这两个配置，所有初始化阶段 KubeVirt 没有实现的能力其实都可以在这里来实现。</p><h2 id="Network-Binding-Plugin"><a href="#Network-Binding-Plugin" class="headerlink" title="Network Binding Plugin"></a>Network Binding Plugin</h2><p>现在可以到 Network Binding Plugin 这个机制了，这个机制其实和 Hook Sidecar 基本上大同小异。主要区别是将二进制调用改成了 gRPC 调用，gRPC 里注册的方法还是  <code>onDefineDomain</code> 和 <code>preCloudInitIso</code> 参数传递从命令行参数改为了 gRPC Request 里的参数，其他都是一样的。</p><p>具体的例子可以参考目前还在 KubeVirt 代码里的 <a href="https://github.com/kubevirt/kubevirt/tree/main/cmd/sidecars/network-slirp-binding">Slirp Binding</a> 的实现。尽管在 Network Binding Plugin 的规范里还增加了<code>networkAttachmentDefinition</code> 字段可以选择一个 CNI，但这个其实使用之前的网卡选择机制也能实现，甚至由于 Sidecar 里可以执行任意代码，在里面再实现一个 CNI 覆盖 Pod 原先的网络也是可以的。</p><p>那么之后的网络架构就变成了下图这样：</p><p><img src="/../images/networking-binding.png" alt="alt text"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然 Network Binding Plugin 的机制是为 Network 扩展准备的，但实际上几乎可以扩展所有 KubeVirt 在 virt-handler 侧的处理逻辑。甚至可以把 KubeVirt 也只当一个框架，所有的逻辑都通过 Sidecar 来处理，相信未来可以玩出不少花活来。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://kubevirt.io/user-guide/user_workloads/hook-sidecar/">https://kubevirt.io/user-guide/user_workloads/hook-sidecar/</a></li><li><a href="https://kubevirt.io/user-guide/network/network_binding_plugins/">https://kubevirt.io/user-guide/network/network_binding_plugins/</a></li><li><a href="https://github.com/kubevirt/kubevirt/blob/main/docs/network/network-binding-plugin.md">https://github.com/kubevirt/kubevirt/blob/main/docs/network/network-binding-plugin.md</a></li><li><a href="https://github.com/kubevirt/kubevirt/tree/main/cmd/sidecars/network-slirp-binding">https://github.com/kubevirt/kubevirt/tree/main/cmd/sidecars/network-slirp-binding</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 KubeVirt v1.4 的新版本里将 &lt;a href=&quot;https://kubevirt.io/user-guide/network/network_binding_plugins/&quot;&gt;Network Binding Plugin&lt;/a&gt; 提升到了 Beta，提供了</summary>
      
    
    
    
    
    <category term="kubevirt" scheme="http://oilbeater.com/tags/kubevirt/"/>
    
    <category term="networking" scheme="http://oilbeater.com/tags/networking/"/>
    
  </entry>
  
  <entry>
    <title>加速容器镜像下载：从缓存到按需加载</title>
    <link href="http://oilbeater.com/2024/10/31/docker-pull/"/>
    <id>http://oilbeater.com/2024/10/31/docker-pull/</id>
    <published>2024-10-31T11:59:25.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>在容器的启动过程中，镜像下载速度往往是影响启动速度的最主要因素，通常占据了启动时间的 70% 以上。特别是对于体积庞大的 VM、AI 镜像，它们的大小可能达到数十 GB，导致下载和解压速度都成为启动的瓶颈。本文将探讨镜像下载的主要瓶颈、常见的优化方案以及最新的按需加载技术，以加速容器启动。</p><h3 id="镜像下载速度慢的原因"><a href="#镜像下载速度慢的原因" class="headerlink" title="镜像下载速度慢的原因"></a>镜像下载速度慢的原因</h3><p>容器镜像下载慢的原因主要有以下几点：</p><ul><li><strong>镜像体积过大</strong>：VM、AI 镜像体积通常较大，可能达到数十 GB，使得下载时间显著。</li><li><strong>gzip 解压耗时</strong>：特别是在内网环境中，解压时间往往远高于网络传输时间，导致解压成为新的瓶颈。</li></ul><h3 id="常见的镜像优化思路"><a href="#常见的镜像优化思路" class="headerlink" title="常见的镜像优化思路"></a>常见的镜像优化思路</h3><p>为了解决下载和解压的速度问题，业界提出了多种优化方案：</p><ol><li><p><strong>镜像缓存</strong><br>镜像缓存是提升镜像下载速度的一种方法，通过缓存镜像可以避免重复下载。然而，缓存无法解决冷启动问题，并且镜像频繁变更（如应用更新或安全更新）会导致缓存失效。要实现高效的缓存管理，还需要较复杂的机制来管理缓存更新。</p></li><li><p><strong>减小镜像体积</strong><br>减少镜像体积也有助于缩短下载时间，但在某些场景下，例如 VM、AI、CUDA 镜像，体积优化空间有限。它们通常需要使用超过 7 GB 的存储空间，难以进一步缩减。</p></li></ol><h3 id="按需加载：是否可行？"><a href="#按需加载：是否可行？" class="headerlink" title="按需加载：是否可行？"></a>按需加载：是否可行？</h3><p>目前，大多数容器在启动时并不需要完整的镜像内容。一些论文表明，启动期间仅需 6.4% 的镜像内容，因此理论上可以通过按需下载来优化启动速度。然而，现有的镜像格式存在以下问题，限制了按需下载的实现：</p><ul><li><strong>OverlayFS 的限制</strong>：需要所有镜像层下载完毕后才能得知最终文件结构。</li><li><strong>gzip 不支持随机访问</strong>：即使只需下载单个文件，也要下载并解压整个层。</li><li><strong>校验问题</strong>：镜像 digest 是按整个层计算的，无法针对单个文件校验。</li></ul><h3 id="eStargz：实现按需加载"><a href="#eStargz：实现按需加载" class="headerlink" title="eStargz：实现按需加载"></a>eStargz：实现按需加载</h3><p>为了解决上述问题，eStargz 提出了针对 gzip 层的优化方案，即每个文件单独压缩并增加文件级别索引。eStargz 引入了如下优化：</p><ol><li><strong>独立压缩</strong>：每个文件单独压缩并索引，解决了 gzip 无法随机访问的问题。</li><li><strong>文件校验</strong>：可以对单个文件进行校验，无需校验整个层。</li></ol><p>具体的存储格式如下图：</p><p><img src="/../images/estartgz.png" alt="alt text"></p><p>每个文件被单独压缩合并成一个大的 blob，在 blob 最后增加一个 TOC 的描述文件记录每个文件的偏移量和校验值，这样就实现了按文件的索引和校验。</p><p>以下是 eStargz 的 TOC 格式示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;entries&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bin/&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dir&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;modtime&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2019-08-20T10:30:43Z&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span> <span class="number">16877</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;NumLink&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bin/busybox&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;reg&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;size&quot;</span><span class="punctuation">:</span> <span class="number">833104</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;modtime&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2019-06-12T17:52:45Z&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;mode&quot;</span><span class="punctuation">:</span> <span class="number">33261</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;offset&quot;</span><span class="punctuation">:</span> <span class="number">126</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;NumLink&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;digest&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sha256:8b7c559b8cccca0d30d01bc4b5dc944766208a53d18a03aa8afe97252207521f&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;chunkDigest&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sha256:8b7c559b8cccca0d30d01bc4b5dc944766208a53d18a03aa8afe97252207521f&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>通过这种改进，eStargz 实现了对单个文件的按需加载，且可以实现文件级别校验。</p><h3 id="性能权衡：优先级加载"><a href="#性能权衡：优先级加载" class="headerlink" title="性能权衡：优先级加载"></a>性能权衡：优先级加载</h3><p>虽然按需加载大幅优化了下载性能，但也可能带来运行时性能的下降。为此，eStargz 采用特殊标识来实现优先级加载，将启动所需文件放置于 <code>prioritized zone</code> 中，确保这些文件优先下载，进而提升运行时性能。</p><p><img src="/../images/estargz-optimize.png" alt="alt text"></p><p>按照作者测试的性能表现如下：</p><p><img src="/../images/estargz-perf.png" alt="alt text"></p><h3 id="代价与挑战"><a href="#代价与挑战" class="headerlink" title="代价与挑战"></a>代价与挑战</h3><p>尽管 eStargz 带来了按需加载的性能提升，但也带来了以下代价：</p><ul><li><strong>存储空间增加</strong>：每个文件单独压缩会增加额外的 metadata，降低压缩率。</li><li><strong>额外插件支持</strong>：eStargz 需要插件支持，例如在容器镜像推送和拉取时需要特定处理插件。</li></ul><h3 id="如何使用-eStargz"><a href="#如何使用-eStargz" class="headerlink" title="如何使用 eStargz"></a>如何使用 eStargz</h3><p>以下是 eStargz 的使用方法，适用于 containerd 的子项目以及一些支持 eStargz 的工具：</p><ol><li><p><strong>Docker, kaniko, nerdctl 命令行参数</strong>：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker buildx build -t ghcr.io/ktock/hello:esgz \</span><br><span class="line">    -o <span class="built_in">type</span>=registry,oci-mediatypes=<span class="literal">true</span>,compression=estargz,force-compression=<span class="literal">true</span> \</span><br><span class="line">    /tmp/buildctx/</span><br><span class="line"></span><br><span class="line">nerdctl image convert --estargz --oci ghcr.io/ktock/hello:1 ghcr.io/ktock/hello:esgz</span><br></pre></td></tr></table></figure></li><li><p><strong>containerd 插件配置</strong>：</p> <figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="section">[proxy_plugins]</span></span><br><span class="line">  <span class="section">[proxy_plugins.stargz]</span></span><br><span class="line">    <span class="attr">type</span> = <span class="string">&quot;snapshot&quot;</span></span><br><span class="line">    <span class="attr">address</span> = <span class="string">&quot;/run/containerd-stargz-grpc/containerd-stargz-grpc.sock&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="section">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd]</span></span><br><span class="line">  <span class="attr">snapshotter</span> = <span class="string">&quot;stargz&quot;</span></span><br><span class="line">  <span class="attr">disable_snapshot_annotations</span> = <span class="literal">false</span></span><br></pre></td></tr></table></figure></li></ol><p>此外，GKE 等云平台的集群已默认启用类似方案，进一步加速了镜像启动速度。看阿里也发表了基于 block device 的按需加载，这类的实现看上去在云厂商都有了比较大规模的落地。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从传统的镜像缓存、镜像体积优化，到按需加载，eStargz 提供了一种兼顾性能和灵活性的方案，使得容器可以在仅下载部分内容的情况下启动。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/estargz.md">eStargz: Standard-Compatible Extension to Container Image Layers for Lazy Pulling</a></li><li><a href="https://medium.com/nttlabs/startup-containers-in-lightning-speed-with-lazy-image-distribution-on-containerd-243d94522361">Startup Containers in Lightning Speed with Lazy Image Distribution on Containerd</a></li><li><a href="https://www.usenix.org/conference/fast16/technical-sessions/presentation/harter">Slacker: Fast Distribution with Lazy Docker Containers</a></li><li><a href="https://github.com/containerd/accelerated-container-image">Accelerated Container Image</a></li><li><a href="https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming">Use Image streaming to pull container images</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在容器的启动过程中，镜像下载速度往往是影响启动速度的最主要因素，通常占据了启动时间的 70% 以上。特别是对于体积庞大的 VM、AI 镜像，它们的大小可能达到数十 GB，导致下载和解压速度都成为启动的瓶颈。本文将探讨镜像下载的主要瓶颈、常见的优化方案以及最新的按需加载技术，</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>AI Gateway 调研之 Kong, Gloo 和 Higress</title>
    <link href="http://oilbeater.com/2024/08/26/kong-gloo-higress/"/>
    <id>http://oilbeater.com/2024/08/26/kong-gloo-higress/</id>
    <published>2024-08-26T07:39:23.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>上篇<a href="2024-08-25-ai-gateway-cloudflare">博客</a>介绍了 Cloudflare AI Gateway，这篇集中介绍一下 Kong, Gloo 和 Higress 因为这三者有一定的相似性，都是从原有的 API 网关基础上进行扩展，通过插件的方式支持了一系列 AI 相关的功能，在交付上也是传统的软件部署方式。这几个算是传统 API Gateway 迎接 AI 浪潮的代表，其中 Higress 更是把产品 Slogan 直接从 Cloud Native API Gateway 变成了 AI Gateway，虽然打不过就加入，但这样变来变去不怕人说没根么：）</p><p>由于这三款产品都需要额外的部署开通，有的 AI 功能还是商业版才有，所以下面的分析都是根据看文档总结而来，可能存在着和实际不符的情况。</p><table><thead><tr><th>功能</th><th>Kong</th><th>Gloo</th><th>Higress</th><th>备注</th></tr></thead><tbody><tr><td>技术栈</td><td>Nginx + Lua</td><td>Envoy + Go</td><td>Envoy + WASM</td><td>虽然几家都提供了插件机制，但是和网关的耦合程度都比价高，非网关的开发者上手还是有一定难度</td></tr><tr><td>日志监控</td><td>每个 AI 插件会将元信息，如模型名、Token 开销费用等信息加入到 Audit Log 中，但是似乎没有自定义元信息的功能，需要通过其他插件来辅助完成</td><td>似乎没有在 AI 这块对日志有功能增强，还是通用的监控</td><td>日志和监控中增加了 Token 的用量，提供的信息和 Kong 类似，也不具备自定义元信息的功能</td><td>如果能增加一些自定义元信息，并支持记录 Request 和 Response 里 Message 信息就更好了</td></tr><tr><td>Proxy</td><td>Kong 提供了归一化的 API 能够用一套统一的 API 去调用不同的 LLM API，这对开发者还是比较友好的能够不需要大改应用代码就能用不同的 LLM</td><td>Gloo 没有提供归一化的 API，只是反向代理到上游 LLM API</td><td>Higress 支持将不同的 LLM API 统一转换成 OpenAI API，这对开发者来说也比较友好，毕竟目前生态里还是直接用 OpenAI API 的比较多</td><td>虽然我觉得是否提供归一化的 API 没那么重要，不过一定要归一化的话归一化成 OpenAI 格式的会好些</td></tr><tr><td>API Key 管理</td><td>客户端的 Key 可以和上游的 Key 不一样，相当于把 Key 在网关层做了一层屏蔽</td><td>客户端的 Key 可以和上游的 Key 不一样，相当于把 Key 在网关层做了一层屏蔽</td><td>直接从客户端透传 Key 给上游</td><td>个人感觉 Gloo 这个功能还比较实用，避免了在 LLM 那里真实的 Key 被过多业务方知道，安全和可控性会更好一些</td></tr><tr><td>Cache</td><td>当前版本没有提供 LLM Cache 相关能力，据说会在 3.8 版本提供</td><td>提供了语义 Cache，看配置是调用了 OpenAI 的 Embedding 和 Redis 的 Vector，不过没看到更细粒度的比如 TTL 相似度的配置</td><td>提供的还是文本匹配的缓存，相比全文本可以通过 JSON PATH 的语法选择部分 Message 做缓存，看配置也是利用 Redis，不过不支持语义 Cache</td><td>Gloo 提供的语义 Cache 看起来更高级一些</td></tr><tr><td>请求&#x2F;响应改写</td><td>可以在 Request 和 Response 阶段分别加 prompt 对 message 进行改写，相当于一个小型的 workflow</td><td>只提供了 prepend system prompt 的能力，感觉提升有限</td><td>和 Kong 类似提供了用 prompt 进行改写的能力，不过现在只支持通义千问的 LLM 感觉不够开放</td><td></td></tr><tr><td>RAG</td><td>目前没有相关功能的插件</td><td>可以对接一个 postgres 和 OpenAI 的 embedding Token 这样可以自己提供一些文本来做 RAG</td><td>和 Gloo 的功能类似，不过只支持阿里云的向量服务和通义千问，还是感觉不够开放</td><td>感觉 RAG 的配置参数都比较少没有相似度，或者爬取网页的接口，只能做比较简单的 RAG</td></tr></tbody></table><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这三款产品由于只是看文档没有真实使用过，里面的内容很可能有不准确的地方，希望了解的同学可以指正。</p><p>总体来看三款产品都是 LLM 爆发前就存在的，之前也不是专门为 AI 场景设计的，很多使用的配置可能懂 Kubernetes 的更能看懂。尤其是 Gloo 的文档全是 YAML 和 CRD 的配置，浓浓的 Cloud Native 味道，Higress 看上去也是各种 ConfigMap 脱离 Kubernetes 是否还能用好我是心里存在疑虑的。</p><p>Higress 虽然没根了，但是整体看 AI 功能做的还是最完整的，发力也比较明显。Kong 感觉还只是试探性的做了些功能，而 Gloo 是把所有 AI 相关功能都放到商业版里了。如果 Higress 能把开发性做好不是被通义千问和阿里云上各种服务绑定的话我觉得还是个不错的项目。</p><p>最后的依赖还是这三款产品的扩展性可能都存在一定难度，需要高度了解网关相关的逻辑并掌握 Lua 或者 WASM 这样非主流的语言。而 AI 应用现在的形态其实还存在很多变化的可能，对应的 API 和需要的通用能力可能也有比较大的变化，比如怎么做 RAG，怎么做 Cache，怎么编排 LLM 都没有确定下来。不知道现在的架构会不会对他们未来的功能灵活变化产生影响。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;上篇&lt;a href=&quot;2024-08-25-ai-gateway-cloudflare&quot;&gt;博客&lt;/a&gt;介绍了 Cloudflare AI Gateway，这篇集中介绍一下 Kong, Gloo 和 Higress 因为这三者有一定的相似性，都是从原有的 API 网关基础上进</summary>
      
    
    
    
    
    <category term="AI" scheme="http://oilbeater.com/tags/AI/"/>
    
    <category term="Gateway" scheme="http://oilbeater.com/tags/Gateway/"/>
    
    <category term="Kong" scheme="http://oilbeater.com/tags/Kong/"/>
    
    <category term="Gloo" scheme="http://oilbeater.com/tags/Gloo/"/>
    
    <category term="Higress" scheme="http://oilbeater.com/tags/Higress/"/>
    
  </entry>
  
  <entry>
    <title>AI Gateway 调研之 Cloudflare AI Gateway</title>
    <link href="http://oilbeater.com/2024/08/25/ai-gateway-cloudflare/"/>
    <id>http://oilbeater.com/2024/08/25/ai-gateway-cloudflare/</id>
    <published>2024-08-25T14:10:45.000Z</published>
    <updated>2026-01-11T13:26:21.899Z</updated>
    
    <content type="html"><![CDATA[<p>随着 AI 的火热，眼看着之前调研的各家竞品 API 网关产品纷纷把自己的介绍改为 AI Gateway，于是就想调研一下这些所谓的 AI Gateway 究竟做了些啥。这次调研的对象有一些之前靠 API 网管或者云原生 Ingress Controller 起家加入 AI 功能的，例如：<a href="https://konghq.com/products/kong-ai-gateway">Kong</a>，<a href="https://www.solo.io/products/gloo-ai-gateway/">Gloo</a> 和 <a href="https://higress.io/en/">Higress</a>。也包括一些第一天就是借着 AI 起来的我认为真正 AI 原生的网关，例如 <a href="https://portkey.ai/features/ai-gateway">Portkey</a> 和 <a href="https://github.com/songquanpeng/one-api">OneAPI</a>。以及这篇博客介绍的基于公有云 Serverless 的 <a href="https://developers.cloudflare.com/ai-gateway/">Cloudflare AI Gateway</a>。</p><p>大体来看目前的 AI Gateway 主要能力在三个方面：</p><p><strong>常规 API 网关功能在 AI API 上的应用</strong>，例如：监控，日志，限速，反向代理，请求或响应改写，集成用户系统等。这些功能其实和 AI 关系不大就是把 LLM 的 API 当成了一个普通的 API 进行接入。</p><p><strong>部分 API 网关功能针对 AI 进行优化</strong>，例如限速功能增加基于 Token 的限速，缓存功能增加基于 Prompt 的缓存，防火墙基于 prompt 和 LLM 返回进行过滤，多个 LLM API Key 之间的负载均衡，多个 LLM Provider 的 API 转换。这些功能在原有的 API 网关就存在类似的概念，不过在 AI 场景下又有了相应的扩展。</p><p><strong>基于 AI 应用的场景增加的新功能</strong>，例如部分 AI 网关增加了 Embedding 和 RAG 的功能，把向量数据库和文本数据库的功能通过 API 的形式提供出来。还有一些针对 token 用量的性能优化，比如 Prompt 简化，语义化 Cache 等。还有一些更偏应用层的功能，例如对 LLM Output 提供打分功能等。</p><p>这篇博客介绍 <a href="https://developers.cloudflare.com/ai-gateway/">Cloudflare AI Gateway</a> 这款 AI Gateway 的特点。</p><h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><p>Cloudflare 的这款 AI Gateway 主要功能其实就是一个反向代理，看完了我甚至觉得我用 Cloudflare Worker 捣鼓一阵也能做个功能类似的。如果你原来用的是 OpenAI 的 API 那么现在你要做的就是把 SDK 里的 baseURL 换成 <code>https://gateway.ai.cloudflare.com/v1/$&#123;accountId&#125;/$&#123;gatewayId&#125;/openai</code> 就可以了。在这个过程中由于流量进出都是过 Cloudflare 的，Cloudflare 平台上就可以提供对应的监控，日志，缓存等功能。</p><p>这个方案有下面几个优点：</p><ul><li>接入很简单，改一下 baseURL 就接入进来了，API 格式也没有任何变化。并且完全是 Serverless 的，不需要自己额外管理任何服务器，这个功能现在是免费的，直接就白嫖了监控数据。</li><li>借助 Cloudflare 的全球网络可以实现一定的用户接入加速，不过这个用户接入的加速相比 LLM 本身的延迟比重应该很小，顶多在首个 Token 的延迟会有明显变化。</li><li>通用借助 Cloudflare 的全球网络可以一定程度隐藏掉源 IP，对于一些 OpenAI API 访问受限的区域用这个可以绕过去。</li></ul><p>但对应的也有下面的缺点：</p><ul><li>所有请求信息包括 API Key 都要在 Cloudflare 上过一道，会有安全方面的一些隐患。</li><li>Gateway 本身没有什么插件机制，想扩展功能的话会比较麻烦，只能在外面再套一层。</li><li>同样是因为 Cloudflare 的全球网路欧，如果一个 Key 一直变换 IP 地址访问，不知道会不会触发 OpenAI 那边的拉黑。</li></ul><h1 id="主要能力"><a href="#主要能力" class="headerlink" title="主要能力"></a>主要能力</h1><h2 id="多个-Provider-支持"><a href="#多个-Provider-支持" class="headerlink" title="多个 Provider 支持"></a>多个 Provider 支持</h2><p>由于 Cloudflare AI Gateway 并没有对 LLM API 进行修改，只是做反向代理，所以几乎主流的 LLM API 它都可以支持，只需要把 baseURL 改成对应 Provider 如 <code>https://gateway.ai.cloudflare.com/v1/$&#123;accountId&#125;/$&#123;gatewayId&#125;/&#123;provider&#125;</code> 即可。</p><p>它唯一多提供的一个 API 叫做 <a href="https://developers.cloudflare.com/ai-gateway/providers/universal/">Universal Endpoint</a> 可以做简单的 fallback。用法是在一个 API 请求里可以填写多个 Provider 的<br>query，这样当前面的 Provider 请求失败时会自动调用下一个 Provider。</p><h2 id="可观测"><a href="#可观测" class="headerlink" title="可观测"></a>可观测</h2><p>监控层面除了基础的 QPS 和 Error Rate 这些监控面板，还针对 LLM 的场景提供了 Token，Cost 以及 Cache 命中率的面板。</p><p>日志方面和 Worker 的日志很类似，只有实时日志无法查询历史日志。这里感觉做的不太好，Worker 至少还有第三方的方案能保存日志，但是 Gateway 这里却没有了。虽然通过一些实时日志 API 再自己保存的方式也可以，但还是太麻烦了。分析 LLM 请求和响应日志应该是很多 AI 应用后续做优化甚至 fine-tuning 的一个重要环节，这里没有直接集成持久化的方案其实是个硬伤。</p><h2 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h2><p>缓存方面，Cloudflare 提供的还是基于文本内容完全匹配的缓存，目测是通过 <a href="https://developers.cloudflare.com/kv/">Cloudflare Workers KV</a> 来实现的。也可以通过 <code>cf-aig-cache-key</code> 来实现自定义 Cache Key，包括设置缓存的 TTL 以及忽略 Cache。但是整体看起来基于现在的功能是无法实现语义缓存的，官方文档的说法是语义缓存会在未来提供。</p><h2 id="Rate-Limiting"><a href="#Rate-Limiting" class="headerlink" title="Rate Limiting"></a>Rate Limiting</h2><p>限速方面，Cloudflare 提供的还是传统的基于 QPS 的限速，这块并没有基于 AI 的场景提供基于 Token 的限速，这里未来还有改善的空间。</p><h2 id="Custom-metadata"><a href="#Custom-metadata" class="headerlink" title="Custom metadata"></a>Custom metadata</h2><p>可以在请求的 Header 中增加一些自定义字段，比如用户信息。这些信息可以通过日志进行检索。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>整体来看 Cloudflare AI Gateway 胜在简单易用，对于之前没有使用 AI Gateway 的用户可以两三分钟就接进来，提供了基础的监控和缓存能力。而且 Cloudflare 还有一些其他配套的 AI 服务例如 Works AI 提供了大量的开源模型的 Serving 和 Worker 提供边缘计算，几个一结合就能搭一套完全 Serverless 的 AI 系统。</p><p>他的问题主要在于更深入的功能提供的比较少，而且功能扩展比较麻烦，只能在外围通过 Worker 再来包一层。与其这样 Cloudflare 还不如直接把 AI Gateway 开源出来变成一个模板，用户可以根据自己需求去更改代码或者写插件，没准还能形成一个新的生态。毕竟我高度怀疑现在的 AI Gateway 其实就是个 Worker 模板。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;随着 AI 的火热，眼看着之前调研的各家竞品 API 网关产品纷纷把自己的介绍改为 AI Gateway，于是就想调研一下这些所谓的 AI Gateway 究竟做了些啥。这次调研的对象有一些之前靠 API 网管或者云原生 Ingress Controller 起家加入 AI</summary>
      
    
    
    
    
    <category term="AI" scheme="http://oilbeater.com/tags/AI/"/>
    
    <category term="Gateway" scheme="http://oilbeater.com/tags/Gateway/"/>
    
    <category term="Cloudflare" scheme="http://oilbeater.com/tags/Cloudflare/"/>
    
  </entry>
  
</feed>
